<!DOCTYPE html><html>
<head><meta name="author" content="Christopher Ferrall"><link             href='http://fonts.googleapis.com/css?family=PT+Mono|Open+Sans:400italic,700italic,400,700,800,300&subset=latin,latin-ext,greek-ext,greek' rel='stylesheet' type='text/css'></link>
<link rel="stylesheet" type="text/css" href="css/doc.css"></link>
<script type="text/x-mathjax-config"> MathJax.Hub.Config({tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]}});</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><title>Computation For Economists</title></head>
<h1>Computation For Economists<br/>Christopher Ferrall<br/>&nbsp;<br/>Queen's University</h1><hr/>
<h2>Table of Contents</h2>
<!DOCTYPE html><html>
<head><meta name="author" content="Christopher Ferrall"><link             href='http://fonts.googleapis.com/css?family=PT+Mono|Open+Sans:400italic,700italic,400,700,800,300&subset=latin,latin-ext,greek-ext,greek' rel='stylesheet' type='text/css'></link>
<link rel="stylesheet" type="text/css" href="css/doc.css"></link>
<script type="text/x-mathjax-config"> MathJax.Hub.Config({tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]}});</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><title>Computation For Economists</title></head><h3>Computation For Economists</h3>
<OL type="I" class="toc1"">
<LI><a href="s001.html" target="content">Prelude to a Mess</a></LI>
<OL type="A" class="toc2"">
<LI><a href="s002.html" target="content">What's Going On?<br/>&emsp;Plan of this Book</a></LI>
<LI><a href="s003.html" target="content">Tell Me Why</a></LI>
<LI><a href="s004.html" target="content">If I Had a Hammer:<br/>&emsp;Computational Tools</a></LI>
<LI><a href="s005.html" target="content">Hello, Cleveland!<br/>&emsp;Your First Ox Program</a></LI>
<LI><a href="s006.html" target="content">What's In the Box?<br/>&emsp;Two Economic Examples Worthy of Computation</a></LI>
<OL type="1" class="toc3"">
<details class="toc"><summary>sections</summary>
<LI><a href="s007.html" target="content">Edgeworth</a></LI>
<LI><a href="s008.html" target="content">Nash</a></LI>
</details>
</OL>
</OL>
<DT><a href="ex001.html" target="content">Exercises</a></DT>
<LI><a href="s009.html" target="content">Programming and Computation</a></LI>
<OL type="A" class="toc2"">
<LI><a href="s011.html" target="content">Programming Essentials in Ox</a></LI>
<OL type="1" class="toc3"">
<details class="toc"><summary>sections</summary>
<LI><a href="s012.html" target="content">Ask Me Anything:<br/>&emsp;FAQs on Programs</a></LI>
<LI><a href="s013.html" target="content">Basic Instinct:<br/>&emsp;Elements of An Ox Program</a></LI>
<LI><a href="s014.html" target="content">Express Yourself<br/>&emsp;Ox Syntax for Calculations</a></LI>
<LI><a href="s015.html" target="content">A Simple Plan<br/>&emsp;Ox Syntax for Conditional and Repeated Execution</a></LI>
</details>
</OL>
<LI><a href="s016.html" target="content">Hardware</a></LI>
<OL type="1" class="toc3"">
<details class="toc"><summary>sections</summary>
<LI><a href="s017.html" target="content">If 6 Was 9<br/>&emsp;A Computational Puzzle</a></LI>
<LI><a href="s018.html" target="content">Tim<br/>&emsp;Hardware for <s>Dummies</s>Economists</a></LI>
<LI><a href="s019.html" target="content">Machine Head</a></LI>
<LI><a href="s020.html" target="content">Numb3rs<br/>&emsp;Integers and Reals</a></LI>
<LI><a href="s021.html" target="content">Memento<br/>&emsp;Memory and Addresses</a></LI>
</details>
</OL>
<LI><a href="s022.html" target="content">The Code-to-Execution Process</a></LI>
<OL type="1" class="toc3"">
<details class="toc"><summary>sections</summary>
<LI><a href="s023.html" target="content">The Ties that Bind<br/>&emsp;When Things Happen in a Program</a></LI>
<LI><a href="s024.html" target="content">Across The Great Divide<br/>&emsp;The Two Kinds of Programming Languages</a></LI>
<LI><a href="s025.html" target="content">Run Lola Run<br/>&emsp;The Programming Cycle</a></LI>
</details>
</OL>
<LI><a href="s026.html" target="content">Advanced Programming in Ox</a></LI>
<OL type="1" class="toc3"">
<details class="toc"><summary>sections</summary>
<LI><a href="s027.html" target="content">Snakes and Arrows<br/>&emsp;Vectors, Matrices and Arrays</a></LI>
<LI><a href="s028.html" target="content">Higher Ground<br/>&emsp;More Things in Ox</a></LI>
<LI><a href="s029.html" target="content">More Expressions</a></LI>
<LI><a href="s030.html" target="content">Objects and Classes</a></LI>
<LI><a href="s031.html" target="content">The Style Council</a></LI>
</details>
</OL>
<LI><a href="s032.html" target="content">Life in the Fast Lane<br/>&emsp;High Performance Computing</a></LI>
<OL type="1" class="toc3"">
<details class="toc"><summary>sections</summary>
<LI><a href="s033.html" target="content">Avoid Overhead</a></LI>
<LI><a href="s034.html" target="content">One Way or Another<br/>&emsp;Parallel Execution</a></LI>
</details>
</OL>
</OL>
<DT><a href="ex009.html" target="content">Exercises</a></DT>
<LI><a href="s035.html" target="content">Digital Mathematics and Statistics</a></LI>
<OL type="A" class="toc2"">
<LI><a href="s037.html" target="content">Fundamentals</a></LI>
<OL type="1" class="toc3"">
<details class="toc"><summary>sections</summary>
<LI><a href="s038.html" target="content">Blurred Lines<br/>&emsp;Linear Algebra and Linear Systems</a></LI>
<LI><a href="s039.html" target="content">Roll With the Changes<br/>&emsp;Differential Calculus</a></LI>
<LI><a href="s040.html" target="content">Add It Up<br/>&emsp;Integral Calculus</a></LI>
</details>
</OL>
<LI><a href="s041.html" target="content">Non-Linear Systems</a></LI>
<LI><a href="s042.html" target="content">Optimization</a></LI>
<OL type="1" class="toc3"">
<details class="toc"><summary>sections</summary>
<LI><a href="s043.html" target="content">Climb Every Mountain<br/>&emsp;Gradient Based Optimization</a></LI>
<LI><a href="s044.html" target="content">Finding Nemo<br/>&emsp;Non-Gradient Optimization</a></LI>
</details>
</OL>
<LI><a href="s045.html" target="content">Sliding Doors<br/>&emsp;Simulation &amp; Randomness</a></LI>
</OL>
<DT><a href="ex035.html" target="content">Exercises</a></DT>
<LI><a href="s046.html" target="content">Digital Economics in niqlow</a></LI>
<DT><a href="ex046.html" target="content">Exercises</a></DT>
</OL>
</body></html>
<OL type="I"
<OL  type="I" ">
<h1><a name="s001"><LI>Prelude to a Mess</a></LI></h1>
<blockquote class="toc"><h4>Contents</h4>
<OL type="A" class="toc2"">
<LI><a href="s002.html" target="content">What's Going On?<br/>&emsp;Plan of this Book</a></LI>
<LI><a href="s003.html" target="content">Tell Me Why</a></LI>
<LI><a href="s004.html" target="content">If I Had a Hammer:<br/>&emsp;Computational Tools</a></LI>
<LI><a href="s005.html" target="content">Hello, Cleveland!<br/>&emsp;Your First Ox Program</a></LI>
<LI><a href="s006.html" target="content">What's In the Box?<br/>&emsp;Two Economic Examples Worthy of Computation</a></LI>
</OL>
</blockquote>
<OL  type="A" ">
<h2><a name="s002"><LI>What's Going On?<br/>&emsp;Plan of this Book</a></LI></h2>

The plan of this book is simple :
<UL>
<LI>Begin with the "hello world" program.</LI>
<LI>End with structural estimation of discrete dynamic programming models by generalized method of moments.</LI>
</UL>

In between it will:
<UL>
<LI>Cover essentials of programming, basic algorithms for mathematics, and computational versions of canonical economic models such as the Edgeworth Box model of competitive equilibrium and subgame perfect equilibrium in sequential games.</LI>

<LI>Use the free (for academic use) programming language Ox, which is a matrix- and object-oriented language that has all the basics an economist needs to do computational economics.</LI>

<LI>Teach the Ox package niqlow, a platform for designing, solving and estimating dynamic programming models. </LI>
</UL>
<h2><a name="s003"><LI>Tell Me Why</a></LI></h2>
<!-- -->

<blockquote class="quote">
Real Economists do not use <ins><t>insert-user-friendly-package-here</ins>.
<br>--Variations on <a href="http://en.wikipedia.org/wiki/Real_Programmers_Don%27t_Use_Pascal">Real Programmers Don't Use Pascal</a></br></blockquote>

<OL class="section">
<LI>Kids Don't Follow</LI>
(Nearly) everyone is a computer user, or a user of computer-like devices.  But few students of economics are computer programmers.  Casual observations over two decades suggests as use of computers (and computer-like gadgets) has risen so has knowledge of how computers work fallen.  Over time computers have become so easy to use that understanding how they work has become less vital to success in many fields or majors, economics included. Yet original computer programming is probably more important to current economic research than ever before.  Let's call this the <em>programming gap</em>.<p/>

<DT>Why does economics have a programming gap?</DT>
First, as taught to undergraduate economics, programming would appear to be a peripheral skill.  We require calculus and linear algebra, and for decades most undergraduate programs have supplemented this with a mathematics for economics course.  On the other hand, I know of no departments that require a computer programming course and only a few that offer Computational Economics, let alone require the course to graduate.  Undergraduate econometrics involves some computer use, but it never involves programming.   A bright econ major with a B.A. would be justified in thinking that economics is done mainly with pen and a paper and Stata or Excel.</p>

Second, introductory computer science courses focus on issues not relevant to an economist, especially how to solve mathematical models numerically. Computer science as a discipline has evolved away from scientific computing, traditionally called numerical analysis.  The things that a student of economics needs t know about computing has little to do with what a computer science professor works on or teaches to her students.  As an analogy, if some other major relied heavily on input-output analysis most economics departments would have trouble finding anyone qualified and interested in teaching it.  This means that even economics degree holders with some programming background have never applied that skill to economics and still think it is unnecessary to contribute to the field.</p>

Why computing continues to have almost no role in formal economic curricula is a mystery to me.  One reason is that it is closely tied to ever-changing technology, so what seemed important to teach 20 years ago is not, and the same may true of what seems important now.  But in many ways the fundamental aspects of computing in economics are not changing any more quickly than other tools.  And certainly the barriers to hands-on training have completely disappeared.  (Readers of a certain age will remember getting a Dickensian portion of CPU minutes on the campus mainframe to run regressions.)  <p/>

Another reason is the tradition of teaching the way you were taught.  Most academic economists that do original programming in their research learned the methods on their own.  It is then natural for them to leave computing out of their formal teaching, even at the graduate level in fields that require intensive programming.  Students start with code given to them by advisors or older students and then tweak it (and now download some Matlab code for a published paper and tried to figure out what it does).  This perpetuates a cottage-industry approach to computational economics.  Unlike disciplines that work on large-scale, multiple-author computing problems (like cosmology), economists work in groups of two or three.  Code is handed down and modified or extended through trial-and-error.</p>

Older cohorts believed that real programmers use FORTRAN (or more recently C).  One perfectly valid reasons for using any language is the programmer has built up language-specific capital.  But a good reason to stay with one language, chosen in the past at a very different stage of computer development, is not a valid reason to adopt that language fresh rather than something else.  Advisors transmit this view to their students.  Since formal teaching of FORTRAN is non-existent, self-study is the solution.  Now consider what the novice undergraduate or graduate programmer confronts.  Code available in economics, especially when written by self-taught programmers, is usually badly documented (let alone coherently indented).  No data structure more complicated than multi-dimensional arrays will be used.  So the code and the coding style to learn is far removed from the mathematics it implements.  Any attempt to teach programming to economists with this starting point quickly bogs down in nested loops, endless assignment statements and blackbox math libraries that may or not be available to students located elsewhere.</p>
<P/>
So, these patterns combine to produce the strange fact that the typical economics student in 2013 understands no more, and perhaps even less about numerical mathematics than their counterparts in the past while the practice of economics relies on programming and numerical methods more every year. The result is a widening gap in programming skills among economics students at the point they start to do research.
<P/>
<LI>Fixing a Hole</LI>
<P/>
The objective of this document is to reduce the programming deficit in economics education. This book introduces programming to the econ student, perhaps an advanced undergraduate or a graduate student just realizing that most modern research does not end with manipulating symbols on paper (although it still starts there).   It assumes the reader uses the Internet, produces documents, perhaps a spreadsheet, and packages such as Stata&#8482;.  The book also assumes that the reader has a good understanding of economic theory and calculus.  But it also assumes that the student has only a vague idea how any of the computer applications they use work, and even less insight about mathematics performed by a computer.  </p>
<P/>
That assumed reader is a fair description of the median student I encounter in my classes.    That person is somewhat reticent to admit they do not know what the difference between compiled and interpreted languages, nor how zeros and ones can represent real numbers.  However, when I ask a class if they learned to invert matrices using cofactor matrices this assumed student nods.  They ploughed through those complex formulas in their math econ class and are ready to do it again. It seems I am always the first person to ever tell them the truth: no one computes the inverse of a matrix this way and the knowledge is useless. They are taught that way because forty years ago it was the only recourse a student might have to invert a matrix and the math econ textbooks have put cofactor matrices, and Cramer's rule in the canon.  It seems to me that it would be better that the student knew that computers solve linear systems with matrix decomposition even if they can't do it on paper for the 3x3 case.</p>
<P/>
In economics the major text on computational methods is <em>Numerical Methods in Economics</em> by Kenneth Judd.  The book is comprehensive in its coverage of algorithms for solving economic models.  However, it does not discuss computer programming at all.  The algorithms are step-by-step mathematical expressions in <em>pseudo code</em>, and an experienced programmer can easily implement them in their favorite language.  But the inexperienced programmer will not know where to start.  If they took their advisor's advice and started teaching themselves FORTRAN they will soon discover the gap between elegant vector notation and the tedium of three levels of <code>DO</code> loops. Further, Judd's book is comprehensive and supported by research on numerical analysis, but its emphasis.  For example, in one sentence Judd mentions that optimization algorithms can be made to respect bounds on parameters to keep them feasible (such as not trying to compute <var>log(-2)</var>) by non-linear transformations.  This book a whole chapter to the implementation of this idea because it is essential for model building and estimation. </p>
<P/>
This book is part prequel to Judd and part companion to it. It discusses the process of creating, testing and describing a program.  It also introduces topics, such as object-oriented programming, that help a programmer write a good program regardless of the algorithm it implements. And it covers high performance computing issues so that a student of economics can move their code from the laptop to the cluster or cloud.  To be complete, there is a great deal of overlap with Judd when it concerns basic algorithms in digital mathematics. </p>
<P/>
<LI>Everyday I Write the Book</LI>
<P/>
As an undergraduate I enjoyed computing science and to a lesser extent economics. When I went to graduate school in economics I did not think the formal computer background would play much role.  But over time I pursued a comparative advantage in work that required original programming.  Although FORTRAN was the first language I was taught, the computer science antipathy towards it rubbed off on me and I have typically avoided it.  When I started to program as an economist, C was not a particular good option for computational science, so I returned to Pascal, often considered a 'teaching language'.  Compilers for these languages to run on personal computers were not always affordable nor reliable in the 1980s.  Gauss emerged as a convenient solution which I used for work on my dissertation.  </p>
<P/>
But in the early 1990s I learned a lesson about programming languages and economics.  When trying to solve a very large (for the time) problem I overwhelmed what a PC could do. But I was able to secure some precious hours of CPU time on a 'supercomputer'.  Of course, as a DOS program, Gauss was not an option.  So I realized I had backed myself into a corner.  From then on I knew that I would avoid languages that were not available on multiple platforms.  I bit the bullet and translated my code into Pascal, which served me well over 15 years, multiple machines and architectures despite its minority-language status.  Learning to use MPI for parallel execution in the 1990s was a key.  The MPI library was available in FORTRAN and C.  But this was no problem, because a little bit of C programming allowed me to access it from within Pascal and my model building continued apace. And I was even able to write Pscal code that a few other people used in C and FORTRAN .  The lesson I learned: computer language popularity was less important as portability and inter-operability with other languages.  </p>
<P/>
Around 1998 a grad student thought I should look at Ox.  I did, and thought it was interesting but I was wary of the corner another matrix-based language had put me in.  Further there was no hope that it could support the large-scale parallel execution I needed.  But two years later I was planning to teach a short course on numerical methods at a different university.  I had access to a computer lab and wanted to have assignments and demonstrations.  But there was no hope of getting a licensed program such as Gauss installed.  I remembered Ox, and being free and easy to install made it a perfect solution. I used it and found it perfect for that purpose.  I still viewed it as primarily for teaching and small scale work.  Only later did I start trying to use it for research.  And once again the problem I was working became much larger than a PC could handle.  So with some effort I once again accessed MPI routines written in C from within Ox and was able to take advantage of high performance computing resources without translating my code.  </p>
<P/>
The last piece of the whole story is <em>object objected programming</em> (OOP), an approach which I was only vaguely familiar with since my formal training took place before OOP had become a standard approach.  With a desire to create a package for solving dynamic programs available to others, I saw a big tradeoff.  My usual approach, which was the same as most economists, was to write a program specific to the problem at hand.  I had 'libraries of routines' to use, but there was no way to define the problem as the program executed.  So if another person was to use my code they would have to fiddle with the knobs and switches of the code and re-compile the result.  Soon it became clear that this was onerous and very hard to make flexible and general.  The only people who might use it would have to be guided by me.  Eventually, I came to see a way around this problem using OOP in Ox.  That large-scale (and on-going) project forced me to think carefully about distribution, documentation and efficiency.</p>
<P/>

<LI>Why Ox? Why not <code>insert-your-favorite-language</code>?</LI>

To present programming and computational economics this book uses Ox, a computer language created by Jorgen Doornik.  Ox is currently at version 7, and has been developed since the early 1990s.  Ox has these key features for our purpose:  it is free to students and academic researchers;  it is portable and suitable for both learning computational economics and doing it. Despite, this, it is not, unfortunately, one of the major languages used in economics.</p>

Economists trained before the 1980s who write scientific programs but otherwise had no computer science training almost invariably used FORTRAN, which was synonymous with scientific programming.  Students often adopt languages (naturally) used by their professors. So FORTRAN had momentum even when other languages and platforms became as good at scientific programming, such as C.  Adoption of FORTRAN in economics has slowed markedly in recent years.  Early young researchers would likely have used C and would be able to find mathematical packages in C.</p>

When PCs came on the scene in the 1980s the basic languages like FORTRAN and C were not readily available for them.  One of the first PC-based languages was Gauss, which was quite popular in economics through the 1990s. However, Gauss was a commercial program that did not run on "mainframe" computers. By the 2000s, Matlab was starting to replace it as was the open source statistical platform R. Stata has introduced a matrix language in order to support more general programming than its original data set orientation. Lately use of Python in scientific computing has been growing.</p>

Each year one or two students tell me <q>Why do you use Ox rather than X,"</q> where the value of X slowly evolves. No one choice could possibly suit every potential reader of this book.   Most people who start to program do not survey all the available options, weigh the pros and cons and then pick the optimal choice.  One reason is that they have no way to weigh the tradeoffs between features and capacities.  So nearly everyone relies on trusted advice.</p>

</OL>
<h2><a name="s004"><LI>If I Had a Hammer:<br/>&emsp;Computational Tools</a></LI></h2>
<!-- -->

<blockquote class="quote">We shape our tools, and thereafter our tools shape us.<br><b>--Marshall McLuhan</b></br></blockquote>

<h4>The Bear Necessities Shopping List</h4> 
<UL> 

<LI>A computer.  </LI>

<LI><code>Ox 7.0</code> or greater installed on the computer.  Instructions appear below.</LI> 

<LI><code>OxEdit</code> editing program. OxEdit is installed along with Ox.  You can certainly use another code editor to edit your programs, but there is no reason too unless you already have a favorite. </LI>

<LI>This book.</LI>

<li>The code directory for examples in this book.</li>

</UL>

<h4>Ox Installation Instructions.</h4>
<OL class="steps">
<LI>Go to <a href="http://www.doornik.com/download/oxmetrics7/Ox_Console/">http://www.doornik.com/download/oxmetrics7/Ox_Console/</a>.
    Choose your platform (Windows, Linux, Max) and click on a download link (either Server 1 or Server 2).</LI>
    
<LI>Open the installation package. If asked to install OxEdit as well, do so.</LI> 

<LI><mark>Mac Users:</mark> There is an issue with the set up of OxEdit on OSX (not an issue with Ox itself).  As set up, OxEdit does not like spaces in path names. This can be fixed, but the easiest thing is to place your Ox code in a folder with no spaces in the path, such as "C:\Users\Paul_Samuelson\Econ_354" instead of "C:\User\Paul Samuelson\Econ 354".  If you don't want to remove spaces in your path please bring me your notebook and we will adjust OxEdit so it works for any path.</LI>

<LI>Open OxEdit.  Click <code>Tools -&gt; Add/Remove Modules.</code> Then look for <code>Takes Input</code> on the menu and make sure the box is checked on.  Then click <code>Close</code>. </LI>        
</OL>

<h4>Using OxEdit and Access Ox Documentation.</h4>

<UL>
</UL>

<h4>The Lush Life Shopping List</h4> 

These are tools that more serious/ambitious computational economics require.  There is no reason to gather these tools until one or more these things are involved:
<DD>You are doing computations that involve many components that work together.</DD>
<DD>Your code takes a long time to finish.</DD>
<DD>Your project involves other people working on the code</DD>
<DD>You wish to distribute your code to others and want them to understand it.</DD>

<UL> <LI><code>GNU make</code>.  <a href="https://en.wikipedia.org/wiki/Make_(software)">Make</a> is a program that automates the building of a program or any other thing on your computer that involves many steps and components.  There are may alternatives that do similar things, but make continues to be popular 40 years after it was first developed.</LI>

<LI><code>git</code>. Installed on your computer or on the
    server and an account on github.com.  <a href="https://en.wikipedia.org/wiki/Git_(software)">git</a> is a <em>version control system</em> that makes it easier to collaborate with others on a project.  Two recommended advanced tools are hosted on github:
    <UL>
    <LI><code>niqlow</code>.  </LI>

    <LI><code>OxDoc</code> </LI>
    </UL></LI>
    
<LI>Access to <code>gcc</code> or another C compiler.  There are two reasons to use C or another compiled language such as FORTRAN. 
    <UL>
    <LI>Write code that can be called from your Ox program that will speed up aspects of your code that are inefficient when coded in Ox. People rarely do this but it is good to have the option.</LI>
    <LI>If you run your code on a cluster with the <code>MPI Library</code> installed then you can run your program in parallel.</LI>
    </UL>
    <DD>If you are using a Windows computer and have no access to a Unix server, you can install <a
    href="http://www.cygwin.com/">Cygwin</a> or <a href="http://www.mingw.org/">MinGW</a></DD></LI>

</UL>

<h2><a name="s005"><LI>Hello, Cleveland!<br/>&emsp;Your First Ox Program</a></LI></h2>
<!-- -->
<OL class="section">
<li>Here is the canonical first program in Ox:</li>

<DD><pre><span class="fname"><em><a href="./code/hello-world.ox" download>hello-world.ox</a></em></span> <object height="100" width="95%" type="text/plain" data="./code/hello-world.ox" border="1" ></object></pre></dd>

<DT>Output should appear that looks like this</DT>
<DD><pre>
--------------- Ox at 12:58:58 on 07-Sep-2012 ---------------
Ox Console version 6.21 (Windows/U) (C) J.A. Doornik, 1994-2011
This version may be used for academic research and teaching only

hello world </pre></DD>

<hr/>
<DT><img src="img/stop_sign.png"/><mark>If you have not executed <code>hello world.ox</code>, <b>STOP</b>.</mark></DT>
<DD>Right click on the <code>hello-world.ox</code> link and save the file to your computer.  If necessary, move the file to your working Ox directory.</DD>
<DD>Open OxEdit.  Click <code>File->Open</code> or <kbd>Ctrl-O</kbd>.  Find <code>hello-world.ox</code> and open it.</DD>
<DD><em>Alternative to the previous two steps:</em> Copy the code in the box above.  Open OxEdit. Click <code>File -&gt; New</code>.  Paste the code in.   </DD>
<DD>Run the program by either <code>Run -&gt; Ox</code> or click on the left <em>running man icon</em> on the tool bar, which does the same thing. (If you created a new file you will be asked to save the file first. Save it to your working Ox directory.)</DD>
<hr/>

<li>Why start with a program that just prints a dumb message?</li>

There is a story and a reason. The original <code>hello world</code> program appeared on the first page of Chapter 1 of <em>The C Programming Language</em> by  Kernighan and Ritchie (1978). In 1978 just to get the words "hello world" to appear on a screen or a paper printout was a big hurdle that involved many issues. These issues were (and still are) hard to describe and resolve in a book.  Kernighan and Ritchie began with the simplest task that  required all the resolution of all those difficult issues, because  there was little point in teaching the rest of the C language if the   student could not get it to print out a message.  Once past the hurdle the reader could more easily absorb the  details in the book knowing they could get their C program to do  something. </p>

 To this day a good place to start any book about programming that may be picked up by a novice asked them to first run <code>hello world</code>. The hurdles are much lower for the target reader of this book than the typical reader of Kernighan and Ritchie in 1978. But computers are still mysterious to many bright people, including students of economics.Even people with computing experience find that getting this simplest task to work is a good way to start learning a new computer language.

<h2><a name="s006"><LI>What's In the Box?<br/>&emsp;Two Economic Examples Worthy of Computation</a></LI></h2>
<!-- -->

Before starting from the beginning with how to program in Ox we consider two basic economic models that are usually encountered by the third year of an economics undergraduate degree.  Typically these models are solved for the basic "two-by-two" cases that we present here.  And other special assumptions are used to keep the problems simple enough to solve on paper.  The purpose of learning computational techniques is to make it possible to <em>generalize</em> and <em>automate</em> the solution of these kinds of problems.  That is, computational techniques can handle more than the special cases covered in economic theory textbooks and homework assignments.  And computational techniques can solve problems over and over again without mistakes (once the code is correct).</p>
<OL  type="1" ">
<h3><a name="s007"><LI>Edgeworth</a></LI></h3>

<h4>A Two Person, Two Good Exchange Economy</h4>

The Edgeworth Box is a way to visualize the fundamental interactions in economic theory: gains from trade with scarce resources.  </p>

For the box to be visual on a page we describe an economy with two goods, 1 and 2, and two people, A and  B.  A consumption bundle is a vector of quantities of the two goods.  So the amount person $i$ gets to consume is $x^i = (x^i_1,x^i_2)$, for $i=A,B$.</p>

Our two people begin with an endowment of each good, denoted $W^i = (w^i_1,w^i_2)$.  They may do better off because their endowments differ and/or their preferences over the two goods differ. Let the preferences of person $i$ be captured by the utility $U^i(x^i)$, which for simplicity is strictly concave and increasing in the consumption bundle elements.  With two goods it is very helpful to consider indifference curves for each person, that is sets of bundles that all deliver the same utility.   With strict concavity we get <q>nice</q> indifference curves that are convex to the origin.  The slope of the indifference curve is called <dfn>the marginal rate of substitution (MRS)</dfn>.  I hope that readers remember that the MRS equals the ratio of the marginal utilities:
$$MRS^i(x^i) = -{\partial U^i(x^i) / \partial x^i_1 \over U^i(x^i) / \partial x^i_2}.$$

If there is no trade then person $i$ simply consumes $x^i = W^i$ and receives utility $U^i(W^i)$.  However, gains from trade may allow both people to get more utility. The total resources in the economy is the vector sum of the endowments:
$$E = W^A + W^B.$$
A feasible allocation of the resources must satisfy the condition $x^A + x^B \le E$, and if we assume that everything is consumed we can simply require $x^A+x^B = E$.


<h4>Pareto Allocations, the Contract Curve </h4>

In general a Pareto allocation is a feasible allocation for which neither person can be made better without making the other worse off by changing to another feasible allocation.  Let $\hat x^A$ and $\hat x^B$ be a Pareto allocation.  With nice preferences, we can describe (an interior) Pareto allocation as one that satisfies a marginal condition.  On the margin each person makes the same internal tradeoff between the two goods.  </p>

That is, A and B's MRSs are equal to each other at a Pareto allocation <em>and</em> all the resources are consumed:
$$\eqalign{\hat x^B = E - \hat x^A\cr
MRS^A\left(\hat x^A\right) = MRS^B\left(\hat x^B\right)\cr
}$$
We can combined the two conditions (efficiency and feasibility) into a single condition on $\hat x^A$:
$$MRS^A\left(\hat x^A\right) = MRS^B\left(E - \hat x^A\right).$$
Thus, the condition is a single non-linear equation with two free variables ($x^A_1$ and $x^A_2$).  So in general there are many Pareto allocations. </p>

Of course, some of the allocations make one person worse off than if they did not trade and simply consumed their endowment.  So a point on the <em>contract curve</em> is a Pareto allocation that is a voluntary trade:
$$\eqalign{U^A\left(\hat x^A\right) &\ge U^A\left(W^A\right)\cr
           U^B\left(E-\hat x^A\right) &\ge U^B\left(W^B\right)\cr}$$</p>

<h4>Competitive Allocations</h4>
The contract curve can be thought of as the prediction of what would happen if A and B negotiate face to face. Neither would voluntarily trade to a point with a utility lower than their endowment.  And if they are patient enough they could exhaust the gains from trade by finding a point that satisfies the marginal condition.</p>

In reality we rarely trade face-to-face.  Instead, we enter a market with prices with an amount of income and chose for ourselves.  In this simple world, there are two prices: $(p^1,p^2)$, but we can normalize $p^1=1$ and focus on a single price.  That is, we can think of good 1 and <q>all other goods</q> and good 2 as some specific good we wish to focus on. The price of good 1 is 1 because allocations of it can be interpreted as dollars available to spend on other goods instead of good 2. So the price vector is $(1,p)$.</p>

In a competitive market each person takes the price $p$ as given and makes an optimal choice subject to their budget constraint.    Person A's budget constraint is:
$$1x^A_1 + px^A_2 = 1W^A_1 + p W^A_2.$$
Person B faces a similar budget constraint.  If both people maximize utility subject to their budget constraint then each will satisfy their own individual marginal condition:
$$MRS^i(x^i) = {p\over 1} = p.$$
Note that this means that both MRS's will be equal to each other because they are both equal to the slope of the budget line. However, we can't lose track of the budget constraint.  If person A satisfy it, then we add one more condition beyond the efficiency condition in a Pareto allocation: $\hat x^A_1 + p \hat x^A_2 = W^A_1 + p W^A_2.$  
Note that this means that $\hat x^A_1$ is not free, its value is determined by $p$ and $x^A_2$:
$$\hat x^A_1 = W^A_1 + p (W^A_2 - \hat x^A_2).$$
Thus a  <em>competitive allocation</em> satisfies two equality conditions and has two free values to satisfy those constraints.  Namely, we can set $p$ to a particular value, call it $p^\star$, and we can set $x^A_$ to a particular value $\hat x^A_2$.  The two conditions are then:
$$\eqalign{
??}$$

<h4>Computation</h4>

Unless you work with simple utility functions it is very hard to solve for Pareto allocations in the Edgeworth Box.  So one of the goals for this text is to teach the methods that would let you solve for Pareto allocations or the contract curve in an Edgeworth Box.  These methods will al so generalize to solve for larger allocation problems, including more that 2 people and more than 2 goods.

<h3><a name="s008"><LI>Nash</a></LI></h3>
<h4>A Two Person Simultaneous Move Game with Two Strategies</h4>

<table style="text-align:center;" align="none" cellpadding="8">
<tr> <th colspan="4">What to Binge Watch</th> </tr>
<tr><td colspan="2"></td><th colspan="2">Jordan</th><tr>
<td style="width:15%;"></td> <td style="width:15%;">U<sub>P</sub>,U<sub>J</sub></td>
<td style="width:35%; border-bottom: solid black 1px;">Breaking Bad (BB)</td>
<td style="width:35%; border-bottom: solid black 1px;">Glee (G)</td> </tr>
<tr> <th>Pat</th> <td style="border-right: solid black 1px; text-align: right;">Breaking Bad (BB)</td>
<td style="border-right: solid black 1px; border-bottom: solid black 1px; font-size:120%;">3,2</td>
<td style="border-right: solid black 1px; border-bottom: solid black 1px; font-size:120%;">1,1</td> </tr>
<tr> <td></td> <td style="border-right: solid black 1px; text-align: right;">Glee (G)</td>
<td style="border-right: solid black 1px; border-bottom: solid black 1px; font-size:120%;">0,0</td>
<td style="border-right: solid black 1px; border-bottom: solid black 1px; font-size:120%;">2,3</td> </tr> </table>

<h4>Nash Equilibrium in Pure Strategies</h4>
<OL class="alg">
<LI>Compute Pat's Best Response Function</LI>
<DD>$a^\star  ar_{P}(BB) = BB$</DD>
<DD>$a^\star_{P}(G) = G$</DD>
<LI>Compute Jordan's Best Response Function</LI>
<DD>$a^\star_{P}(BB) = BB$</DD>
<DD>$a^\star_{P}(G) = G$</DD>
<LI>Construct the best response vector,
$$a^\star(a_P,a_J) = \bigl(a^\star_P(a_J),a^\star_J(a_P)\bigl)$$</LI>
<DD>$a^\star(BB,BB) = (BB,BB)$</DD>
<DD> $a^\star(G,BB) = (BB,G)$</DD>
<DD> $a^\star(BB,G) = (G,BB)$</DD>
<DD> $a^\star(G,G) = (G,G)$</DD>
<LI>Find <q>Fixed Points</q> in the best-response vector: <DD>
$$a^\star\bigl(a^o_P,a^o_J\bigr) = \bigl(a^o_P,a^o_J\bigr)$$ </DD></LI>
<DD>$NE = \biggl\{ (BB,BB),\ (G,G) \biggr\}$.</DD> </OL> </details>

<DT>Complications and Extensions</DT>
<DD>Best responses may not be unique, so $$a^\star()$$ may include sets of strategies.</DD>
<DD>Mixed strategies: beliefs are distributions over opponent strategies, choice is a distribution over my strategies.</DD>

<h3><a name="ex001"><LI>Exercises</a></LI></h3>
<h3>Exercises</h3><OL class="steps">
<LI>Hello, Cleveland. Modify <code>hello-world.ox</code> to print out dialogue from a  favorite movie or play. Have your code also display a link to the clip or the script.
<DT>Example</DT> <DD>Your Ox code might produce
<pre>
David St. Hubbins:  ROCK AND ROLL!
Derek Smalls:       HELLO, CLEVELAND!
https://www.youtube.com/watch?v=dPgOA5kPk8c
</pre></DD></LI>

<LI> Learn how to use the <em>formatting</em> code <q>\n</q> so that Ox will print out each line of dialogue separately with only one <code>println()</code> statement.  </LI>

<LI>Find the Ox function that will convert a bit of text (called a <em>string</em>) to all upper case letters.  That is, this Ox function will take <q>hello, Cleveland</q> and convert it to
    <q>HELLO, CLEVELAND</q>. Use it in your code.</LI>

</OL>
</OL>
</OL>
<h1><a name="s009"><LI>Programming and Computation</a></LI></h1>
<blockquote class="toc"><h4>Contents</h4>
<OL type="A" class="toc2"">
<LI><a href="s011.html" target="content">Programming Essentials in Ox</a></LI>
<LI><a href="s016.html" target="content">Hardware</a></LI>
<LI><a href="s022.html" target="content">The Code-to-Execution Process</a></LI>
<LI><a href="s026.html" target="content">Advanced Programming in Ox</a></LI>
<LI><a href="s032.html" target="content">Life in the Fast Lane<br/>&emsp;High Performance Computing</a></LI>
</OL>
</blockquote>
<OL  type="A" ">
<h2><a name="s011"><LI>Programming Essentials in Ox</a></LI></h2>
<blockquote class="toc"><h4>Contents</h4>
<OL type="1" class="toc3"">
<LI><a href="s012.html" target="content">Ask Me Anything:<br/>&emsp;FAQs on Programs</a></LI>
<LI><a href="s013.html" target="content">Basic Instinct:<br/>&emsp;Elements of An Ox Program</a></LI>
<LI><a href="s014.html" target="content">Express Yourself<br/>&emsp;Ox Syntax for Calculations</a></LI>
<LI><a href="s015.html" target="content">A Simple Plan<br/>&emsp;Ox Syntax for Conditional and Repeated Execution</a></LI>
</OL>
</blockquote>
<OL  type="1" ">
<h3><a name="s012"><LI>Ask Me Anything:<br/>&emsp;FAQs on Programs</a></LI></h3>

This chapter assumes that the reader is completely new to programming of any sort. The very basic idea of computer programming is introduced by analogy and through a question-answer format. The next chapter then brings that analogy closer to reality.</p>

<OL class="section">

<h4>Meta-language: Language about Language</h4>

<LI>What is a computer language? &hellip; a computer program?</LI>

These are difficult to answer precisely. An accurate answers would include jargon that someone asking the question would not understand anyway.  So instead, let's ask a different question &hellip;</p>

<LI>What is the English language?</LI>

There is no one answer to that either (this is not a good start for a FAQ!).  But we could say that, in its written form, the English language consists of a set of allowed symbols and a set of rules for putting those symbols down in a sequence, one after the other.

<DL>
<DT>Some symbols like "." and "?" play special roles that others, such as "a" and "B" do not.  </DT>

<DT>Other symbols, like a space " " can be repeated without&nbsp;&nbsp;&nbsp;&nbsp; changing the meeting.</DT>

<DT>Certain symbols are not allowed in English, such as, "&oslash;", and certain sequences of symbols are not allowed, such as "szzx qqbb". </DT><DD>But English has an escape clause to deal with this: anything inside double quotes does not have to follow the rules of English and should be taken as is.</DD>

<DT>Valid English with non-English symbols and words:</DT>
<DD><pre>        In Norwegian "&oslash;st" means east, while in Martian "szzx" means west. </pre></DD>
<DD>In the sentence the non-English components are put inside quotes.  Of course, valid English can go inside quotes as well.</DD>
</UL>

<LI>What does it mean for something to be valid in English?</LI>

It means that someone who already knows English will understand the sequence of symbols and agree it is proper English.  Some rules that say which symbols are allowed next to each other are called <em>spelling</em>, and other rules are called <em>syntax</em>.  So "zbignew" is not spelled as a proper English word, but Zbignew is perfectly fine because in English words starting with capitals are names, and names can be anything.  They do not need to follow spelling rules.  Finally, English syntax rules out "Eat dogs man." but rules in "Dogs eat man." It also rules in "Eat dogs, man!" because <code> ,</code> and <code> !</code> turn it into an imperative statement to consume canines followed by an interjection.</p>

Finally, note that the rules and symbols allowed in English allow for an infinite number of different sequences of symbols and an infinite number of meanings.</p>

<LI>How does a computer language like Ox compare to a human language like English?</LI>

<DT>A computer programming language, including Ox is</DT>
 <DD>a set of symbols</DD>
 <DD>a set of rules that say what sequence of symbols are allowed.</DD>

<DT>A <u>program</u> is a sequence of symbols that may or may not follow the rules of the language, just as a document may or may not follow the rules of English.  </DT>
<DD>As a computer language, the rules in Ox (its syntax) are very different than the syntax in a human language such as English. </DD>
<DD>A key difference between a computer language like Ox and a human language like English is the scope they are designed to handle. A computer language is not designed to allow for the variety of documents in a human language, such as novels, poems, tweets, etc.  </DD>
<DD>Instead, Ox is a kind of computer language that is built to express a very narrow subset of proper English documents:
<blockquote>A valid Ox program is a <b>to-do list</b>.</blockquote></DD>

<LI>What is the essence of a to-do list?</LI>

<DT>In English a to-do list is written for a human (perhaps not the same person as the author) to understand then carry out the requests on the list.  </DT>
<DD>We assume this person wants to carry out the requests but can only do so as long as the requests make sense and are feasible.  </DD>
<DD>Let's call the person reading the to-do list the <em>executor</em>.  </DD>
<DT>The executor of an English to-do list will probably ... </DT>
<DD>first skim the list all the way through first looking for problems without worrying about the details.  </DD>
<DD>Then, if that goes well, start carrying out the instructions one-by-one. </DD>
<DD>The list may not make sense if it is not proper English or does not provide enough information to complete the request.  </DD>
<DD>So the to-do list may have to include explanation or extra information beyond just the requests.  And the tasks on the list might conflict with each other in way that is only apparent as the executor is carrying them out.  </DD>
<DD>So if such a problem arises the executor might have just stop and give up.</DD>

<LI>How is an Ox program like a to-do list?</LI>

<DT>A computer program is a to-do list (at least in the class of languages Ox belongs to), but it also includes auxiliary information needed to interpret the requests correctly.  </DT>
<DD>So for a computer program there must be an executor who will try to carry out the tasks the program requests.  </DD>
<DD><a href="">??</a> goes into some detail about program execution and the notion of the executor will become much more explicit.  </DD>
<DD>For now, you should see the Ox executor as a aspect of the computer the program is written on that is equivalent to the reader of an English to-do-list.</DD>

<DT>For brevity, the thing that acts like the executor of Ox will be referred to as <code>ExOx</code>: the name we are using for what executes an Ox program.</DT>
<DD>What ExOx is exactly will become apparent as we go along.</DD>

<DT>Just as a to-do list in English could be translated into an equivalent to-do list in Spanish (or Swahili or Navajo etc.), so nearly all computer languages are potentially equivalent.  </DT>
<DD>You could get a given computer to do the same tasks if written in Ox or C or FORTRAN or Perl or LISP or R or MATLAB etc. </DD>
<DD>However, how efficiently a particular to-do list can be done, and how simple the to-do list is to write, can differ across computer languages.  We discuss these differences in detail in Chapter ?.</DD>

<LI>What is the simplest English sentence?</LI>

In English there is not a single simplest sentence.  Perhaps the shortest complete English sentence is "I am" unless we count for imperatives like "Go!". However, in some important ways "I am" is no simpler than "She prevaricates" or the shortest verse in the Bible: "Jesus wept." A proper English sentence must have a subject and a predicate.  These can be very complicated sequences of symbols or just two words.  But grammatically they are equivalent even though the number of letters (or how abstract the verb is) are different.

<LI>What is the simplest possible (proper) Ox program?</LI>
<DT>The Simplest Ox Program</DT>
<DD><pre>main(){}</pre></DD>
<DD>That is a complete Ox program that tells <code>ExOx</code> to do absolutely nothing.  </DD>
<DD>Many other sequences of symbols would be valid Ox programs that do nothing, but some symbols could be removed from those programs and nothing would continue to happen.  </DD>
<DD>However, if any of the symbols in the program above were removed or modified the program would fail to be understood by <code>ExOx</code>.</DD>
<details><summary>Turing Snobs</summary>The Simplest Ox Program actually does printout a standard message, so a purist will take exception to Ox.  However, the dispute is not with Ox as a computer language itself but with the <code>ExOx</code> interpreter of that language.</details>

<LI> Why is this the simplest possible program?</LI>

<DD>Because a complete Ox program must <em>define</em> a procedure called <code> main </code>.  </DD>
<DD>A procedure is defined by its name, followed by information inside parentheses, <code> ( ) </code>, and then certain information inside curly brackets <code> { } </code>.  Nothing is required to be inside those delimiters, so the simplest program is the one above.</DD>

<LI>Is there any syntactical difference between that simplest program above and this one?</LI>
<DD><pre>
/* Do nothing */
main(    )
  {

  }
// done
</pre></DD>
Yes and no.
<DD>First, the symbols are obviously different, but as programs they both do exactly nothing.  The second program includes two Ox <em>comments</em>.  </DD>
<DD>A comment is text in a program that is there to explain to a human (or possibly a different computer program) what the code is doing.  </DD>
<DD>By design, the executor of the program ignores comments completely.  Comments in Ox are any symbols that come between <code> /*</code> and <code> */</code> or come between <code> //</code> and the end of a line in the program.  </DD>
<DD>These ways to mark comments come from C, so they are similar to many other languages based on C but make no sense to someone just starting.  Comments are an "escape clause" in a computer program.  They say to the interpreter, ignore this material because the human put it here to communicate with other humans (or possibly other computer programs that look at this program).  </DD>
<DD>Further, any sequence of white space in Ox is equivalent: " " is the same as "\ \ \  \  ". And, with one exception blank lines are the same as white space.</DD>

<LI>What is a simple Ox program that does <em>something</em>?</LI>

The <code> hello world.ox</code> program in the preface is a standard "do-something" program.
<DT>Here is another one</DT>
<DD>For goodness' sake, do something!
<pre>
main(){
  decl x;
  x = 20.3;
  }
</pre></DD>
<DD>This program assigns the numerical value 20.3 to something called <code> x</code>.  </DD>
<DD>If you run this program you will see no more output than the do-nothing program above.  However, it really does something and will be expanded on below.</DD>

<DT>Do the same thing differently.</DT>
<DD><pre>
main(){
  decl x = 20.3;
  }
</pre></DD>

<h4>Understanding a Program: Symbols, Tokens, Parsing, Syntax</h4>

<LI>What does it mean to run or execute a program?</LI>

It simple means to carry out the to-do list that the program is.  This can be done by executing the program on a computer.  Or it could mean doing it yourself mentally.  How programs are executed is discussed later in the hardware sections.</p>

<LI>Does a computer understand my program like I understand English as I read it?</LI>

A computer program is written in a language that makes it easier for a human to write it, but the computer hardware will not understand the language directly.</p>

<LI>In the programs above, symbols like <code> ( ) </code> and <code> ;</code> seem to be different than letters like <code> main</code>.   What do the brackets do?  </LI>

Let's return to English.  Written English has special symbols, like period "." to end a sentence. Sentences typically have no special symbol at the start. (Spanish has &iexcl; and &iquest to begin special sentences.)  And typically a paragraph is one or more sentences that ends in a blank line or a new line that is indented.  </p>

It would be confusing to use <code> .</code> for both the end of a statement in a computer language and as the decimal place in numbers.  So in Ox (and many other languages), the special symbol <code> ;</code> ends a complete statement and acts like <code> .</code> in English. And like English a new statement begins after the last one ends so there is no need for a special start symbol.</p>

<LI>What is the syntax of "Dogs eat man."?</LI>

If we apply English syntax to that sentence it means we are <em>parsing</em> the sentence.  Parsing does not result in the meaning of the sentence but rather interpreting the sequence of symbols.  From a parsing perspective "Dogs" and "Cats" and "Martians" could all start that sentence and the syntax would be the same.  So "Dogs" is a unit of the English language syntax, a <em>word</em>.  In general, we would say it is a <em>token</em>.</p>

The token is a unit of the language that is defined by one or more symbols.  The parser needs to find the tokens in the list of symbols, and in English this is done with spaces and punctuation.  So in terms of tokens the sentence boils down to <code> T1 T2 T3 T4</code>, where <code> T1</code> is "Dogs" and <code> T4</code> is the final period.  Notice that the spaces between words are not tokens.  They are only there to mark the beginning at end of tokens so they are discarded during the parsing stage.</p>

A key thing is that a token has <em>properties</em> or <em>attributes</em> which the syntax and the semantics of the language must keep track of.  One of these properties is the sequence of symbols that made it up so that later its meaning and other attributes can be looked up.</p>

<DT>Example of a Token and Its Attributes</DT>
<dd><pre>
Token T1
   input: Dogs
   type: Noun, improper, plural
   role: Subject
</pre></dd>
Notice that there are many attributes to the token.  In human languages the same string of symbols can mean completely different things based on where they appear.  (For example, "dogs" can also mean the verb which means to chase relentlessly.)</p>

The symbol <code> { </code> creates a <em>block</em> of statements, ended by <code> } </code>.  A block of statements acts like a single statement.  An analogy to English: a sentence expresses a complete thought.  A paragraph is made up of 1 or more sentences that also expresses a complete thought, it's just a more complex thought than a single sentence cannot convey.  In English we put paragraphs in sections, sections in chapters, chapters in books, etc.  But in most C-like languages such as Ox, blocks can go inside blocks.  That is, <code> {  { } { } } }</code> is a block with two blocks inside it, like a book section consisting of two paragraphs.</p>

<LI>Are spaces important?</LI>

Spaces are important in Ox because, like in English, they separate sequences of symbols that produce separate <em>chunks</em> of meaning.  For example, in English <code> Dog eats man.</code> and <code> Dog eatsman.</code> are completely different because one space is missing in the former.  In the same way, the program above would not be proper Ox if it read <code> declx;</code> instead of <code> decl x;</code>.  </p>

On the other hand, spaces are not important everywhere in Ox, typically when special symbols are involved.  <code> main ( ) </code> is the same as <code> main()</code> because the spaces are usually needed to separate things called <em>identifiers</em>, such as <code> decl</code> and <code> x</code>.  Identifiers cannot have special symbols in them, so in <code> main()</code> the identifier is <code> main</code> and is followed by special symbols <code> ()</code>. But <code> declx;</code> is a single identifier followed by <code> ;</code>, whereas <code> decl x;</code> are two separate identifiers next two each other followed by <code> ;</code>.</p>

<LI>What is the important information about Ox so far?</LI>

<DL>
<DT>Every Ox program has a single <code> main()</code> procedure.</DT>
<DD>Without finding a <code> main</code> procedure, <code> ExOx</code> will not do anything.</DD>
<DD>The first thing inside <em>main()</em> is the first things that really happens when <code> ExOx</code> is carrying out the to-do list.</DD>
<DD>Things that appear above <code> main()</code> in the program do not happen before it, but they may be handled before the program executes.</DD>

<DT>A well-written Ox program will include <em>comments</em> to make it easier for a human to understand but are completely ignored by <code> ExOx</code>.</DT>

<DT>Identifiers look like words, and like English words they are separated by spaces and special symbols.  </DT>
 <DD>Because computer languages are supposed to be somewhat understandable by humans, special symbols often play roles in the language that are similar to their uses in human languages.</DD>
</DL>

<LI>What is an Ox syntax error?</LI>

A syntax error is a sequence of symbols that do not follow the Ox rules. An analogy to an English to-do list would  be "The milk buy."  A human might realize the list writer meant to write "Buy the milk."  But typically program executors are not designed to guess, although they are designed to give helpful feedback if possible.  That is, the human reader might say "I don't understand.  Did you mean 'Buy the milk'?"  </p>

Some of these syntax rules are easy to learn and intuitive, but others are harder to keep in mind.  But many of even the simplest rules that you already know are easy to forget about when writing a program.  Humans do not think like computers and their languages are not the same as computer languages, so we often fail to follow basic syntax rules when writing programs

<DD><pre>
main() {
  x = 5;
  }
</pre></DD>
This will cause a syntax error.  The reason in Ox is that a variable like <code> x</code> that you want to assign values to has to be <em>declared</em> before it is used.  <code> ExOx</code> will look through the code and discover this problem before trying to carry out or execute the program.  So, instead:
<DD><pre>
main() {
  decl x;
  x = 5;
  }
</pre></DD>

The term/token <code> decl</code> is special.  For example, you cannot name a variable <code> decl</code>: you cannot write this: <code> decl decl</code>.  Ox will not let you use <code> decl</code> in any other way. (Why not try it and see?)</p>

<LI>Are there other special terms in Ox besides <code> decl</code>?</LI>

In computing languages special terms are called <em>keywords</em> or <em>reserved words</em>.  They act like pronouns and punctuation do in English. For example, it would be very confusing if "the" meant "tea" in English, as in "Pass the the."  English function words tend to be reserved.  The list of keywords in Ox 7.0 is
<DD><pre>
    array     default   foreach    operator   static
    break     delete    goto       parallel   string
    case      do        if         private    struct
    char      double    inline     protected  switch
    class     else      int        public     switch_single
    const     enum      matrix     return     this
    continue  extern    namespace  serial     virtual
    decl      for       new        short      while
</pre></DD>

You cannot name something in your Ox program one of these terms. If you do, your program will be rejected by Ox or it will be misinterpreted.

<LI>What does <code>#include </code> mean?</LI>

<DD><pre><span class="fname"><em><a href="./code/hello-world.ox" download>hello world.ox</a></em></span>
<object height="100" width="95%" type="text/plain" data="./code/hello-world.ox" border="1" ></object></pre></dd>

<DD>Recall our analogy to English: the executor of a to-do list will probably first scan the whole list before doing the items one by one.  </DD>
<DD>In the same way the executor of a programming language will go through your program more than once before actually executing it.  </DD>
<DD>Following the C programming language, the symbol <code> #</code> in Ox signals a "pre-compilation directive."  What that means is that <code> ExOx</code> will process items that start with <code>#</code> on its first pass (or scan) of the program.</DD>

<DD>These pre-processing directives are not requests to do something in the same sense that <code> x = 5;</code> asks that the  number 5 be assigned to a variable named <code> x</code>.   </DD>
<DD>In <code> hello world</code> the <code> #include </code> directive tells Ox to "find the file named <code> oxstd.h</code> and insert its contents here as if the programmer had typed them."  This happens on the first pass through the program.  On the second pass <code>#include ...</code> has been replaced by the contents of the included file.</DD>

<DD>The use of <code>#include</code> and a similar more complicated <code>#import</code> directive is very useful for writing computer programs that are reliable and easy to read.  </DD>
<DD>In the case above, the effect is to tell <code> ExOx</code> to make available to this program all the standard routines in the Ox language.  Because <code> hello world</code> refers to <code> println()</code> it must be declared before it is used in the program.</DD>


</OL> 
<h3><a name="s013"><LI>Basic Instinct:<br/>&emsp;Elements of An Ox Program</a></LI></h3>

<h4>Introduction</h4>

A computer program attempts to transfer a wish your clever but messy brain has into instructions for a dumb but orderly computer to do. If you are new to programming you have to learn about the different layers of symbols and meanings in any program written in a particular language. If you have already learned a language you will see how the rules of Ox compare to the languages you have learned.</p>

As with any other choice, there are tradeoffs between different programming languages. Many of these tradeoffs boil down to: <em>Pay me now or pay me later</em>.  Some languages are designed to be "easy" to learn.  Ox is not like that.  Its rules are a lot like C and C++, which were not developed to be "easy".  However, for doing economics Ox is <em>much</em> easier than many if not all other languages.</p>

This section introduces you to these overall features of an Ox program without delving into many details.
<ol class="steps">
  <li>Comments and Whitespace</li>
  <li>Identifiers</li>
  <li>Keywords and Symbols</li>
  <li>Constants and Literals</li>
  <LI>Constant Arrays and Enumerations</LI>
  <LI>Things (variables etc.)</LI>
  <LI>Statements</LI>
  <LI>Preprocessing</LI>
</ol>

Most of your time learning to program will be taken up with all the details not discussed here.  And there is a limit to how much understanding of the list above can be gained without just doing it.  So you might find it useful to simply skim this section first and return to it later if/when things go wrong.</p>

Some of these concepts include most of the meat of the program.  Others are limited but very important in making your program readable, reliable and replicable.</p>

<OL class="section">

<LI>Comments and Whitespace</LI>

A comment is text inserted into a computer program that is ignored by the computer when running the program.  In this sense, comments are completely unessential to what the program does.  However, comments <em>are</em> completely essential for you, other humans, and in some cases other computer programs to understand what your think your program does.</p>

Ox, like many languages, have two different kinds of comments.  The first kind is text that falls between two special sequences of characters, <code>/*</code> and <code>*/</code>.  Special characters that begin and end different kinds of code in a program are called <em>delimiters</em>.  
<DD><pre><code>
/* This is an Ox  comment */
<DD></code></pre>
Anything between <tt>/*</tt> and <tt>*/</tt> is considered comment in Ox. This kind of comment <em>can</em> be nested (unlike C and C++):
<DD><pre>
/*  A comment
    /* a comment inside a comment*/
*/
println("hello world");
</pre></DD>
Why would <code>/*</code> be used as a delimiter?  The reason is that <code>/*</code> is never a valid expression in mathematical expressions so it is safe for the language to use it as a special item.   The other thing to note is that these kinds of comments can include multiple lines of your program.  This allows you to expand and format your comment to make it easy to read.</p>

Anything from <tt>//</tt> to the end of the line is also comment.
<DD><pre>
// This is an Ox comment &hellip; until the end of the line
</pre></DD>
Note that this kind of comment also has a beginning and an end, but the delimiters are not symmetric as in
<code>/* &hellip; */</code> comments.  We get end-of-the-line by hitting the <tt>Enter</tt> key.  It turns out that doing that actually inserts two <em>special characters</em> into your program that are not printed.  One character says to return to the first column of the page. The other character says to create a new line.  So really these comments are delimited by <code>//  &hellip; &lt;CR&gt;&lt;LF&gt;</code>.  These comments make it easy to add an aside to your code. It also makes it easy to temporarily remove one line of code that you may later want to make operational again.
<DD><pre>
    one = cons + 1;   // comment
    /* two = cons + 1;   // comment inside a comment
    */
</pre></DD>

Some computer languages like Python treat lines of code and spaces at the start of lines as important part of the meaning of the code.  Ox follows in the tradition of older languages that do not (with a couple minor exceptions).  Each of the following code segments are the same in Ox:
<DD><pre>
println("hello world");
<HR/>
println(
"hello world"
);
<HR/>
     println(
             "hello world")
     ;
<HR/>
println(    "hello world"           );
</pre></DD>
Hopefully You think the first two are clearer because the whitespace in the later versions seem to throw in random patches of space.  You will develop your own style of programming in terms of adding or deleting whitespace.  It is important for both you and readers of your code that your style helps display the logic of the code.

<h5>Things Can Go Wrong with Comments</h5>

Comments are essential for explaining (documenting) your code.  And comments do not themselves do anything. They are removed by the process that implements or executes your code (discussed in the next chapter).  But this means that comments can cause problems.  First, you might not close a comment properly:
<DD><pre>
/* My hello world program!! /*
main() {
    println("hello world");
    }
</pre></DD>
Here <code>/*</code> does not close out the comment above (should be <code>*/</code>).  Everything past <code>main()</code> is ignored because it is still in the comment.  The other problem is a deleted end-of-line:
<DD><pre>
// Print hello.  decl h="hello";
println(h);
</pre></DD>
The <code>decl</code> statement is accidentally on the same line as the comment.  A syntax error occurs because <code>h is not declared.</code></p>

As you start to write more complicated programs make sure the <em>sophistication</em> of your comments keeps up with the code.  Notice this does not mean the <em>quantity</em> of comments should somehow expand as your code does.</p>



<LI>Identifiers</LI>

A <em>identifier</em> in Ox is the name of <q>something</q>.  The next section talks about different kinds of things in Ox.  In our programs, most identifiers will be the name of <em>variables</em> and <em>functions</em>.  As with all other languages, Ox has rules for what is a valid identifier.  In Ox, identifiers are made up of letters and digits. The first character must be a letter. Underscores (<code>_</code>) count as a letter.  Identifiers can't start with a digit because Ox will think it is a number (numbers are not identifiers).  Identifiers can't have any other special characters other than <code>_</code>, because many of these characters have special meanings.  For example, <code>+</code> means <q>addition</q>, so you can't use <code>a+b</code> as an identifier.  Ox would think you are giving an instruction: <q>add b to a</q>.  Identifiers are <em>case sensitive</em>.  So <code>abc</code> and <code>ABC</code> are two different identifiers.</p>

What about <code><q>hello</q></code>?  According to the rules above that is not an identifier because <code><q/></code> is neither a letter nor <code>_</code>.  So that is <em>not</em> an identifier.  It is a <em>constant string</em> and is not the name of something. Sometimes Ox will use strings as <em>labels</em> for rows or columns of output.  Again, that is not the same thing as an identifier.</p>


There are some other rules about identifiers, both in Ox and other languages.  For example, it would be confusing in English if someone's name was Me, or even worse me. If we read  <q>Me says he is going to the store.</q> it is hard to tell what the meaning is.  Most parents would not torture their kids by giving them such a name, even though Me is otherwise a perfectly reasonable English identifier.  Of course, poets like to play with the implicit rules of identifiers, including e e cummings and <img src="Prince.png"/>.</p>

The same is true in a programming languages: some valid identifiers are off limits to the programmer because they mean something special in the Ox language. In a programming language, such special identifiers are called <dfn>keywords</dfn> and/or <dfn>reserved words</dfn>. If you make the mistake of using an Ox keyword as an identifier it will probably create a syntax error, but Ox may have trouble telling you what the error is.</p>

<h5>Keywords in Ox</h5>
<DD><pre>
array       default     foreach     operator    static
break       delete      goto        parallel    string
case        do          if          private     struct
char        double      inline      protected   switch
class       else        int         public      switch_single
const       enum        matrix      return      this
continue    extern      namespace   serial      virtual
decl        for         new         short       while
</pre></DD>
Do not pick any of these as identifiers for things in your program.  Your code will be misinterpreted by Ox.  Ox will probably notify you of the problem.  If you try to declare a variable with one of these names it will complain (try it!). Our programs will contain only a few of these keywords, but if you look at the full Ox syntax you will see each of them plays a special role just like <q>me</q> and <q>the</q> play special roles in English.</p>

Further, there are names that are valid identifiers and not keywords that are still bad ones to use. For example, you could use <code>println</code> as an identifier because it follows the rules and is not a reserve word. But that would be a bad idea if you ever want to print something out from your code.</p>

<!--X
<LI>Run this code.  Note the error that is created.  Change the code that it prints out 5.0.</LI>
<DD><pre>
#include "oxstd.h"

main() {
	decl println=5.0;
	println(println);
	}
</pre></DD>
X-->

<LI>Constants and Literals</LI>

If you look at a well-written Ox program that does some real work you should notice that, in terms of a count of characters, most of it is comments, whitespace and identifiers.  The next most frequent components would probably be constants and literals.  These come in different flavours which should be fairly natural, although some of the distinctions may not be clear until later.</p>

First, we have already encountered a literal: <code><q>hello, world</q></code>. That is a <dfn>string constant</dfn>.  There are some details about strings best left for later since most strings in your code will be simple like <q>hello, world</q>.  Next, we have <dfn>integer constants</dfn> such as 2, -33, 99999.  A sequence of digits, with possibly a leading <code>-</code> is an integer constant.  </p>

A <dfn>double constant</dfn> has a name that won't make sense because it comes from programming concerns in past decades.  But essentially a double constant is a real number.  As text it consists of an integer part, a decimal point, a fraction part, and optionally <tt>e</tt>, <tt>E</tt>, <tt>d</tt> or <tt>D</tt> and an optionally signed integer exponent. Either the integer or the fraction part may be missing (not both); either the decimal point or the full exponent may be missing (not both).
<DD><pre>
Ways of writing 1
                        1.0     1.      0001.0      1.00000   1E0   10E-1   0.001E3
Ways of writing 1/10
                         .1     00.1    .10000      0.10000   1E-1  10E-2   0.001E2
</pre></DD>

We now encounter a first important feature of Ox as a tool in economics.  Ox understands vectors and matrices. This is not true of all languages.  For example, C has no notion of a matrix as we have, which is one of the motivations for an economics student to create a language like Ox. A <dfn>matrix constant</dfn> lists within <tt>&lt;</tt> and <tt>&gt;</tt> the elements of the matrix, row by row. Each row is delimited by a semicolon, successive elements in a row are separated by a comma. For example:
<DD><pre><code>
    < 0,     1, 2; 10, 11, 12 >

    < 0.0, 0.1, 0.2 >

    < 1100 >
</code></pre></DD>
which are respectively a 2 by 3 matrix, a 1 by 3 matrix and a 1 by 1  matrix, the first constant is:
<DD><pre>
 0    1    2
10   11   12
</pre></DD>
The comma is optional, so the first matrix constant may be written as (the semicolon is still required):
<DD><pre>
    < 0 1 2; 10 11 12 >
</pre></DD>
The index of each row is one higher than the previous row. Within each row, the column index of an element is one higher than that created with the previous element in the same row. An <em>empty matrix</em> can be written as:
<DD><pre>
    < >
</pre></DD>
At this point you might not see a reason to allow such a thing, but it turns out to be a useful when the program is going to construct a matrix bit-by-bit.  Starting with an empty matrix and then building is common in larger programs.  Further, Ox has a sophisticated way to create large and complicated matrix constants.  For someone already familiar with a similar language it would make sense to discuss these features now.  However, in this book we return to this material later.</p>

<LI>Constant Arrays and Enumerations</LI>

The thing that Ox documentation calls an <dfn>array constant</dfn> might also be called <dfn>list constant</dfn>.  Here are some examples:
<DD><pre>
    { "hello, world", "goodbye, cruel world"}

    { 12, 99.5, "pi" }

    { {"integers", -5  , 99,   0},
      {"doubles" , 22.3, -0.5   },
      {"strings" , "a" , "b"    } }
</pre></DD>
An <dfn>array constant</dfn> is a list of constants in braces <code>{&hellip;}</code>, separated by a comma. This is a <em>recursive</em> definition, because the constant can itself be an array constant as shown in the last example. It would be quite possible to do a great deal of computational economics in Ox without using ox arrays (lists).  However, lists can be very useful in more complex code and they play a role in making you output from Ox look nice.</p>

Here is an Ox array that is <em>not</em> a constant:
<DD><pre>
decl v;
{ 12, v, 99.1}
</pre></DD>
The reason is <code>v</code> is a variable (discussed below), and variables are not constant.  So certainly variables can be put in a list, it's just that this will not be a constant list.  That means it may create an error depending on the context.</p>

Ox inherits from C the notion of an enumeration or simply <code>enum</code>.  (Note that <code>enum</code> appears on the keyword list.)  An enumeration is sort of like a constant list of integers.  And it looks similar to a constant list but is different in important ways.  Another way to think of it is <code>enum</code> allows your program to give integers a meaningful name.  You might think of identifiers in an enum as <em>tags</em> or as <em>aliases</em>.
<DD>Here are three enums:<pre><code>
enum{Zero,One,Two}
enum{OFF,ON}
enum{MinusOne=-1,Zed,Three=Two+1}
enum{Error1=-2,Error2=-2,Error3=-2}
</code></pre></DD>
If these lines appear in your code, you can then use the identifiers in the enums in your code:
<DD><pre><code>
println(1," = ",One);
println("You can't do that.  Error code:",Error2);
</code></pre></DD>
In other words, <code>One</code> is now exactly the same as putting <code>1</code> in your code.  How does the enum do that?  An <code>enum{</code> starts at 0, so the first identifier you list will be associated with the integer <code>0</code>.  Then the second thing in your enum is an alias for 1, the third for 2, etc.   This is an easy way to give integers meaningful names which in turn can make your code easier to read and fix.  </p>

Notice that in the code above <code>OFF</code> is also associated with 0 and <code>ON</code> is also associated with 1.  Why allow this?  Without using enum your code may have lots of cases of the integer constant <code>0</code>.  Sometimes it will mean one thing, at another point another.  If your code changes you might change some of these 0s to 1s but keep others the same.  Further, <code>0</code> does not tell us what it means, whereas <code>OFF</code> can mean something even if it is just an alias for <code>0</code>.
<DT>Enums do not create a thing, so this code produces an error.  See for yourself</DT>
<DD><pre>
#include "oxstd.h"
enum{Five}
main() {
    Five = 5;
    }
</pre></DD>

Ox enums can do more than simply follow 0, 1, 2, &hellip;.  Each item in the list can explicitly set the integer value, as in <code>MinusOne=-1</code>.  Then Ox will quietly associate the next item in the list with the next integer, in this case it would be -1+1 = 0.  So <code>Zed</code> and <code>Zero</code> both mean 0 in the code above.  Enums can also include <em>very simple</em> arithmetic, as in the case <code>Three=Two+1</code>.</p>

One way to use enums is to actually give the same integer different names.  In the code above all the error enums equal <code>-2</code>.  This lets the code add signal or flag the same situation (an error has occurred) but in the code treat them separately.  So if later the programmer wants to treat <code>Error3</code> differently the <code>enum</code> might be change so that <code>Error3=-99</code>.  Now it will be different than the other error codes.<p/>

Ox has some built-in or pre-defined <code>enums{}</code>.  One that you should learn to use in order to make your code more reliable is:
<pre><code>enum{FALSE,TRUE}</code></pre>
In other words, your program can replace the integer 0 with <code>FALSE</code> and the integer 1 with <code>TRUE</code>.  (You do not have to include the enum definition because it is part of Ox.)  This reflects something discussed in more detail in the next chapter, that the number 0 is associated with something false and 1 with it being true.</p>

<LI><em>Things</em> Physically Exist During an Ox Program</LI>

The official Ox term for a thing is an <em>object</em>.  However, object is sometimes used to refer to one kind of thing.  We use the thing to refer to anything in your program that has a particular physical location in computer memory assigned to it while your program is running.  Most things in basic Ox programs are either a <em>variable</em> or a <em>function</em>.</p>  

It may seem strange to think of an aspect of a computer program as a physical thing. What is meant by this is that an amount of memory is associated with the <q>thing</q> in question.  Memory consists of semi-conductor bits which are actual physical locations on the memory chip.  On the other hand, in <code>enum{Off,On}</code> <code>On</code> and <code>Off</code> are not considered things because they are just tags for the numbers 0 and 1.  Before your program begins to run the Ox system it replaces those tags with the digital value of the integer.  So as your program runs <code>On</code> is not associated with a location in memory.  So it is not considered a thing (or an object in the official Ox lingo).<p/>

A thing in Ox must be <em>declared</em> before it is used (referred to).  If you try to use a thing in Ox before it is declared then Ox will complain and stop executing your program. Variables are declared with the <code>decl</code> operator.  Functions are declared by simply listing it and its arguments.  This can be done separately from the <em>definition</em>. Or it is done at the same time as the definition.
<DD><pre><code>
f(a);                       // declare a function called f but don't define it

decl y;                     // declare a variable called y

g(b) {                      // declare g at the same time as defining it.
    println("b= ",b);
    }
</code></pre></DD>

Languages like C or FORTRAN require that a variable's <em>type</em> is specified when it is declared.  If you create an integer named <code>j</code> in C then <code>j</code> will be interpreted as an integer at all times during the program.  They are examples of <em>statically typed</em> languages.  (There is a way to get a single location to be treated as more than one type.  This feature plays an important role in how Ox is written and comes up in Chapter ??.)<p/>

Ox is an example of a <em>dynamically typed</em> language.  If you <code>decl j</code> it starts as an unitialized (no type).  It can then become an integer, change to a string and end up as a function!<p/>

<h5>Basic Types of Ox Variables</h5>

Variables in Ox are <em>implicitly typed</em>, and can change type during their lifetime. The life of a variable corresponds to the level of its declaration. Its scope is the section of the program in which it can be seen. Scope and life do not have to coincide.<p/>

The basic Ox types are listed here.  Later chapters discusses several more and go into depth about the life of things.
<DL>
<DT><code>int</code>:</DT><DD>an integer, holding values like 5 or -493</DD>
<DT><code>double</code>:</DT><DD>a real number holding values like 13.2 or -3.19417.</DD>
<DT><code>matrix</code>:</DT><DD>a two-dimensional grid of real numbers which can be manipulated as a whole, such as $\matrix{1&2\cr 3&4}$.</DD>
<DT><code>string</code>:</DT><DD>zero or more characters as in <q>hello, world</q>.</DD>
<DT><code>array</code>::</DT><DD>a list of Ox things (technically, <em>references</em> to things).</DD>
</DL>

<LI>Statements</LI>

In Ox statements <b>do something</b>.  A statement is like a complete sentence in English, except statements in Ox end with a semicolon <code>;</code> rather than a period.  The reason might be obvious: periods also show up in real numbers (like 33.2) so using it to also end a statement can be confusing.  So <code>println("hello, world")</code>  is not a statement, but <code>println("hello, world");</code>.  </p>

The semicolon tells Ox it should have received all the information about what to do for this step in the program. Anything after <code>;</code> would either be the next statement or some other aspects of the program.  So when it comes time to run the program this statement will be <em>executed</em> before going past the semicolon.</p>

What makes computers and programming languages powerful is the capacity to build complex statements of out simple statements.  The most fundamental of these <em>structures</em> is a statement that will run a  statement only if some condition holds.  This is the <code>if () then </code> structure in Ox.  These are discovered later.</p>

<li>Preprocessing Directive</li>

The last element of an Ox program introduced now is ironically often at the top of the program and happens before anything else (hence the term preprocessing). The symbol <code> #</code> in Ox signals a preprocessing directive.  These are like statements except Ox statements do stuff when the program is running. Preprocessing directives happen as your Ox program is being read and understood.  We have already seen one in hello-world:
<DD><pre>#include "oxstd.h</pre></DD>
This directive tells Ox to: 
<OL class="steps">
<LI>Find the file named <code>oxstd.h</code>.  If it can't be found everything stops and the program never runs.</LI>
<LI>Insert the contents of the file as if the programmer had typed them.</LI>
</OL>
All the <code>#directives</code> are handled and then the program is read again.  So on the second pass <code>#include ...</code> has been replaced by the contents of the included file.</p>
The only other preprocessing directive seen in simple Ox programs is  <code>#import</code>.  This is like
<code>#include</code> but does more and its use is best discussed later.  It is key for writing complex Ox programs that are reliable and easy to read.  
</oL>

<h4>Summary</h4>
<ul>
  <li>Ox programs consist of whitespace, comments, preprocessing directives and code.</li>
  <li>Code includes different kinds of constants and statements</li>
  <li>Variables are the main <q>things</q> that takes on values and changes while the program runs</li>
  <li>Variables in Ox have different types, and the type of a variable can change as the program runs.</li>
  <li>Ox is a matrix-oriented language so it understands and processes matrices.</li>
</ul>
<h3><a name="s014"><LI>Express Yourself<br/>&emsp;Ox Syntax for Calculations</a></LI></h3>

<h4>Introduction</h4>

Like any computer language, you can program Ox to perform calculations like a calculator (or a spreadsheet cell formula) would.  Of course, the point of a general purpose mathematical language like Ox is to code elaborate calculations that no calculator could.  But before doing that the basics have to be available to you.</p>

<OL class="section">

<LI>Calculator-like Expressions</LI>

Consider a mathematical expression (A):
<DD>$$ { y^2 + \ln(z) \over e^{{(3 - yz)}^{-2}} }\qquad(A)$$
On a calculator you could key this expression as long as you had values to assign to the variables $y$ and $z$.  But there would be limitations:  you cannot put one expression "over" another to represent division. You would need to use "/" to do this.  And to compute $yz$ you must use "$*$" or "$\times$".  And you would use <code>^</code> to represent $y^2$.</p>

Another issue is how to implement functions like $\ln(x)$ and $e^x$.  Typically these are implemented not as operators (like <code>^</code>) but as named functions.  In the case of Ox and nearly every other language the corresponding functions are <code>log(x)</code> and <code>exp(x)</code>.</p>

With those concerns in mind, a naive translation of (A) might look this:
<DD><pre>(A).1     y^2  + log(z) / exp( (3-y*z)^(-2) ) </pre></DD>
Extra whitespace has been put in the formula to make it easier to read.  Remember two or more spaces are the same as one space, and inside expressions spaces are not important.  They could all be removed from (A).1 and the result would be the same.  Also, note that this is an Ox <em>expression</em>; it is not a <em>statement</em> yet because there is no <q>;</q> to end it.  And the expression would almost certainly be surrounded by more code to, for example, store the results in a variable.</p>

To evaluate an expression the calculator or Ox must <em>parse</em> it.  For the most part it will parse expressions the way you learn in math.  Parsing starts at the left and mostly (moving) right. This requires that operators are carried out in an order.  As Ox scans left-to-right it will decide which things get done first then second, etc.</p>

<DT>Basic Arithmetic Operators in Ox</DT>
<DD><pre>
#   Class          Symbols      Note
-----------------------------------------------
1   grouping        ()  []
2   power           ^
3   signs           - +         right to left
4   multiplicative  * /
5   additive        + -
6   assignment      =           right-to-left
</pre></DD>
Operators are listed in their order of precedence. There are several other kinds of operators in Ox discussed later.  These are the basic ones.</p>

A scientific calculator can use brackets to group values, and you could compute expression (A) in Ox as:
<DD><pre>(y^2+ln(z)) / exp( (3-y*z)^-2)</pre></DD>

For the most part, this order is exactly as you would expect from the way we write math on paper.  For example, when a left bracket "(" is found in the expression, the matching right bracket will be found and then everything inside the bracket will be evaluated before proceeding.  Other hand, when evaluating <code> x*y+z*w</code> the * comes before + so <code>x*y</code> would be computed first.  Then since * comes first again, <code>z*w</code> is computed before it is added to <code>xy</code>.  </p>

Just as in ordinary math, if you wanted <code>y+z</code> to be computed you would have to move it up in precedence by writing <code> x*(y+z)*w</code>.  However, in the case of <code> x*y^z*w</code> we see that <code>^</code> comes before * in precedence, thus this would be evaluated as <code>x(y^z)w</code>.  But it is a bit dangerous to rely on the precedence in this case since you have to be very confident that <code>^</code> comes first.  So I usually err on the safe side and write <code> x*(y^z)*w </code> rather than relying on operator precedence.</p>

Notice that <code> =</code> is just a low precedent operator (#6 in the table above).  Consider two Ox statements:<DD><pre>
1.     x = y;
2.     x + y;
</pre>
These are not completely different in terms of syntax. Both are valid statements in Ox.  And from the table we know that with <code> x = y+5;</code> that + is completed before =. So <code>y+5</code> will happen and the result will be assigned to x.  </p>

There is one thing that is very special about <code>=</code>, however.</DT> Namely, the <em>left</em> side of it must be some physical location to store the information on the right. So although <code> 4+5;</code> is not an error in Ox, <code> 4=5;</code> is.  That is because 4 is not a <q>thing</q>.  It is not a physical spot in your computer memory which can store the value 5.  So it is not a <dfn title="">left value</dfn> or <dfn title="">lvalue</dfn>.</p>

Ox has several more useful operators to help you code sophisticated mathematical procedures.  And, most importantly, Ox operators work on matrices in ways that are likely new to you even if you have do some programming before.  The ability to process matrices in complex ways is one of the most important aspects of Ox, because it makes your code simpler and more efficient.  However, like any powerful tool, these extended operators can create errors if you do not understand them before using them in your code.  These are discussed later.</p>

<li>Indexing matrices, strings and arrays</li>

To get to elements of a matrix and other things with more than one value (including strings and arrays) you have to give the <q>index</q> to the value.  In general a matrix has two indices, as in $a_{ij}$ being the element of a matrix $A$ in the ith row and jth column.  Ox does the same thing, except there is no way to use subscripts in a plain text program.  And if you just wrote <code>Aij</code> that looks like an identifier.  Instead, each index must be put inside square brackets, so <code>A[i][j]</code>.</p>

However, in Ox like many languages, indexing always starts at zero.  So the top-left element has index <code>[0][0]</code>.   A 2 &times; 3 matrix has elements:<DD>
<pre>
     [0][0]   [0][1]   [0][2]
     [1][0]   [1][1]   [1][2]
</pre></DD>

In matrix algebra terminology, a <em>vector</em> is a matrix for which one of the dimensions is 1.  Ox knows if one of the dimensions of a matrix is currently 1.   So the ith element of a 5&times;1 column vector would be indexed by <code>[i][0]</code>.  And for a row vector it would be <code>[0][i]</code>.  You can always include the <code>[0]</code> index, but you can drop it and use only one of the index brackets.  If you
<DD><pre>
v = <0; 1; 2>;
v[1] = 4;
</pre></DD>
If, however, you index a matrix with only one index Ox will print out a warning and act as if you put <code>[0]</code>.
<DD><pre>
A = <0, 1; 2, 3>;
A[1] = 4;
</pre></DD>

<li>Prefix and Postfix Incrementation</li><p>

<q>Prefix</q> means <q>placed before the thing</q>; <q>postfix</q> means <q>placed after the thing</q> and incrementation means add or subtract by one.  In first generation computer programs (like FORTRAN or COBOL) one of the most common types of statements would be
<DD><pre>
    i = i + 1;
    j = j - 1;
    </pre></DD>
This is incrementing the variable <code>i</code>.  This would typically happen inside a <em>loop</em>, a kind of complex statement introduced below.  Anything that is very common and involves the same symbol twice (here <code>i</code>) is prone to error.  The programmer might accidentally type <code>i = j + 1;</code> and not notice the mistake.  </p>

So Ox uses the same syntax as C and many other C-based languages to eliminate the need/danger of increments.  In Ox you can simply write
<DD><pre> i++; </pre></DD>
This means <q>add 1 to the current value of <code>i</code> and store it back in <code>i</code></q>.  And you can subtract 1 with <code>i--</code>.  Note that the following uses will create errors:
<DD><pre>//ERRORS  
5++;

msg = "hello";
msg++;

list = {"milk","eggs"};
list--;
</pre></DD>

You can also place the value <em>before</em> the thing to be incremented;
<DD><pre> 
++i; 
--j;
</pre></DD>

Is there a difference?  Yes, there is a difference between <code>++i</code> and <code>--i</code>.  You should
try to understand the difference yourself by running this code segment in a program:
<DD><pre>
decl i;
i = 5;
println(i);
println(i++);
println(++i);
println(i);</pre></DD>



<h4>Transpose</h4><p>

The postfix operator <tt>'</tt> takes the transpose of a matrix. It has no effect on other arithmetic types of operands.   That is, the transpose of an integer or a double is itself.  

<li>Logic and Relations</li>

Besides computing expressions computational economics needs to compare values, check for conditions based on inputs, etc.  This requires ways to carry out <em>logical</em> operations.  This requires storing the values of <code>TRUE</code> and <code>FALSE</code>.  That is, if your model does one thing if $x < y$ and another thing if $x\ge y$ then the result of the comparison has to be recorded and remembered.  </p>

One intuitive notion is that <code>FALSE</code> is like the numeric value 0.  And <code>TRUE</code> is like the numerical value 1.  This works beautifully and is the basis of Boolean logic.  However, what is the truth value of 3?  Or -22?  In Boolean logic these values cannot occur, but if we try to store truth values in, say, an Ox <code>int</code> value we might encounter such values. (Some languages have a specific type that only stores 0 and 1).  In Ox (and many other values), the rule is that <q>0 is FALSE</q> and <q>not 0 is TRUE</q>. In other words, anything but 0 is treated like TRUE.  And if you ask Ox to store a TRUE value it will store the value 1.</p>

<DT>Logic and Relational Operators in Ox</DT>
<DD><pre>
Name            Symbol       Example     Notes on Ox Value Produced
--------------------------------------------------------------------
truth value                     A       FALSE if A=0, TRUE otherwise
Equality        ==          A==B        equals 1 if A=B, 0 otherwise
Not Equal       !=          A!=B        equals 0 if A=B, 1 otherwise
Less Than       &lt;           A&lt;B
Greater Than    &gt;           A&gt;B
Less or Equal   &lt;=          A&lt;=B
Greater or Equal&gt;=          A&gt;=B

Not             !           !A          equals 1 if A=0, 1 otherwise
And             &amp;&amp;   A&amp;&amp;B            1 if A and B are TRUE, 0 otherwise
Or              ||           A||B       equals 1 if A or B are TRUE, 0 if both FALSE
</pre></DD>

What happens if <code>A</code> or <code>B</code> is a matrix?  What is the logical meaning of $A < B$ if
both sides are matrices?  These types of comparisons are explained later.



</OL>
<h3><a name="s015"><LI>A Simple Plan<br/>&emsp;Ox Syntax for Conditional and Repeated Execution</a></LI></h3>

<h4>Responding to Input</h4>

So far we have looked at very simple programs and the basic elements of the code itself.  We have seen that Ox has syntax for carrying out mathematical computation and a real understanding of matrices.  Later we see that the use of matrices in Ox goes beyond linear algebra.    However, everything so far has been similar to using a calculator to carry out calculations already determined before the program is running.  </p>

Now we introduce aspects of Ox that allow a program to be a <em>contingent plan</em> to deal with input that is not known until after the program is running. To make this easier to see and try out we need a way to provide input to the program that is not <q>hard-coded</q>.  There are many ways in Ox to read in data from files and most serious computational economics would rely on this kind of data input.  However, to emphasize reaction to input we introduce the Ox method for asking for input from the keyboard interactively.  This method is the <code>scan()</code> function.

<DD><pre><span class="fname"><em><a href="./code/hello-world.ox" download>scan.ox</a></em></span>
  <object height="100" width="95%" type="text/plain" data="./code/scan.ox" border="1"></object></pre></dd>

<mark>Note:</mark> If you run this program and nothing happens it means you have not set OxEdit to take input.  First you have <code>Run-&gt;Stop All</code> to kill the program.  Then return to the instructions given earlier for setting up OxEdit.  Then try again.</p>

There are two bits of syntax in the program that we will only discuss later, namely <code>%g</code> and <code>&amp;x</code>.  Essentially, <code>%g</code> says that the person should enter a real number (not a name or other kind of input), and <code>&amp;x</code> says to put the number entered into the variable <code>x</code>.

<OL class="section">

<li><span style="font-size:large">if (</span> <span style="font-size:x-small">I-could-read-your-mind</span> <span style="font-size:large">)</span><span style="font-size:x-small">what-a-tale-my-thoughts-could-tell</span></li>

With the ability to process numbers like a calculators the next basic element of programming is to do different things based on the value of things.  In Ox this is embodied by our first complex statement, the <code>if</code> statement.  A complex statement is one made up of two or more other statements. </p>

The simplest Ox if statement has the form
<DD><pre>if ( &laquo;condition&raquo; ) &laquo;statement&raquo;</pre></DD>.
The characters &laquo; and &raquo; are used to indicate that you do not include the actual word condition or statement.  Instead, this means a condition of your choosing and a statement of your choosing goes in that place.  Meanwhile, <code>if</code> is a <em>keyword</em> that plays the role like an operator even though it is not a symbol.  Also the round brackets are required parts of the syntax.  This kind of <em>programming structure</em> it often called <q>if-then</q> but Ox does not include <code>then</code> in the syntax.</p>

The condition is an expression that is tested for being TRUE or FALSE.  If it is TRUE then the statement is executed.  If it is FALSE then the statement is skipped and the next statement in the program is executed next.
<DD><pre>
#include "oxstd.h"
main() {
    decl x;
    scan("Enter x: %g",&x);
    if (x &lt; 1.0)
        println("x is less than 1.0");
    println("Finished");
    }    </pre></DD>
This program prints out an extra line  of output if the user enters a value less an 1.0.  Note that a statement ends with <code>;</code> so the statement that is the then part is <code>println("x is less than 1.0");</code>.  Does this mean that you can only do one thing if the condition is true?  No, because there is another way to create a complex statement using <code>{ &hellip; }</code>, which creates a statement block.
<dd><pre>
{
    statement-1;
    statement-2;
    &vellip;
}</pre>
Notice that this use of <code>{ }</code> is different than the use seen earlier to create an oxarray.  However, every program we have seen so far has used brackets in a similar way because the <code>main()</code> function is defined by the statements between the brackets that follow.</dd>

Here the brackets create a single statement from 0 or more statements.  A use of brackets to create a more complex program could look like this:
<dd><pre>
#include "oxstd.h"
main() {
    decl x;
    scan("Enter x: %g",&x);
    if (x &lt; 1.0) {
        println("x is less than 1.0");
        if (x &lt; 0.0)
           println("In fact, it is less than 0!");
        }
    println("Finished");
    }    </pre></DD>
Extra whitespace (indentation) is used to make the logic of the program more obvious to a human by indenting statements that are part of the if statement.  But the indentation does not change the meaning (the semantics) of the program.

<li>Or Else!</li>

In the simple if statement nothing happens when the condition is false.  But often we want something different to happen if the conditions is false, hence the option of adding an <code>else</code> component.  The format is <code>if (&laquo;condition&raquo;) &laquo;statement&raquo; else &laquo;statement&raquo; </code>.
<dd><pre>
    &vellip;
    scan("Enter x: %g",&x);
    if (x &lt; 1.0)
        println("x is less than 1.0");
    else
        println("x is at least as big as 1.0");
</pre></DD>
Notice that  either a <code>;</code> or a <code>}</code> must appear before <code>else</code> because the <em>then</em> part must be a complete statement.  And, of course, the <em>else</em> part can be a statement block surrounded by curly brackets.</p>

Further, the <em>else</em> part can also be another if statement:
<dd><pre>
    if (x &lt; 1.0)
        println("x is less than 1.0");
    else if (x &lt; 2.0)
        println("x lies between 1.0 and 2.0");
    else
        println("x is at least as big as 2.0");
</pre></dd>
Each <tt>else</tt> part matches the closest previous <tt>if</tt>, but it is much better to use curly brackets to make it clear which <code>if</code> each <code>else</code> goes along with:
<dd><pre>
    if (x &lt; 1.0)
        println("x is less than 1.0");
    else {
        if (x &lt; 2.0)
            println("x lies between 1.0 and 2.0");
        else
            println("x is at least as big as 2.0");
        }
</pre></dd>

<LI>The Conditional Expression <code>&hellip; ? &hellip; : &hellip;</code></LI>

One of the basic uses of <code>if()</code> is to make the value of a variable depend on some condition.  For example, perhaps the rest of the program does different things depending on whether the value of <code>x</code> entered from the keyboard is negative or not.  Rather than checking it over and over again we can define a variable that carries this information:
<DD><pre>
decl xispos;
scan("Enter x: %g",&x);
if (x &lt; 0.0)
    xispos = FALSE;
else
    xispos = TRUE;
&vellip;
if (xispos) { 
    // handle positive values
    }
else {
    // handle negative values
    }
</pre></DD>
Notice that the name of the variable <code>xispos</code> says what information that is being stored in it.  You should try to come up with names like this in your own program to make them for you and others to read them.</p>
Because setting a value of a variable based on a condition is so standard Ox has a special kind of operator to do this without using the more flexible <code>if()</code>.
<DD><pre>
xispos = x &lt; 0 ? TRUE : FALSE;
</pre></DD>
The operation is called the conditional expression and uses the symbols <code>?</code> and <code>:</code>.  If the condition (the expression before <code>?</code>) is true then it equals the expression  between <code>?</code> and <code>:</code>.  If the condition is false it equals the expression after <code>:</code>. One reason for using this instead of <code>if()</code> is that it makes it easier to see that the point is to set the value of <code>xispos</code>.  The operator can be placed in any expression.  They can be used in a chain to return 3 or more different values:
<DD><pre>&laquo;cond1&raquo; ? &laquo;val-0&raquo; 
                             : ( &laquo;cond2&raquo; ? &laquo;val-1&raquo; 
                                                     : &laquo;val-2&raquo;)</pre></DD>
Round brackets, new lines and indentation are added here to make it clearer what is happening (but as usual they are not required).  Further  <code> ? : </code> can return strings or other non-numerical values as well.


<li><span style="font-size:large">while(</span> <span style="font-size:x-small">my-guitar-gently-weeps</span> <span style="font-size:large">)</span> </li>

Armed with the <code>if()</code> statement your program can now respond dynamically to results that were not known until the program was executing.  So the <em>plans</em> your program can implement are now more interesting. But there are still very simple calculations that become tedious program.  For example,
suppose there is a vector of 3 numbers and you want to find the first element that is negative.  So if the vector is $\pmatrix{0.12&2.3&-6.5&}$ we want to print out -6.5 since the previous values were positive.  And if there are no negative values we would want to know that.</p>   

Not knowing any other syntax your code might look like this:
<DD><pre>
const decl vec = &lt;0.12; 2.3; -6.5&gt;;

decl fneg;

fneg = 0.0;     //no negative found yet.
if (vec[0]&lt;0.0) 
   fneg = vec[0];
else if (vec[1]&lt;0.0)
   fneg = vec[1];
else if (vec[2]&lt;0.0)
    fneg = vec[2];

if (fneg&lt;0.0) 
    println("first negative value =",feg);
else
    println("no negative values in vec");
</pre></DD>
Notice this is a sequence of if statements of the same form with only the element of <code>vec</code> being checked changing.  In essence we won't to keep checking while a negative value has not been encountered. It would be more elegant and more flexible if the calculation could simply repeat one statement changing the index each time.  The <code>while()</code> statement
<dd><pre>while( &laquo;condition&raquo; ) &laquo;statement&raquo;</pre></dd>

To implement the nested if statements as a while loop needs a new variable, the index into <code>vec</code> that will start at 0 then 1 then 2, but only if necessary (if a negative value has not been found yet).
<dd><pre>
fneg = 0.0;
i = 0;
while( (fneg==0.0) && (i&lt;3) ) {
    if (vec[i]<0.0) fneg = vec[i];
    ++i;
    }
if (fneg&lt;0.0)
    println("first negative value =",feg);
else
    println("no negative values in vec");
</pre></dd>

With a <code>while()</code> statement we can rethink the loop in many ways.  Note that if we get to the end of the vector with no negatives the index <code>i</code> will equal 3, because the while loop will increment i beyond the biggest index in <code>vec</code>.
<dd><pre>
i = 0;
while( (i&lt;3) && (vec[i]&ge;0.0) ) 
    ++i;
if (i&lt;3)
    println("first negative value =",vec[i]);
else
    println("no negative values in vec");
</pre></dd>

It would also be much more useful if the while loop could be used no matter what length <code>vec</code> is.  That is possible using the built in <code>rows()</code> function in Ox which returns the number of rows of a matrix.
<dd><pre>
n = rows(vec);
i = 0;
while( (i&lt;n) && (vec[i]&ge;0.0) ) ++i;
    
if (i&lt;n)
    println("first negative value =",vec[i]);
else
    println("no negative values in vec");
</pre></dd>


<li><span style="font-size:large">for (</span> <span style="font-size:x-small">the-nights</span> <span style="font-size:large">;</span> <span style="font-size:x-small">I-can't</span> <span style="font-size:large">;</span> <span style="font-size:x-small">remember</span> <span style="font-size:large">)</span></li>

Many loops in a program could be describe like this:  start with the first case; do something to it; move on to the next case and repeat until done.  Suppose that the cases to deal with are in an oxarray (a list).  For example suppose it is a list of student names in the class and we just want to print out the class roster.
Using a <code>while()</code> statement it might look like:
<dd><pre>
    decl stud, names;
    names = {"Adele","Beyonce","Celine"};
    stud = 0;
    while(stud&lt;3) {
        println(stud,". ", names[stud]);
        ++stud;
        }
</pre></dd>
Note that this loop uses the increment operator <code>++</code> discussed earlier.  As you might imagine, this kind of loop happens all the time in code.  And things can go wrong.  One of the practical problems is the following.  If many statements are in the body of the loop then the increment part may be a long way from the <code>while()</code> part.  It would be clearer if they could stay close together even when the body of the loop is long.  </p>
Because this kind of loop is so common a special loop exists in all languages to simplify it.  Here is the general syntax of a Ox for loop and the translation of the while loop into it.
<dd><pre>
for ( &laquo;initialize&raquo; ; &laquo;condition&raquo; ; &laquo;incremement&raquo; )  &laquo;statement&raquo;

            &darr;             &darr;                &darr;            &darr;

for (   stud = 0   ;    stud&lt;3    ;    ++stud  )   println(stud,". ", names[stud]);
</pre></dd>
So the <code>while</code> loop above corresponds to this <code>for()</code> loop:
<dd><pre>
for ( )
</pre></dd>
So notice that the first part initializes a <em>loop counter</em>, in this case <code>stud</code>.  The second part is the condition to check on each pass of the loop.  The first time this condition is FALSE the loop ends.  The third part is what would appear at the bottom of a while loop.  It increments or updates the condition which will be checked at the <q>top</q> of the loop.</p>

<dl>
<dt>&nbsp;&nbsp;<tt>foreach (</tt><i>element-identifier</i> <tt>in</tt> <i>collection-identifier</i><tt>)</tt>  <i>statement</i>
</dl><p>

implements a loop over all elements in the collection.

The following restrictions apply to the <tt>foreach</tt> loop:
<ul>
<li>The <i>collection-identifier</i> must be an lvalue; it can be an object member, but may not
contain an index, because that would be interpreted as the <i>foreach-index-expression</i>.
<li>The <i>element-identifier</i> and the identifiers in the <i>foreach-index-expression</i>
must be local variables
<li>The dimension of the <i>collection-identifier</i> must be fixed during the loop, but its contents may change.
<li>Assigning to the <i>element-identifier</i> does not change the <i>collection-identifier</i>.
<li>When the loop terminates, the <i>element-identifier</i> is undefined.
</ul>

The <i>foreach-index-expression:</i> part determines how the loop is performed:
<ul>
<li><tt>foreach (el in a)</tt>         --- loop over all elements (matrix, array, string), no access to iterators;
<li><tt>foreach (el in a[i][j])</tt>   --- loop over all elements of a matrix with access to iterators i and j;
<li><tt>foreach (el in a[i][])</tt>    --- loop over all rows i, with access to i;
<li><tt>foreach (el in a[][j])</tt>    --- loop over all columns j, with access to j;
<li><tt>foreach (el in a[i])</tt>      --- loop over all elements i (row/column vector, string or array).
</ul>

<p>

<LI>Other Statements Worth Knowing About</LI>

The <tt>foreach</tt> expression is used to loop over all elements in a matrix, array or string. The most simple form:
<dl>
<dt>&nbsp;&nbsp;<tt>foreach (</tt><i>element-identifier</i> <tt>in</tt> <i>collection-identifier</i><tt>)</tt>  <i>statement</i>
</dl><p>
implements a loop over all elements in the collection.

<p>The <tt>do</tt> statement executes the substatement, then repeats this as long as the test expression is nonzero (for a matrix: all elements are nonzero). The test is performed after the substatement is executed.
So for the <tt>do</tt> statement the substatement is executed one or more times, whereas for the <tt>while</tt> statement this is zero or more times.


The <tt>return</tt> statement exits the function; if it is followed by an expression, the value of the expression is returned to the caller, see <a href="#ox_syntax_RefReturn">returning values</a>.

A <tt>continue</tt> statement may only appear within an iteration statement and causes control to pass to the loop-continuation portion of the smallest enclosing iteration statement.

A <tt>break</tt> statement may only appear within an iteration statement and terminates the smallest enclosing iteration statement.

<h4>Flick-of-the Switch</h4>

A <tt>switch</tt> statement is a compact way of writing a sequence of <tt>if</tt> statements involving the same variable for comparison.  We will discuss the simpler version, the <code>switch_single</code> statement. The more flexible switch statement can be see in the Ox syntax documentation.
<DD><pre>
    switch_single ( &laquo;integer&raquo; ) {
        case &laquo;val-0&raquo; :  statement-block;
        case &laquo;val-1&raquo; :  statement-block;
        &vellip;
        case &laquo;val-k&raquo; :  statement-block;
        default : statement-block;
        }
</pre></DD>
Several things need to be pointed out.  First, instead of testing a condition for being true or false the condition is an integer value so that many different cases can be coded and treated differently.  Next, the statement requires <code>{ }</code> to follow the condition.  But because of this statement blocks inside the switch_single do not require curly brackets around them.  Next, each value of the integer condition is listed as a <code>case</code>.  So &laquo;val-0&raquo; means the first value you want to handle.  It could be -123 or 45 or whatever.  Then a colon <code>:</code> is followed by a statement block.  This would be like the <em>then</em> part of an if statement but this statement block does not have to have curly brackets around.   Ox knows the block ends once it finds another <code>case</code>.  You can code as many different cases as you need.  But there are a lot of integers.  You can say what to do for all other cases by specifying the <code>default</code> case.  That statement block will end once the right bracket that matches the one that started it all is found.
<dd><pre>
    switch_single (i) {
        case 0:
            println("zero");
        case 1:
            println("one");
        case 2:
            println("two");
        default:
            println("something other than 0, 1, or 2");
        }
</pre></dd>


</OL>
</OL>
<h2><a name="s016"><LI>Hardware</a></LI></h2>
<blockquote class="toc"><h4>Contents</h4>
<OL type="1" class="toc3"">
<LI><a href="s017.html" target="content">If 6 Was 9<br/>&emsp;A Computational Puzzle</a></LI>
<LI><a href="s018.html" target="content">Tim<br/>&emsp;Hardware for <s>Dummies</s>Economists</a></LI>
<LI><a href="s019.html" target="content">Machine Head</a></LI>
<LI><a href="s020.html" target="content">Numb3rs<br/>&emsp;Integers and Reals</a></LI>
<LI><a href="s021.html" target="content">Memento<br/>&emsp;Memory and Addresses</a></LI>
</OL>
</blockquote>
<OL  type="1" ">
<h3><a name="s017"><LI>If 6 Was 9<br/>&emsp;A Computational Puzzle</a></LI></h3>

<blockquote class="quote">
<em>Pay no attention to that man behind the curtain.</em>
<b><br>--The Wizard of Oz</br></b></blockquote>

We look at a simple Ox program that poses a puzzle about how computers do math.  The answer to the puzzle must wait for a later chapter, but the puzzle may motivate you to learn about how computers works before trusting them with your own research.</p>

<DT>Does $10x=\sum_{i=1}^{10}\ x$?</DT>
<DD><pre><span class="fname"><em><a href="./code/If6was9.ox" download>If6was9.ox</a></em></span>
<object height="400" width="95%" type="text/plain" data="./code/If6was9.ox" border="1" ></object></pre></dd>
<DT>The program does something simple twice. </DT>
<DD>A number is assigned to a variable, <code>x</code>.  </DD>
<DD>Then <var>10x</var> is compared to the value of adding <var>x</var> to itself 10 times.  </DD>
<DD>This is done first for <var>x=0.1</var> and then <var>x=0.25</var>.  </DD>
<DD>The program is supposed to print out <q>Yes</q> or <q>No</q> based on the comparison of the two expressions.</DD>

Of course, in <em>symbolic</em> mathematics the results are identical to each other.  But these operations are being carried out on a computer using digital mathematics not symbolic mathematics. The output when <code>10x.ox</code> is run is:
<DD><pre>--------------- Ox at 13:13:35 on 07-Sep-2012 ---------------

Ox Console version 6.21 (Windows/U) (C) J.A. Doornik, 1994-2011
This version may be used for academic research and teaching only<pre>
Is 2.5=10*(0.25)? Yes
Is 1.0=10*(0.10)? No</pre></dd>

<img src="img/stop_sign.png"/>
You are supposed to be surprised by this output. Please stop and be surprise for a second.<br/>&hellip;</p>

If you can explain the output you might read the next few chapters quickly.  If you cannot explain the output then as a student of economics you should be thinking, <q>Perhaps I cannot trust Ox to do arithmetic.</q> After all, if you cannot rely on adding x to itself 10 times always being the same as 10x, for all values x, then how can we rely on it to, say, find a consumption bundle at which marginal utility equals the slope of the budget line?

<p/>
Is this is a flaw in Ox, a misunderstanding of the code, or something deeper?  The short answer is that it is indeed an inherent feature of numerical math and it illustrates a danger is naively using a language like Ox. if you use Stata can verify that it will produce the same puzzling output with this interactive output

<DD><pre><span class="dt">Stata also has a 10x 'problem</span>
. scalar x = 0.25
. di 2.5==x+x+x+x+x+x+x+x+x+x
1
. sca x = 0.1
. di 1.0==x+x+x+x+x+x+x+x+x+x
0
</pre></DD>
The outputs <code>1</code> and <code>0</code> are equivalent to <q>yes</q> and <q>no</q>. (Mathematica and Maple are designed to carry out symbolic operations, so this question would not apply to them, at least when they are in symbolic mode.)</p>

The reason for this puzzling behavior turns out to be a subtle feature of rational numbers. This is a curiosity but not ultimately a major issue in programming.  It is trotted out now to motivate you to be a bit curious and a bit wary about what is happening when you use the computer to do math.  Knowing how and why this happens will not make you a great economist, but it is a lesson along the way towards doing economics on the computer.</p>

<dT>You can run this program to try different values of <var>x</var>:</dT>
<DD><pre><span class="dt">Do It Again</span>
<em><a href="./code/If6was9reprise.ox" download>If6was9reprise.ox</a></em>
<object width="95%" type="text/plain" data="./code/If6was9reprise.ox" border="1" ></object></pre></dd>

<h4>Some remarks about the Ox programs above.</h4>

In each case <code>main()</code> consists of the statements between the opening bracket (<code>{</code>) and its close (<code>}</code>). This makes <code>main()</code> a <em>function</em>, also called a <em>procedure</em>, a <em>routine</em>, and similar to things called <em>subroutines</em> and <em>methods</em>.   In these notes a function or method will usually be referred to with empty parentheses, like  <code>main()</code> instead of just <code>main</code>.  This might help the reader keep track of whether a variable or some other kind of object is being talked about rather than a function. The code inside <code>main()</code> consists of <em>statements</em>.  Ox is a kind of computer program in which the programmer tells the computer what to do in a sequence. A complete statement in Ox ends with a semicolon, <q>;</q>.</p>

The <code>if (condition) &hellip; ; else &hellip; ;</code> is a programming <em>structure</em>.   Like a function it includes other statements inside the structure.  At least two statements must appear, one after <code>if ()</code> and one after <code>else</code>.  Ox will check whether the condition inside <code>(&nbsp;)</code> is true (<code>then</code>) or not (<code>else</code>) and execute the corresponding statement.  But a <em>block</em> of statements is treated the same as a single statement. A block is created by putting statements inside curly brackets, just like <code>main()</code>.  If the logic of the program said that something should be done <code>then</code> but nothing has to happen <code>else</code>, then the program has two options.   Ox also has <code> if (condition) then </code>.  That is, you do not need to include <code>else</code> if it is not needed.  Or, you could put an empty block in your code: <code>else { }</code>.</p>

The statements that belong to <code>main()</code> and to <code>if () then else </code> are indented and preceded by four spaces, so that they appear to be inside, to belong to, <code>main()</code>.  The use of <em>indentation</em> in computer code is a simple thing that helps both you and any reader of your code to follow its logic. Later on we discuss other aspects of programming that do not affect what it does but does affect how humans can understand the code. My personal style of indentation is not the only way.  Some people may place <code>{</code> on the line after <code>main()</code> so that it is isolated and treated symmetrically with its partner <code>}</code>.   </p>

Those stylistic differences can be distracting but are less important than, say, following conventions of punctuation in English.  That's because in computer programming the syntax either reflects the programmer's intention <u>or not </u> regardless of the style of the coding. The reader of the source code can see the exact intention of the code whether if follows their preferred style or not (as long as the reader understands the computer languages rules of syntax and definition of things like <code>if () &hellip; else &hellip; </code>).  But in English punctuation and other conventions are followed in the hope of transmitting the meaning as accurately to the reader.  Unexpected notation could possibly change the meaning in the reader's mind. 

You might be surprised, or perhaps not, that computer scientists have been known to actually argue about <a href="http:://en.wikipedia.org/wiki/Indent_style">indent style</a>.</p>
The program <code>If6was9reprise.ox</code> can do much more than <code>hello world.ox</code> and in fewer lines.  It uses  an <em>iterative</em> statement  (<code>do { } while()</code>) to repeat a statement (or block of statements) more than once, which eliminates the need to have almost duplicate lines.  And it uses the conditional statement <code> A ? B : C</code> to check a condition (A) and return different values (B and C) depending on whether the condition is true or false.</p>

If the Ox code looks familiar it might be because you have already done some programming in C or other C-like languages.  This similarity was by design, but in many ways the similarities are only skin deep.  Ox is very different from C in how does things even when the programs look nearly identical and produce the same output.  More on that will be discussed later. 
</OL>

<h3><a name="s018"><LI>Tim<br/>&emsp;Hardware for <s>Dummies</s>Economists</a></LI></h3>

General purposes computers continue to grow in power, capacity and complexity.  We can safely ignore or at least delay discussion of many of these developments, but programming does require some sense of what happens when a program executes.   Just as economics uses models that are simpler than reality but hopefully capture key aspects of the situation, so for our purposes we are going to discuss a very simple computer.  </p>

The model computer we will discussed is named <em>Tim</em>, a long-forgotten cousin of the also nearly-forgotten <a href="http://en.wikipedia.org/wiki/Apple_Lisa">Lisa</a>.
<em>Tim</em> also resembles  a clone of the <a href="http://en.wikipedia.org/wiki/IBM_AT">IBM AT</a>), circa 1985.</p>

<OL class="section">

<li>Pleased to Meet Tim</li>

The basic design of Tm is shown in Figure 1 which is the kind of stylized picture that a economist programmer might have in mind as they struggle to do computational economics.  Tim is a complex electronic circuit made up of <em>semi-conductors</em>, gates that let electrical current flow through the circuit or not depending on the presence (or lack) of other electrical force.   One such location that is on/off or 0/1 is a <dfn title="Binary digIT">bit</dfn>, a binary digit. The current  being on or off  (or magnetic charge being positive or negative) at a location depending on other conditions allow the computer to represent logic (truth and falsity) and then to build from this hardware to represent numbers. </p>

<dd class="callout"><span class="dt">Figure 1. Schematic for Tim</span><p><img src="img/Tim.png" width="70%" height="70%"/></dd>

The schematic is zoomed out too far to see individual bits or gates, although some special locations are blown up to make them visible (just as highways on a map are thousands of time thicker than in reality).  Parts of the circuit are contained within an integrated chip.  Different chips are connected to each other by an electronic conductor called a <em>bus</em>,  which is conductive material that carries electrically stored information from one place on a circuit board to another.  Information travels via a flow of 0/1 (on/off) electrical states. A bus will typically carry several bits at once, which is a <em>parallel bus</em> rather than one bit at a time (a <em>serial bus</em>).  </p>

<!--<dd><pre><span class="dt">Figure 2. Kiss Me on the Bus</span></pre></dd>-->
The circuit that, say, adds two numbers together is a <em>processor</em>, and processors will be wired to carry out many different operations.  General-purpose computers contain more than one processor, including a specialized processor for, say, controlling graphical displays (the <dfn title="Graphical Processing Unit">"GPU</dfn>). <a href="#??">Chapter ??</a> discusses parallel programming, which is writing a program that controls more than one processor in order to do a task quicker than using on processor alone.  Tim has a single processor, its <defn title="the central processing unit">CPU</dfn>.  Information processed in Tim's CPU must be sent and received from other aspects of the overall computer system.</p>

The CPU is connected by a bus to <dfn title="random access memory">RAM</dfn>, with many many 0/1 states that the CPU <em>writes</em> and then retrieves (<em>reads</em>). Information in RAM typically requires an electric current to hold its state,  If the power supply is interrupted, even temporarily, RAM is wiped out and will start in an arbitrary state when power is restored.  When power is first turned on, the CPU reads basic information (<dfn title="Basic Input/Output System">BIOS</dfn>) from memory that is stable regardless of power to initialize or <em>boot</em> the system.  We can safely ignore details about booting and shutting down a computer because our programs execute when Tim is up and running smoothly.</p>

Long-term stable storage that survives with or without power is provided by a separate component, originally a "hard" drive or a "floppy" drive.  A hard drive is a spinning drum composed of densely packed magnetic cells. Information is read or written at a location as it passes under head that communicates with the CPU through a bus.   Access to information on a drive is not random: the time it takes to process a datum depends on its location, because the head must move to it.  On the other hand, information in RAM can be accessed in any order, although adjacent information is faster to retrieve (or write) than information scattered in memory.  (Your small and quiet computer-like devices use solid state technology, such as <em>flash memory</em>, to store information stably.  Although there is no disk nor drive involved in this kind of storage the words are still applied because it serves the same function that hard and <q>floppy</q> disk drives served in the past.</p>

<li>Misty water-colored memories</li>

The location of information in RAM or a drive is given by an <em>address</em>.  The address is not a number intrinsically: like everything else digital it is simply a sequence of 0s and 1s that will route the circuitry to a physical location.  An address refers to a a cell or a <dfn title="a fixed number of bits in RAM located at an addressed treated as one piece of information">word</dfn>.  Physically adjacent memory cells have logically adjacent addresses when interpreted as a number, which is why it is useful to think of addresses as numbers.  Add one to an address and you will be directed to the next location (possibly including a jump to the lowest address on the next memory chip).</p>

Humans are not good at handling long strings of 0s and 1s, so we convert the patterns into more compact forms. For example, four bits can take on 2<sup>4</sup> = 16 different values: <code>0000, 0001, 0010, 0011, &hellip;, 1111</code>.   We can convert these patterns into a decimal number by treating each place as a power of 2, just as with decimal numbers:  
<DD><pre>        
0101<sub>2</sub> = 0&times;2<sup>3</sup> + 1&times;2<sup>2</sup> + 0&times;2<sup>1</sup> + 1&times;2<sup>0</sup> = 0 + 1&times;4 + 0 + 1 =5<sub>10</sub>.</pre></DD>
When discussing different bases, the base is given  since <code>0101<sub>10</sub></code> = 101 not  5. </p>

Memory addresses on a machine can be any length necessary.  Tim has a fixed address length.  For example early PCs like Tim had 16-bit addresses.  This became 32-bit and eventually 64-bit addresses.   To think of a string like <code>0100 1011 1110 0011</code> as an address is not easy, but it is the same as <code>19427<sub>10</sub></code>, which is not too daunting.  However, the number of decimal digits required to present a string of bits is not even, because powers of 10 are not the same as powers of 2.  Four bits require 2 decimal digits to code (0 to 15), but that leaves 84 decimal numbers with no purpose, 16 to 99.  So, decimal is more compact and easier for our eyes to process than binary, but it is not a good code for summarizing strings of bits that come in powers of 2.  A code with 8 or 16 numerals works well, hence the use of <q>hexadecimal</q>. First count 0 to 9, same as decimal, then A<sub>16</sub> for 10<sub>10</sub>, B = 11<sub>10</sub>, C = 12<sub>10</sub>, D = 13<sub>10</sub>, E = 14<sub>10</sub>, F = 15<sub>10</sub>.   A single hexadecimal numeral corresponds to four bits, no more no less.  A 64-bit address is the same as 16 hexadecimal digits.  </p>

<div class="pb"></div>
<dd><pre><span class="dt">4-bits Binary, Decimal, Hexadecimal</span>
Binary        Decimal    Hexadecimal
0000            00              0
0001            01              1
0010            02              2
0011            03              3
0100            04              4
0101            05              5
0110            06              6
0111            07              7
1000            08              8
1001            09              9
1010            10              A
1011            11              B
1100            12              C
1101            13              D
1110            14              E
1111            15              F
</pre>

<pre><span class="dt">Other Terms</span>
Unit           Means                              Distinct Values (base 2)            Distinct Values (base 10)           Distinct Values (base 16)
byte          8 bits                                                  1000000                                       256                                        FF
KB             1 Kilobyte                               1000000000 bytes                             1024 bytes                              4FF bytes
MB            1 Megabyte             10000000000000000000 bytes                      1,048,576 bytes                          F FFFF bytes
GM            1 Gigabyt  10000000000000000000000000000 bytes                1,073,741,824 bytes                     4FFF FFFF bytes
</pre></dd>

A machine that handles 64-bit addresses can access 2<sup>64</sup> = 18,446,744,073,709,551,616<sub>10</sub> different words of memory.  A CPU can treat multiple words as a single entity (which is necessary for reasons not important to us).  It can for some purposes subdivide a word and access each byte or even each bit of a word individually.  This flexibility can make programs more compact because some types of information fit within a byte.  But Tim's CPU is simple.  It works on memory words. Tim uses 16 bit, or four hexadecimal digit, addressing.  And each memory cell is 64 bits (16 hex digits).  So an address on Tim might be written <code>1B9E</code>. </p>

Since we are just making up addresses and not actually wiring the circuits on Tim, addresses will have one letter to emphasize it is hexadecimal not an ordinary decimal like 9300.  Contents of the memory cell <code>1B9E</code> might look something like <tt>0000 FE99 0A32 BD01</tt>.  A space will appear every four digits, which means if an address is stored in the memory cell it will appear on its own in our notional memory contents.</p>

<DD><pre><span class="dt">Table ?.  Some Memory Addresses and Contents on Tim</span>
Address       Contents Right Now
-------------------------------------------
069A           0000 FE99 0A32 BD01
069B           0887 D066 BD01 B36E
069C           1944 0000 0000 0033
</pre></DD>

The CPU processes instructions, which might be "add these two numbers together." Where does it get the instructions and how does it know what the instruction means?  The answers since the <a href="http://en.wikipedia.org/wiki/Von_Neumann_architecture">year 1945</a> or so, are:</DT>
 <DD>"from RAM"
 <dd>and</dd>
  <DD>"because Tim's circuits are hard-wired to do so."</DD>

That is, Tim treats memory contents as both instructions as well as as data.  They are instructions because when the bit pattern is copied to the right physical location on Tim's CPU it causes the circuitry to process the bits at various locations in the CPU and RAM.  They are data when the bit pattern is copied to physical locations on Tim's CPU with circuity that will interpret them as numbers or other information.</p>

The CPU does not have circuity to process arbitrary memory cells directly, for example to add contents of address <code>069B</code> and <code>AE44</code>.   This would require direct connections to each memory cell instead of a single bus between RAM and CPU.  Instead, the instruction to add memory cell contents together must include instructions to copy the contents to locations in the CPU.  Then the contents of these location are added (following logic discussed in <a href="#??">Chapter ??</a>).  Locations on the CPU to contain data and address to work on are called <em>registers</em>, illustrated by R1 and R2 on Figure XXX.  There are many registers in a CPU, but only are few important to help understand programming.</p>

Recall a machine instruction is a sequence of 0s and 1s which may have been stored in RAM.   The CPU cannot execute instructions directly from RAM just as it cannot directly add two memory cells together.  An instruction must be copied from memory to the CPU to be executed, and it must be placed in the <dfn>IR</dfn>, the <em>instruction register</em>.  The contents of the IR dictate what happens <em>next</em> to the state of Tim's circuitry.  </p>

How does the CPU 'know' when it is done with the current instruction, and how does it know where to get the next instruction from?  As usual, there is nothing but circuitry to provide the answer.  In this case the circuity is a <em>clock</em>, which dictates what happens now and what happens next. The CPU cycle is like the parts of our brains that tell our hearts to beat and our lungs to breath.  That part of the brain is made up of the same stuff as the part that lets you read and comprehend this sentence. But it must operate independently in order to impose order.  The same is true of the instruction cycle and other cycles on a CPU: they must be semiconductor circuits, but they must be wired to move from one state to the next in very different way than the parts of the CPU that multiply numbers or compute $e^x$.  </p>

The faster the clock speed the more instructions can be carried out in the same amount of time, all else constant.  As a typical early PC Tim has a cycle 2 MHz: twelve million cycles per second.  However, a single instruction can take several cycles to complete, so the clock speed is not the same as the <em>instructions per second</em>.  Microprocessors passed the GHz point by the 2000s, nearly one thousand times the number of beats per second as Tim.  The development of multicore computers and with many changes in how instructions work the actual speed of work has gone up even more, at least in certain ways. But, like many things, these details do not change the basics required to understand what your program does.</p>

The instruction cycle dictates a sequence of actions on Tim. It relies on the <em>instruction register</em> (IR) and the <em>program counter</em>, usually denoted <q>PC</q> but here called MPC for <em>machine program counter</em>.   A basic instruction cycle might look like:
<dd class="callout"><span class="dt">Tim's Inner Instruction Cycle</span>
<OL class="section"><OL class="alg">
<LI>Go to the address currently stored in the MPC and fetch (load) the contents.  Put them in the IR.</LI>
<LI>If the instruction says to change the MPC (jump to a new address), then reset the MPC and return to 1.</LI>
<LI>Execute the instruction in the IR.  This may involve reading or writing to RAM, manipulating values in registers, etc.</LI>
<LI>Increment the MPC to the next memory cell and repeat.</LI>
</OL></OL></dd>

Notice that the default says the next instruction is in the next memory address.  If this were the only possible cycle it would be nearly impossible to re-program a computer.  But the  instruction set includes the possibility of resetting the MPC so that the sequence of instructions executed depends on the data. Most readers will understand that programs and applications execute on a computer within the context of an operating system (the OS).  The OS is simply a large collection of instructions and data.  In the old days operating systems had serious names like Unix, CP/M, AIX, and DOS.  Later OS's got names that were more descriptive like Vista or Leopard or Ice Cream Sandwich. </p>

The operating system on Tim happens to be called <em>Skyway</em>.</p>

<li>Freeze Frame: Interrupting a running program</li>

As a program, how can Skyway run at the same time as programs written to do economics (or play games or download music)?  With multiple CPUs it is possible for the OS to run on some processors while programs and apps run on other processors.  But computers seem to work the same with one CPU as with several, except perhaps faster.  How does this happen?</p>

It is an illusion that the OS operates simultaneously with other programs and applications.  An OS like Skyway is a privileged program in many ways, but it must hand over the CPU to other programs for them to do their work. The illusion is sustained because another part of Tim's CPU cycle occasionally <em>interrupts</em> whatever is the current instruction and returns control to some other location in memory.  In particular, it would return control to Skyway for a slice of time.  Skyway would carry out tasks to keep things running smoothly and when this timeslice expires control can be returned to the user's program for another time slice.</p>

<DT>An Analogy to Interrupts</DT>
<DD>This is like a rich homeowner leaving her condo once a week in order for a maid to come and clean. </DD>
<DD>The maid finishes and leaves.  The owner returns.  </DD>
<DD>If we were watching through the windows, but only occasionally and  never when the maid is working, it would appear that the homeowner is enjoying a clean house without doing anything.  </DD>
<DD>The special location that the MPC occasionally jumps to will carry out the housekeeping chores that are needed and then relinquish control again to the running program.  </DD>
<DD>It may not finish all the chores that week, but it knows that what is not done on this cycle can be done the next time it gets access to the condo.</DD>

<DT>To strain the analogy a little bit towards accuracy: </DT>
 <DD>Imagine that instead of making the homeowner leave the house while cleaning the maid could simply freeze the homeowner, like in an episode of <em>Star Trek</em>. </DD>
 <DD>When finished the maid unfreezes the homeowner who does not realize that 30 minutes have gone by.  </DD>
 <DD>The reason this analogy is better is that when two (or more) programs share the CPU on Tim only one is busy at a time.  The others are suspended temporarily; they do not have to leave and come back.  </DD>
 <DD>In fact,on Tim both the homeowner and the housekeeper get interrupted by the system.  This way the homeowner is not frozen for hours when the maid has a lot to do.  After a while the maid freezes and the homeowner wakes up and continues.</DD>

<dd class="callout"><span class="dt">Tim's Outer Instruction Cycle</span><OL class="section"><OL class="alg">
<LI>Store the current MPC in a register and then set it to a special address (start of visit by the maid).</LI>
<LI>Carry out the Inner Instruction Cycle as described above for a fixed number of clock cycles.</LI>
<LI>Retrieve the saved address and store it in the MPC.</LI>
<LI>Carry out the Inner Instruction Cycle for a fixed number of clock cycles.</LI>
<LI>Return to 1.</LI>
</OL></OL></dd>

Equipped with a CPU clock and circuits to interrupt the inner execution cycle, multiple programs can appear to run 'simultaneously' on Tim.  The outer cycle must change so that where the MPC is stored in step 1 depends on which program is being interrupted.  Then in step 3 the next running program is restored. If the last of them in the list just ran then the first one becomes the next one.  Running programs line up and wait for their slice of the clock to get things done. It only seems simultaneous because our perception of time runs so much slower than even a 1985 PC clock cycle.  The more programs currently running the slower a single program will appear to run because its slice of wall-clock time falls as more programs are added to the active list. This process is called <a href="http://en.wikipedia.org/wiki/Time-sharing">timesharing</a>, and is like the idea that several people can own a share of time-share vacation home and hire a maid to keep the place clean.</p>

As the operating system, Skyway combines the services of maid, property manager, and salesman.  It makes sure that the owners only arrive at the condo when it is clean and no one else is there. Tim's system programmers must worry over the details of how Skyway shares time with other programs.  They must also ensure that one running program cannot mess up the stuff used by another (each timeshare owner might have a locker in the condo).  From an economics programmer's point of view, the housekeeping chores of the OS and the work of other running programs can be ignored while our program is running.  To it, it is the only thing running on Tim.  But it cannot start itself, so its machine instructions must be organized so Skyway knows which address contains the first instruction of the program to cede control to the first time.  </p>

Returning to our condo analogy: the program ends when it no longer demands a slice of the timeshare.  If it leaves politely, it will remove the Do Not Disturb sign from the door and lock it as it heads to the airport. If it leaves in a hurry (perhaps something went wrong) then the maid might not know it is gone, which may ruin someone else's vacation.</p>
</OL>


<h4>Summary</h4>
<UL class="sum">
<LI>All electronic computers include processors (general and specialized), random access memory, long-term storage (disks) connected by buses, and input/output devices</LI>
<LI>Memory is stored in words that have digital addresses.  Hexadecimal notation is convenient for representing binary information stored in a number of place that is a power of 2 (such as 32 or 64 bits).</LI>
<LI>The CPU operates on an instruction cycle controlled by an electronic clock.  Instructions are stored in memory and are executed when loaded into the instruction register (IR) on the CPU.</LI>
<LI>A single action in our minds, like assign <code>y</code> the value of <code>z</code>, requires multiple machine instructions to move memory contents to and from the CPU and manipulate them inside registers.</LI>
<LI>Slices of time are shared by running applications. Timesharing is possible because the clock (and I/O devices) can interrupt the instruction cycle, forcing a running program to relinquish control of the CPU temporarily.
</LI>
</UL>

</OL> 
<h3><a name="s019"><LI>Machine Head</a></LI></h3>
<OL class="section">

<LI>Run, Run, Run</LI>
<DT>This figure gives you a sense of what happens when a user of Tim the Machine asks Skyway the operating system to start a program</DT>
<dd class="callout"><h4 align="center"><u>Run It: Starting a program.</u><p>
<img src="img/LoadPgm.png" width="70%" height="70%"/></h4></dd>

The OS (Skyway) would contain a sequence of instructions to <em>load</em> and <em>execute</em> a program. An executable program is a block of machine instructions sitting on the disk in a file. We will use the file extension <code>.exe</code> for a file on Tim's hard drive that contains executable instructions.  (The extension <code>.exe</code> is used in Windows, but Unix-based operating systems do not use an extension to denote programs).  </p>

The program our user happens to ask to run is called <code>thrash.exe</code>. The block of binary machine instructions for <code>thrash</code> must be copied from the hard drive into RAM. Skyway keeps track of parts of RAM that are not being used by itself or other running applications.  It will load <code>thrash</code> in some free memory (and then mark that memory as used so next time it won't overwrite it.) </p>

Because the OS decides where programs are copied into RAM to be executed, the instructions in <code>thrash.exe</code> could not know where it will be in memory when it executes. So An executable on disk cannot contain absolute addresses. Instead, addresses must be <em>relative</em> addresses.</p>
<dd><pre><span class="dt">Relative addressing</span>
Address       Contents                         Interpretation
--------------------------------------------------------------------------------------
D69A           0000 FE99 0A32 BD02        Top memory cell while running Base
...
D6A1           0887 D066 BD01 B36E         Go To Address  BASE+6E
...
D69C           <s>1944 FFE7 BA77 0033</s>    Random contents at program startup
                  0000 0000 0000 0000          After instruction at D6A1 has executed
</pre></dd>

Here we imagine <code>thrash</code> being loaded at address <code>D69A</code>, which will be the <code>Base</code> address.  Then the OS puts the first instruction of <code>trash</code> to execute on the list of running applications.  When its turn is up, the MPC will be loaded with that address and the program can start to execute. Somewhere in the program is an instruction that says to set the contents of a memory cell to 0.   This instruction happens to be at <code>D6A1</code>, and memory cell to set is at address 6E past <code>Base</code> (the last 8 bits of the cell contents is the relative address).  You should check my hexadecimal math to confirm that <code>BASE+6E =D69C</code> The CPU on Tim adds <code>6E</code> to base, goes to that address (<code>D69C</code>), and sets all the bits in the memory cell to 0.  The next time <code>thrash</code> runs it will surely be loaded at a different location in memory, but the relative location of the cell to clear will still be <code>6E</code> down from the base address.</p>

On Tim the addresses are 16 bits long, but the program contains relative addresses that are only 8 bits long (such <code>6E</code>).  This means that a program like <code>thrash</code> can only refer to memory cells within 2<sup>8</sup>-1 = 255 addresses of the Base.  For the programmer it does not help that there are many more memory cells than that.  Their program is limited in the amount of data it can process, without some mechanism to use more than one base address or to store longer relative addresses.  This is why a <em>program</em> running on a computer with, say, 8 Gigabytes of RAM might run out of memory well before that, perhaps after 2GB of data are used.  The machine language and the operating system only have 31 bits to store relative addresses.  <code>2<sup>30</sup> = 1GB</code>, and adding a 31st bit allows addressing over 2GB of memory cells.  The operating system can reach all of the memory because its memory registers have, say, 36 bits, which allows for <code>64GB</code> addresses.  </p>

One way the operating system can put the extra capacity in the length of the addresses to good use is to treat disk space as <em>virtual memory</em>.  That is, locations on the disk can be logically treated as addresses beyond RAM.  Disk storage is slower to access than RAM, but in return many large programs could be running at once by using virtual memory.  However, this does not change the limit on the size of memory a single program can access. When the CPU and the OS move from, say, 36 bit addressing to 64 bits, and this is accompanied by more relative address bits then it is possible for programs to process much larger amounts of data.</p>

<li>Think like a machine</li>

Does programming require you to learn the binary instruction codes on a computer?  Fortunately, no, because many ways have developed since the 1950s to let humans deal with instructions they can understand and then let something else translate that to machine instructions.</p>

For example, consider ways to set the value of one variable to the value of another.
<DD><pre><span class="dt">How do I assign <em>z</em>?  Let me enumerate the ways. </span>
English           Let y be z.
Ox or C           y = z;
Stata             gen y = z;
Unix C shell      set y = z
Pascal            y :=z;
BASIC             LET y = z
</pre>

<DT>Tim-speak for assignment</DT>
<DD>(made up binary instructions on the 16-bit address, 64-bit word machine)
<pre>
0000 FE99 0A32 BD01
0887 D066 BD01 B36E
1944 0000 0000 0033
</pre></DD>

For humans each of these statements are conceptually similar, but in the computer languages what happens on the machine is very different.  The example for Tim-speak is made up, but real computer instructions would seem even more arbitrary.  The machine instruction equivalent concept of <q>Let y be z</q> would go something like this:
<DD><pre><span class="dt"><q>Let y be z</q> in Tim-speak.</span>
Address       Contents                             Explanation
-------------------------------------------------------------------------------------------------------
069A           0000 FE99 0062 BD01          Copy contents of address Base+62 (z) to Register R1
069B           0887 D066 BD01 006E          Copy contents of R1 to memory address Base+6E (y).
069C           1944 0000 0000 0033           Set MPC to the next statement to process (at address Base+33)
</pre></DD>

It appears that <code>0000FE99</code> is the machine instruction for fetching the contents of a memory cell and placing them in a register. As humans we might give <code>0000FE99</code> a name such as <code>LoadA</code>, which is exactly the kind of thing a lower level <a href="http://en.wikipedia.org/wiki/Assembly_language">assembly language</a> for Tim-speak would refer to.
 The cell to go to (<code>0A32</code>) comes next followed by the destination, say Register R1, with a code <code>BD01</code>.  For this to happen the MPC must be pointing at <code>069A</code>.  The <code>LoadA</code> instruction would automatically increment the MPC by one, changing it from <code>069A</code> to <code>069B</code>.</p>
 
The command at the next address is <code>0887 D066</code>, which it completes the assignment by moving contents of a register, this case R1 with code <code>BD01</code> back to a memory address. We might give this instruction the mnemonic <code>StoreA</code>.  What address does it store in?  It appears to be <code>Base+6E</code>.  Finally, <code>1944 0000</code> is the command for resetting the MPC to a new address (a <code>JUMP</code> instruction).  The address to jump to <code>Base+0033</code>.</p>

<li>Or Else! (hardware version)</li>

Although computers have sped up, have more storage, and are interconnected by networks, the basic operations they perform are basically unchanged.  In fact, just a few basic instructions can support nearly everything you might think to compute.   Here is a very small set of <q>pseudo instructions</q>
<dd class="callout"><pre><span class="dt">Pseudo code for basic CPU instructions on Tim</span>

MNEMONIC        EXTRA INFO    EXPLANATION
-------------------------------------------------------------------------------------------------
STORE:          Ri ADDRj      Store content of register Ri at address stored in an register ADDRj

LOAD:           ADDRj Ri      Load contents of address stored in ADDRj into register Ri

OPERATE:                      Carry out operations (+,-,*,/,exp(),ln(),x<sup>y</sup>) on register values

IF (A) THEN {B}               If A is true, increment the MPC and continue.
                                    Otherwise, set the MPC to the address below instruction block B

GOTO            ADDR           Put the address stored in a register in the MPC and continue

STOP:                          Return control to the Operating System
</pre></dd>

An example of an actual instruction set with corresponding assembly language mnemonics is here for the famed <a href="http://koti.mbnet.fi/~atjs/mc6809/Information/6809.htm">MC609</a> chip. Beyond these instructions our simple computer would also need methods to read and write data from long-term storage and to get input and output from other devices (keyboards, monitors, etc.)  It may not be clear that such a short set of instructions can carry out complex operations.  But the key is that what instructions are executed can be made conditional on the data (the <code>IF (A) THEN (B)</code> instruction). </p>

Another way to illustrate a sequence of instructions in Tim-speak is a <em>flowchart</em>.In flow charts a test of a condition is traditionally a diamond shape &#9670;.  The possible results of the test are given by arrows out of the diamond marked <q>Yes</q> and <q>No</q> or <q>T</q> and <q>F</q>.   </p>

<dd class="callout"><h4 align="center"><u>Flowcharts for <code>If-Then</code> and <code>If-Then-Else</code> Code</u><p>
<img src="img/if-then.png" width="35%" height="35%"/>&nbsp;<img src="img/if-then-else.png" width="35%" height="35%"/>
</h4>&nbsp;</dd>

<li>Wet. Lather. Rinse. Repeat.</li>

Together with an unconditional jump to a new location (<code>GOTO</code>) instructions can be repeated.
<dd><pre><span class="dt">Loop using conditional and unconditional jump instructions</span>

         ASSIGN: R1 0
TOP      IF (R1 &lt; 50) THEN {
               <em>block of instructions to repeat</em>
               OPERATE: R1 = R1+1
               GOTO TOP
               }

</pre></dd>

This is an example of <q>pseudo code</q> which is close to what an <dfn>assembly language</dfn> program might look like.  It is a list of symbols that use the pseudo language for machine instructions along with some other features and conventions.  The program mimics what Tim would do if the sequence of instructions were executed.  A new line in the program corresponds to incrementing the MPC and executing the next instruction.  This code is simply a program <em>segment</em>.  Instructions would come before and after this to carry out the complete task.</p>

<h4>How to Loop</h4><OL class="steps">
<LI>The first thing that happens in a computer loop like this one (that does something a fixed number of times) is the setting of the <em>loop counter.</em>  Here the register <code>R1</code> is the counter.  It must be initialized before entering the loop.  And it is important that nothing inside the loop uses <code>R1</code> for any other purpose, say to store the result of adding two numbers which would wipe out the current value of the counter.</LI>
<LI>Next, the condition for doing another iteration of the loop is <em>tested</em>.
    If we have done fewer than 50 trips through this instructions the condition is true, which means that the MPC will be incremented to the next address.    </LI>
<LI>The line <em>block of instructions to repeat</em> just means put whatever instructions you want to perform 50 times here.  That could 1 instruction or 10 million instructions. This is often called the <em>body of the loop.</em></LI>
<LI>After that is done, some housekeeping is required. The loop counter is incremented since another trip has been made.  Then the MPC must be set to the address of the condition test statement.  The program illustrates this by using the label <code>TOP</code>, which is meant to be the address in memory where the machine code for <code>If (A) THEN {B}</code> is.  Note that these two housekeeping lines together with the instructions to repeat are the block of code <code>B</code>.  </LI>
<LI>So once the condition is false (on the 51st pass through the command labeled <code>TOP</code>), the code will skip all that material and set the MPC to the address of the next line in the program, whatever that is.   So the right bracket <code>}</code> is just another way of indicating an address.  What address corresponds to <code>}</code> depends on how many lines are executed.  So the part of the instruction that says <q>set the MPC to the address below B</q> cannot be completed until it is known what address is related to <code>}</code>.  That is, when the assembly language program is converted to machine instructions it will have to go back to the instruction at <code>TOP</code> and fill in the address of <code>}</code>.  </LI></OL>
<DD>&nbsp;</DD>

<h4>Getting Lost</h4>

However, from a human perspective, the pseudo code for a loop shown above is not so easy to follow, because it is not clear that the code will come back to the <code>IF () THEN</code> line 50 times.  Our eyes have to see the <code>TOP</code> label and the <code>GOTO TOP</code> command, and then initializing and incrementing of the loop counter. </p>

Using the flowchart symbol for an <em>if</em> structure we can illustrate a for loop
<dd class="callout"><h4 align="center"><u>A flowchart diagram for a loop</u><p><img src="img/Loop.png"/></h4>&nbsp;</dd>
    
This allows our eyes to visualize the branching and returning in the program.  Below the block <code>B</code> is a visual detour on the page which, if taken, always includes incrementing the loop counter and then returning to the test or condition.  In the flowchart the program is actually complete after the 50 passes, so it reaches the <code>STOP</code> symbol.</p>

In a long program there may be dozens of loops along with other tests of conditions. This means the programmer has to come up with <em>labels</em> for each loop <em>and</em> to ensure that the <code>GOTO</code> statement at the bottom refers to the correct label.  The flowchart illustrates the correct jump but one loop may be inside another and the loop labels must be kept straight. However, there is no reason that we cannot codify the idea of a loop in a higher-level programming command.</p>

That is, suppose our assembly language for Tim speak allows us to including something like:
<dd><pre>
  FOR(i=0;i<50;i=i+1) {
                block of instructions to repeat
                }</pre></dd>
This <code>FOR</code> loop is a <em>structure</em> built upon the basic Tim-speak instructions that will automatically create the loop initialization, trip count check, counter update and return to the trip count check. Another program can be written so that when this text appears in a program it replaces it with then <code>IF () THEN ... GOTO</code>.</p>

Because looping is a fundamental operation, it is has its own flowchart symbol:
<dd class="callout"><h4 align="center"><u>Flowchart for a for loop</u><p><img src="img/for-loop.png"/></h4>&nbsp;</dd>
</OL></oL>

<h4>Summary</h4>
<UL class="sum">
<li>Programming is the process of creating a block of instructions to do a task. </li>
<LI>A programming language is a tool designed to encode what a human wants the computer to do in a form the human can follow.  </LI>
<LI>The language must then be translated into machine instructions that carry out the tasks. One task or statement in a program will typically required several (perhaps dozens) of simple machine instructions. </li>
<LI>Language <em>structures</em> allow the programmer to carry out a complex task by safely using the computer's ability to jump to different machine instructions based on current contents of memory or registers.</LI>
<LI>Two of the most fundamental structures are the <em>if () then &hellip; else &hellip;</em> structure and
the <em>for-loop</em> structure</LI>
</UL>

<h3><a name="s020"><LI>Numb3rs<br/>&emsp;Integers and Reals</a></LI></h3>

<OL class="section">
<LI>Two Bits, Four Bits, Eight Bits, A Dollar</LI>

Since a computer <em>word</em> contains a finite number of bits it cannot take on any integer value.Instead, a fixed number of bits (a <em>word</em>) will be used to represent different integers as different bit patterns.  To keep these notes easy to read we will start out four bit words. Realistic word sizes are 32 and 64 bits.</p>

Four bits has 2$^4$ or 16 different values: <code>0000 0001 0010 &hellip; 1111</code>. So at most we can code 16 different integers in a four bit word.  By analogy two decimal digits can store 10$^2$=100 different values, 0, 1, &hellip; 99.<DD><details class="aside"><summary>This little piggy</summary>You may notice that we obviously adopted the decimal system because we have ten fingers.  But we can really represent 11 different values with our hands if no fingers equals 0.  So perhaps if computer geeks had been around in the Stone Age we would actually count using base 11!</details></DD>
We think of the number <code>35</code> as 3$\times 10^1$+5$\times 10^0$.  With four binary digits an computer engineer could wire arithmetic circuitry to interpret the bits as powers of two.  For example, a 4-bit word equal to <code>0101</code> would be interpreted (by hardware) as
<DD>$$0101_2 = 0\times 2^3 +1\times 2^2 +0\times 2^1 + 1\times 2^0 = 5_{10}$$</DD>
This is an example of a four bit <dfn title="">unsigned binary integer</dfn>.

<LI>What about negative numbers?</LI>

Let's first think how humans do this and then compare it to the ways developed to do it digitally.  Humans use a binary code, "+" and "-", to modify the interpretation of a number.  We allow + to be implied or the default, which means there are two different symbols for one state, "+" and "\ ".  Humans place the sign bit in the leftmost, highest valued, digit, as in $-55$ and $+55$.</p>

Naturally, a computer can store the binary sign information in a single bit: positive and negative being coded as either 0 and 1.  And it matters where in the circuitry this "sign bit" shows up since the hardware must treat it differently than a power of 2.  For our purposes we can write the sign bit as the leftmost bit just as with signed decimal numbers.  So that means that in the example above, <code>0101</code>, the leftmost 0 would not be the 2$^3$ position. The 0 could mean either positive or negative.  As it turns out, it will be treated as a plus sign.  So now we reinterpret the four bits as $0101 = (+) 1\times 2^2 + 0 + 1\times 2^0 = +5_{10}$.</p>

It is worth noting (and this will be repeated several times), the bit pattern has not changed only the interpretation of the bit pattern. The interpretation of the pattern is done by the circuitry and the CPU can have circuitry for both signed and unsigned integer arithmetic.  In fact, it does, because both interpretations of a fixed number of bits will be important.</p>

At this point, the symbolic and digital representation of integers part company. If we were to continue with the human approach computers would treat <code>1101</code> as -5$_{10}$.  That is, the sign bit turns on and changes the absolute value stored in the three other bits negative.  But, it turns out, this is <em>not</em> the best way to store negative numbers digitally.  Instead, computers use <dfn title="The coding and hardware design for signed integers">2s Complement Arithmetic</dfn>.  The negative of a number is found by switching 0s to 1s and vice versa (the complementary bit) then adding 1 to the result. The complement of a bit is to switch its value: 0 becomes 1 and 1 becomes 0. In 2s complement arithmetic, a number is negated by complementing each bit in the word and then adding 1 to it.</p>

<DT>Representing 5 and -5 in binary 2s Complement.</DT>
<DD><pre>
+5    =     0101
-5    =     1010 + 0001    =   1011
-(-5) =     0100 + 0001    =   0101    =   +5
</pre></DD>
If we carry out ordinary addition for +5 + (-5) we get what we would want. Note that in binary <code>1+1</code> equals <code>0</code> and "carry the 1".  So the 16 possible patterns of bits map into the signed integers in a wrap around fashion.  Start at 0 and go up to +7.</p>

<DT>2s Complement integers in four-bits</DT>
<DD><pre>

Decimal:     -8     -7     -6    -5    -4    -3     -2     -1      0     +1     +2     +3     +4    +5    +6    +7
2s Comp.:  1000   1001   1010  1011  1100  1101   1110   1111   0000   0001   0010   0011   0100  0101  0110  0111
</pre></DD>

<DT>5 + (-5) does equal 0.</DT>
<DD><pre>
     0 1 0 1
+    1 0 1 1
------------
 [1] 0 0 0 0
</pre></DD>

<DT>In the four bit word we get 0000.  </DT>
But there is a leading 1 that would go in the fifth bit if it existed.  But unlike our symbolic operations there is a finite number of bits, four.  The extra 1 simply disappears into the <dfn title="The term for where carried 1s from the leftmost bit in a word goes.">bit bucket</dfn>. Of course, if the word have another bit then -5 would be a different pattern and adding +5 to it would still result in 0 in the word.</p>

If we added 1 to <code>0111</code> we wrap around to <code>1000 = -8</code>.  Keep adding one to make it way back to 0.  This means that in four bits $7+1 = -8$? This is an example of <dfn title="The event of attempting to store the result of an arithmetic operation that is too large to fit in the word being used.">numeric overflow</dfn>.  The number we are trying to represent, +8, does not fit in the fixed number of bits using 2s complement of arithmetic.  So in the final value position, the extra bit overflows into the sign bit. This would be the same as if on paper we only had two places for decimal digits and we added +01 to +99.  Without the ability to magically insert a new place for 10$^2$, the final 1 that we carry over spills in to the sign column turns + into -.</p>

<LI>Float On</LI>

Understanding the coding integers, whether signed or unsigned, on a computer is fairly straightforward.  Conceptually there is not much more to it than the discussion above. Electronically, semi-conductor components are designed to code arithmetic operations on integers, which goes beyond what an economist needs to know. </p>

Things are a bit different when we ask about real numbers, an element of $\Re$, the real line. Obviously we cannot represent real numbers exactly on a computer because we only have a finite number of states, even if we used all of memory to represent a single number we are still dealing with a finite system. The digits of a irrational number like $\pi$ go on forever.  So a computer can easily represent a concept like 0 or -5 in an exact sense, but not the concept of an point on the real number line.</p>

Let's first rule out the irrational numbers like $\pi$ and just consider how we might approximate the set of rational numbers. Recall that a rational number $x$ takes the form $x = a/b$ where $a$ and $b$ are integers ($b\neq 0$). There are an infinite number of rationals in any interval, such as $[-1,+1]$.  So in the case of integers we can use 2s complement to represent all integers within a finite distance of 0 (the distance determined by the number of bits in the word).  But this is not true of the rationals, so there is no hope of being able to represent all the rationals in any interval of the real line.</p>

Before we get specific about how rationals are represented digitally, consider the fact that we would not want our digital rational numbers to be evenly spaced on the real line like the signed binary integers are.  We would want them to be closer together where we expect to do most of the computing. There is no reason to suppose that any particular calculation is going to required close approximations to numbers around, say, 10 million or -623.231529.  Instead, it makes sense that the digital approximation is best near 0, meaning that we want more digital rationals around 0 than other points on the real line.</p>

For a rational number, such as 31.94, we can always rewrite it as: $31.94 = .3194 $\times 10^2$. In this formulation the decimal place "floats" so that the first significant digit in the number, namely <code>3</code>, is in the 10$^-1$ place.  (Or you could write it as $3.194 \times 10^1$). Now notice that the rational number is coded using three integers: <em>3194, 10, and 2</em>.  These three elements of scientific notation are called the <em>mantissa</em>, the <em>base</em> and the <em>exponent</em>, respectively.  If we always use the same base then two signed integers can be used to represent any (non-repeating) decimal.  Of course, the number of bits available to store the integers limit how many different rationals can be stored this way.</p>

Thus, on computers a real number, an element of $\Re$, is approximated by a <dfn title="The code that uses 2 signed integers to represent real numbers">floating point real number (FPR)</dfn>.  In FPR the base is implicit, and is always 2. So only two signed integers code a rational, the exponent and the mantissa.
In base 10 the leading digit (the 3 in 31.94) can be anything between 1 and 9, but not 0.  But In base 2 the leading bit is always 1.  So it contains no information and therefore the leading 1 does not need to be stored. Instead, the hardware can be wired to treat the FPR as if a 1 was there without actually needing a bit to store it.</p>

<DT>31.94 as a FPR</DT>
<DD class="callout"><pre>
        3194<sub>10</sub>
      = 1100 0111 1010<sub>2</sub>
      = 1.100 0111 1010 x 2<sup>0000 1011</sup>   [decimal moves 11$_{10}$ places, which is 1011<sub>2</sub>]
      = 0 100 0111 1010 x 2<sup>0000 1011</sup>   [implicit first 1 handled by hardware]
</pre></DD>

On our model computer Tim, the exponent and mantissa are stored in a single word. The floating point hardware on the CPU treats the two parts of the word differently. So some number of bits are reserved for the signed binary integer for the mantissa and some for the signed binary integer for the exponent.  If 64 bits are in the word, and, say, 53 bits are used to store the mantissa that leaves 11 bits for the exponent.  With this assumption we can complete a FPR coding for 3194.0:</p>

<DT>31.94 as a FPR in a 64 bit word</DT>
<DD class="callout"><pre>
Base10
3194       Base 2:
         = 0 0000 0000 0000 0000 &hellip; 0000 0000 0100 0111 1010 0 00 0000 1011
           |---------------------mantissa------------------------| |--exponent--|
         = Base 16:
           0000 0000 00023 D00B
</pre></DD>

<LI>Making Flippy Floppy</LI>

In computer lingo, a <defn>FLOP</defn> is a <em>floating point operation</em>. FLOPS refers to floating point operations per second and is a way to measure how quickly a computer system can perform numerical operations.
Multiplication of FPRs is fairly easy to understand:
<DD><pre>
3194 &times; .036
=.3194 &times; 10<sup>4</sup>     &times;      .36 &times; 10<sup>-1</sup>
=.3194 &times; .36     &times;  10<sup>4+(-1)</sup>
= .114984 &times; 10<sup>3</sup></pre></DD>
In other words, FPR multiplication needs an integer multiplication and an integer addition.</p>

The distribution of FPRs on the real line depends on the number of bits in the mantissa and exponent. 
Binary integers are distributed evenly, FPRs are not. So there can be many FPRs near 0 and some FPRs much larger than the largest binary integer. There exist smallest positive and negative floating points different from zero. But note that the use of exponents in and a related number: the smallest $\epsilon > 0$ such that $1.0-\epsilon < 1.0$,  called <dfn title="A measure of how accurate arithmetic is on a computer system.  It is defined as the smallest number that if subtracted from 1.0 results in a value strictly less than 1.0.">machine precision</dfn>.</p>

We have already seen the case of integer overflow: add 1 to the biggest positive integer and you get the biggest negative integer. The idea of overflow is easy to see using decimal numbers in scientific notation:
<DD><pre>
31,940,000 + 0.0003194
= 31940000.0003194
=.3194000000031940 &times; 10<sup>8</sup></pre></DD>
That means that now suppose that 15 <em>decimal digits</em> are required to store the mantissa of the result exactly.  Note that <code>2<sup>52</sup>= 4,503,599,627,370,496</code> which is smaller than the mantissa. When 53 bits are used to store the mantissa of a FPR only 52 bits are available for the magnitude (because one bit or half of the bit patterns are used for negatives.) That means that Ox or any other standard application using current hardware could not store the result exactly.  Round-off error would occur.</p>

<DT>Perspective on this round-off error</DT>
Adding and subtracting of FPRs of very different magnitudes can lead to large round off errors, even if both of the original numbers can be stored exactly in the given number of bits. So a good idea is to try to define the <b>units</b> of the variables that appear in your program so that the magnitudes of numbers stored that will be operated on are not wildly different. But even in this case, the round-off error is still very small and the overall precisions of the calculation is still within the range Ox reports of <code>DBL_DIG = 15 = decimal digits of precision.</code> However, <em>anytime</em> a FPR operation is performed there is a potential of <dfn title="When an operation on floating point reals is not exact.">round off error</dfn>. As we will see, it is not just a case of adding numbers of wildly different magnitudes. By understanding that round-off error is always possible and avoiding some avoidable coding choices it is not a major issue for most work.</p>

<li>Overflow and Underflow</li>

<DT>Overflow occurs when an operation results in a number larger in magnitude then the FPR can store.</DT>
<DT>Underflow occurs when an operation results in a number closer to zero than the FPR can store.</DT>

In the early days of computing, these were major concerns because  the result of these operations can be unpredictable. If not handled by the hardware or software, overflow can result in a value that looks perfectly reasonable.  From then the calculations using the result are completely meaningless but there might be no way to discover this.</p>

<DT>The extreme case of overflow is trying to compute and store infinity.</DT>

<em>Symbolically:</em> $3/0$ is not a real number, although we can associate it with +$\infty$ in the "extended reals". We can also say $ln(0)= -\infty$. Note that $0\times 10^1 = 0 \times 10^2 = 10^(-1) \dots$. What this means is that there are many equivalent bit patterns in a 64 bit FPR. If hardware is built to ensure that true 0s are only stored one way, the other bit patterns that equal 0 can be used for special purposes.</p>

<em>Numerically</em>: two special bit patterns are designated (numerical) +NUM$_$\infty$ and -NUM$_\infty$.  
Hardware treats them properly, for the most part:
<DD>NUM$_\infty + x\quad=\quad $ NUM$_\infty - x \quad=\quad $ NUM$_\infty * x \quad=\quad $ NUM$_\infty \div x \quad=\quad $ NUM$_\infty$.</DD>
<DD>x/0 = NUM$_\infty$</DD>
<DD>x/NUM$_\infty$ = 0</DD>

<DT>What about $0/0$? </DT>
Even in the extended reals this is undefined, and it is misleading to assign it any value. Numerically it is assigned another special bit pattern called <dfn title="Not a Number">NaN</dfn>.  <code>NaN</code> is treated differently than numerical infinity.  1/$\infty$=0, but any operation involving <code>NaN</code> results in <code>NaN</code>.</p>

<details><summary>OOPS!</summary>
<DD class="callout"><pre><span class="fname"><em>fpr-limits.ox</em></span>
<object height="400" type="text/plain" data="./code/fpr-limits.ox" border="1" width="500" ></object></pre></dd></details>

<li>The puzzle solved.</li>

We can now explain the puzzle posed by this bit of code:
<DD><pre><span class="fname"><em>If6was9.ox</em></span>
<object height="400" type="text/plain" data="./code/If6was9.ox" border="1" ></object></pre></dd>

As you may recall, the problem is that Ox seems to conclude that $10\times 0.1 \ne 1.0$.   The first piece of the puzzle is now in place:  Ox uses floating point arithmetic and so only some real numbers can be stored exactly.  Perhaps there is "round off" error occurring.  Yes, it is round-off and it is the kind of round-off you are already familiar with! From elementary school, we learn that 
<DD><pre> 1 / 3  = 0.<span style="text-decoration: overline">3</span></pre>
That is, in base 10, the fraction 1/3 cannot be stored exactly in a finite number of places.  It is a repeating fraction. Of course, other fractions can be stored exactly, including
<pre>
1 / 10 = 0.1
1 /  4 = 0.25</pre></DD></p>

However, it turns out that whether a fraction (a rational number) is repeating or not depends on the base the number is represented in.  It turns out that 1/10 is a repeating fraction in base 2. The number <code>1.0 = 10*0.1</code> is of course stored exactly in base 2. So with 53 bits in the mantissa there will always be round-off error when operations involve 1/10.</p>

The lesson is this:  NO Operation on FPR should be considered as exact unless it is guaranteed to involve only integer values.</p>

<LI>Fuzzy Logic</LI>

To Repeat: In general, calculations carried out on FPRs should also be expected to contain round-off error. So <code>y==10*x</code> is not a safe way to check whether y=10x. Exact comparisons of values (using <code>==</code>) should not be relied on in your code, as in the case that <code>10*0.1 &neq; 1.0</code>.</p>

For typical magnitudes (not enormous or infinitesimal), FPRs have no more that 15 decimal digits of accuracy. So a safer way to test equality of FPRs might look like this:
<DD><pre>
if ( fabs(y - 10*x) < 1E-15 )
    println("Yes")
else
    println("No");
</pre></DD>
<code>fabs()</code> is Ox's absolute value function.  And Ox understands scientific notation, so <code>1E-15 = 10<sup>-15</sup></code>.  This says that if the difference between the two FPR expressions is small enough then call them equal. </p>

Ox has three built-in routines for doing this
<DD><pre>
isfeq(ma,mb);
isdotfeq(ma, mb);
</pre>
The first will compare the two arguments accounting for round-off error. It returns 1 (TRUE) if they are close enough and 0 (FALSE) otherwise.</DD>

<DD>In this sense <code>feq()</code> is a "fuzzy equality" tester. The default level of <em>fuzziness</em> is 1E-13 or 10<sup>-13</sup>. These two code segments are equivalent
<pre>
if ( fabs(y - 10*x) < 1E-13 )           if (feq(y,10*x))
    println("Yes")                          println("Yes")
else                                    else
    println("No");                          println("No");
</pre>
Further, the very useful <code>? &hellip; : &hellip; </code> operator let's you test for a condition and return a value without using <code>if() else ;</code>.  So this is also equivalent:
<pre>
println( feq(y,10*x) ? "Yes" : "No" );
</pre></DD>

</OL>
<h3><a name="s021"><LI>Memento<br/>&emsp;Memory and Addresses</a></LI></h3>

<OL class="section">

<h4>Characters and Strings</h4>

The number <code>3194</code> can be represented in computer memory as a signed or as a unsigned binary integer. In either case it would be stored in 64 bits as
<DD><pre>
3194<sub>10</sub>
    = 00000000000000000000110001111010<sub>2</sub>
    = 00000000C7A<sub>16</sub>                      //binary integer
</pre></DD>
It can also be represented as a floating point real, which would include an exponent to shift 3 digits to the right. Clearly you cannot store "T" either as an integer or a real. So as a I typed the previous point <q>3194</q> must be represented in yet another way. </p>

As with numbers, characters are stored using bits and given interpretation by code and hardware (keyboards!).  More than one code is used for characters. Most in use now are related to <defn>ASCII code</defn> developed in the 1960s.  This code uses one byte (technically 7 of 8 bits).In ASCII, <q>3194</q> is four characters (64 bits) that happen to be <dd><code>00110011 00110001 0011 1001 0011 0100</code>.</p>

ASCII was designed to represent European languages. Other character sets and special symbols must be stored differently using more bits. Thus there are extensions to ASCII such as <defn>Unicode</defn>, a 16 bit code for symbols. In Unicode if the leftmost 8 bits are zero the whole thing is interpreted as ASCII. As these these leftmost bits change from all zero other character sets are coded, such as Arabic, Cyrillic, etc.</p>

One or more characters together (such as <q>3194</q>) is usually called a <defn>string</defn>.

<li>Point Blank</li>

One of the most important aspects of machine instructions is this: 
<blockquote>
Memory contents can be interpreted (by the hardware) as the <em>address of another cell</em>.
</blockquote>

<DT>Consider Some Memory Cells in RAM</DT>
<DD><pre>
    Label       Address     Contents
    --------------------------------------------
    xmpl        0A39        0011 0011 0011 0001
                0A3A        0011 1001 0011 0100
                0A3B        0000 0000 0000 0000
                0A3C        0000 0000 0000 0000
    Score       0A3D        0000 1100 0111 1010
    Id          0A3E        0000 0000 0000 0011
    Age         0A3F        0000 0000 0000 0011
    Q           0A40        0000 1010 0011 1001
</pre>
The labels are identifiers in the human's program that is currently loaded in this part of RAM.</DD>

If we convert 4-bit groups at address <code>0A40</code> (labeled Q) into hexadecimal we get <code>0A39</code>, which happens to be the address of the first cell shown. That means that <code>Q</code> is <em>pointing</em> to another variable in the human's program named
<code>xmpl</code>.</p>

A <defn>pointer</defn> is a scalar data type containing a memory address. Hardware instructions can retrieve the pointer's content, interpret them as an address, then retrieve or manipulate the contents of the address pointed to.
    <DD><details class="aside"><summary>Technical Note</summary>In real computer languages a pointer is usually more than just an address, but a key aspect of a pointer is always a physical address of a location in memory.</details></DD>

In Ox, a <em>pointer</em> is stored in a something it calls an <code>array</code>, and a bit more precisely, an <code>oxarray</code>, which was discussed briefly as a way of storing different kinds of items in a list.
The different between a pointer and other data types (like integers, floating-point reals, etc.) is that the language will given you a way to access and manipulate the contents pointed to. </p>

In Ox, if <code>Q</code> is an  array (or what we would call a pointer in these notes) then <code>Q[0]</code> is the syntax for the content that Q points to:
<DD><pre>Q[0] = "contents of xmpl" = <code>0011 0011 0011 0001</code> = "31".</pre>
<code>Q[1]</code> means go to the address in <code>Q</code> and then drop down one cell:  <code>Q[1] = "94"</code>. </DD>

To use pointers the program must be able to get the address of a location. In Ox that involves using the <code>&amp;</code> operator:<code> &amp;xmpl = 0A39.</code> That is, <code>&amp;x</code> can be called <q>the location of x</q>.</p>

</OL>

</OL>
<h2><a name="s022"><LI>The Code-to-Execution Process</a></LI></h2>
<blockquote class="toc"><h4>Contents</h4>
<OL type="1" class="toc3"">
<LI><a href="s023.html" target="content">The Ties that Bind<br/>&emsp;When Things Happen in a Program</a></LI>
<LI><a href="s024.html" target="content">Across The Great Divide<br/>&emsp;The Two Kinds of Programming Languages</a></LI>
<LI><a href="s025.html" target="content">Run Lola Run<br/>&emsp;The Programming Cycle</a></LI>
</OL>
</blockquote>
<OL  type="1" ">
<h3><a name="s023"><LI>The Ties that Bind<br/>&emsp;When Things Happen in a Program</a></LI></h3>
<OL class="section">

<li>Introduction</li>

Some feature of a programming language and its runtime system is said to be <em>dynamic</em> if it is determined after the program starts executing.   We will use <code>RT</code> to denote running time: how long the program  has been executing in terms of total time it is in charge of the CPU, either directly or indirectly through the interpreter having charge of the CPU.   And <code>RT0</code> is the moment at which <code>RT=0</code>.  Before  <code>RT0</code> the parser, compiler, linker, and loader tasks all occur.   At <code>RT0</code> the intent of the program starts to be implemented.</p>

A <dfn>static</dfn> feature of a language occurs (or is determined) before <code>RT0</code>.  Static features do not respond to, and are not determined by, the execution of the program. They do not depend on inputs that could be differ from one run of the program to the other.  A feature is <dfn>dynamic</dfn> if it occurs or is determined after <code>RT0</code>.  For example, the length of a vector exists in the mind of the programmer even as the  code is being written.  But this does not mean it is a static feature.   If the language is dynamic the length remains an unspecified integer until some time after <code>RT0</code>.</p>

As the names suggest, if a feature is static in one language and dynamic in another, then the static language is less flexible.  But this comes at a cost: a static feature is something that can be checked and made secure before run time.  If the feature is fixed during compile time then the compiler can be sure that it is handled appropriately at all points in the program.  But if it is dynamic, a good compiler will include extra code in the object file to ensure the quantity is handled properly.</p>
  
A dynamic solution might be slower to execute because the checking has to take place as the program runs.   Or it might be less safe since a dynamic change without checks might do something that shouldn't happen, such as write over a memory cell allocated to another running program.  Operating systems are designed to stop things like that from happening, and they 'monitor' what is happening while a program is executing.  For example, on any OS you might use to do economics, the run time system will not let your program corrupt the memory cells of another running program.</p>

<LI>Static vs. Dynamic Memory Allocation.</LI>

We have already seen a case in an interpreted language that the memory a program can use for storing data can change while the program is running. But since the interpreter is a program written in a compiled language then obviously they too can allocate memory dynamically.  </Dp>

<DT>Two versions of the a C program called <code>seven</code> are given here: </DT>
<DD><pre>
seven.c                       sevenb.c
----------------------------------------------
#include &lt;stdio.h&gt;         #include &lt;stdio.h&gt;
main() {                   main() {
   int h, *d;                 int h, *d;
   h = 6;                      h = 6;
   d = malloc(1);             d = &h;
   *d = h;                    h=7;
   h = 7;                     printf(h,*d);
   printf(h, d);
   }                          }
</pre>
The first creates the sequence of memory states in Figure ??, and the modified version creates the sequence in Figure ??+1.</DD>

At <code>RT0</code> the executable <code>seven.exe</code> is in memory and starting to run.  The static variables <code>h</code> and <code>d</code> have space allocated for them.  However, note that <code>d</code> is declared with a <code>*</code> before it.  This means that it stores not an integer but a <em>pointer</em> to an integer.   For our purposes we can imagine that <code>d</code> is simply a memory cell, but in some cases more memory is store with a pointer than just the address. </p>

At <code>RT0</code> the variables are not initialized so their contents are unknown, but two constants referred to in the program are ready for use, <code>6<sub>10</sub>= 0110<sub>2</sub></code> and <code>7<sub>10</sub> = 0111<sub>2</sub></code>.  As in <code>six.c</code>, the contents of <code>h</code> are replaced by 6 as the first user instruction after <code>RT0</code>.</p>

The next statement is very C-specific, although something like it is available in nearly any language.  It calls a predefined function which asks the OS for some new dynamic memory, in this case 1 memory cell. The function returns the address of the memory cell allocated to the program, in the Figure <code>F299<sub>16</sub></code>.  Before it returns control back to <code>seven.exe</code> the run time system has ensured that the new memory cell is not being used by another program.  This address is stored at <code>d</code>, and that location is known at <code>RT0</code> because <code>d</code> is statically allocated.</p>

In <code>seven.c</code> we can write <code>h=6</code> but not <code>6=h</code>.  That is, <code>=</code> is not the symmetric mathematical operator <em>=</em>.  It is an <em>assignment</em> operator, and which side of it you are on matters.<details class="aside">The language Pascal recognizes this difference by using <code>:=</code> for assignment to distinguish it from mathematical equality.</details> 
But why can't we write <code>6=h</code> in C?  Because the left side of the assignment has to be a location in memory at runtime (although some other uses of <code>=</code> occur before <code>RT0</code>, but not the ordinary statements above.)  And <code>6</code> has no location.  </p>

It is true, and the Figures emphasize it, that the constant 6 has to be stored somewhere in the object file for this assignment to happen.  So you might think that <code>6</code> on the left side of <code>=</code> could refer to that location.  But then the contents of that address are no longer guaranteed to be constant during run time.  Suddenly, half way through execution, 6 may equal 9, a language feature that might appeal to Jimi Hendrix (ask your parents/grandparents).

<DT>Consider this segment of C code:</DT>
<DD><pre>
main() {
    int a, b, c;
    a = 5;
    b = a;
    c = a*a+3;
    }
</pre></DD>

In the first assignment what matters is the location of <code>a</code>.  But in the second assignment what matters is the <em>content</em> of the location of <code>a</code>.  But then note that in the third statement the content of <code>a</code> matters, but it enters into an expression.  That expression, <em>a*a+3</em> must be computed and stored somewhere and <em>then</em> assigned to <code>c</code>.  </p>

So the assignment operator <code>=</code> does indeed assign the contents of one location to the contents of another location. The difference is that the location of <code>a*a+3</code> is implicit.  It is temporarily used to store the result so that in the next round of program execution its contents can be copied to the <em>permanent</em> location <code>c</code>.   Once that is done, the location may be used again for temporary storage and the results of <code>a*a+3</code> are destroyed. </p>

On the other hand, the locations labeled <code>a, b, c</code> are the same locations throughout execution.  They are allowed to be place on the left side of <code>=</code>, but <code>a*a+3</code> does not refer to a fixed location and the compiler will not allow this to show up on the left side.  It is <em>not</em> a left-object, but it is a valid expression that can appear on the right side of an assignment. If it does, its value is stored in a temporary location that is controlled by the run time system and will be re-used repeatedly as scratch space.</p>

<figure>
<h4>Dynamic Memory Allocation.</h4>
<img src="img/malloc.png"/></figure>

The next expression says to get the contents of the address <code>h</code> and put them in the address <em>pointed to by the contents of address d</em>.  So the dynamic memory contents are updated.  The <em>compiler</em> allowed this to happen because it could check that <code>d</code> is <code>*int</code>.  That is, <em>where</em> <code>d</code> points to is dynamic, but <em>what </em> interpretation to give the thing it points to is <em>static</em>.  The compiler will only let <code>seven.c</code> treat <code>*d</code> as an integer. At execution no extra code has to run to ensure that the expression on the right hand side, <code>h</code>, is of type <code>int</code>, because its type is also know at compile time.  </p>

Next, the contents of <code>h</code> are changed to 7  but both the constant that it started with and the dynamic variable that was initialized with is value are left unchanged.   Finally <code>h</code> and <code>d</code> are printed to the screen.  What values should show up?</p>

Now consider <code>sevenb.c</code>.  The value of <code>d</code> is not given by a new dynamic location, but the <em>location</em> of <code>h</code>.  That is, <code>\&</code> is an unary operator (like a negative sign) that returns the address of where <code>d</code> is in memory.  This location is only known once the loader and loaded the executable into memory, but that all occurs before <code>RT0</code>, so <code>\&d</code> is static. Then <code>h</code> is changed as in the first version and both <code>h</code> and the value pointed to by <code>d</code> are printed.  Again, what shows up?</p>

<figure>
<h4>Static Memory Allocation with a Pointer.</h4>
<img src="img/mallocb.png"/></figure>

This shows that pointers do not <em>require</em> dynamic memory allocation.   The slightly different program <code>sevenb.c</code> works fully within the static memory, with <code>d</code> assigned to the address of <code>h</code> using the C operator <code>\&</code>.    The effect  of the second instruction is to place in <code>d</code> the location of the statically allocated <code>h</code>.  Also, note that the second argument to <code>printf()</code> is no longer <code>d</code> but <code>*d</code>.</p>


<li>Static vs. Dynamic Variable Size</li>

We hold off discussing different types of data until the next chapter, but consider at least a vector or list of integer values, such as <code>3, -1, 6, 8</code>.  One way to store this in C would be four variables: <code>int d0, d1, d2, d3</code>.  This is fine if the program always deals with four integers.  For example if these integers are codes for the ethnic origin of a person's grandparents then there will always be four values for any person.  In some cases the ethnicity of a grandparent is unknown or <em>missing</em>, but this could be coded with a special value like <code>-1</code>.</p>

However, now suppose that the list of integers is the ethnicity of children in classroom.  Now the number of kids may not be known until runtime.  It may be that the maximum class size is, say, 30.  So a naive programmer may write <code> int d0, ..., d29</code> (but they could not use ..., they would must list every variable).  Of course, a better solution is to store one variable <code>d</code> and have it contain the list of values.
<dd><pre>
ethnicb.c
=================
int d[30];           *int d, size;
                          scanf("%d",&size);
                          d = malloc(size);
</pre></dd>

<details class="aside"><summary>Note:</summary> How C's <code>scanf(\%d,\&size)</code> works is not important, except to say that it gets input from the user's keyboard and translates the results into an binary integer.   It then stores the result at the location sent to it, which is why <code>\&</code> appears before <code>size</code>.</details>

In the first version the length of the vector <code>d</code> is in the source code, so it is <em>static</em>.  In the second version, the size of the class is read as input after <code>RT0</code> and stored in <code>size</code>.  Then, <code>size</code> is used to allocate enough memory dynamically to store the needed vector.  The difference memory states are illustrated in Figure ??.</p>

How would the program process a single student's ethnicity? In the case of the grandparent code, the source would just use <code>d0</code> for the first grandparent.  In the classroom example, this will not work. <code>d0</code> is in the form of an identifier, so the lexical analyzer will parse it as a variable.  However, in <code>ethnic.c</code> there is no identifer with the name <code>d0</code>.  So it would be a disaster to use <code>d0</code> as a way to point to the first element of the vector <code>d</code>.   In math notation we might use <em>d<sub>0</sub></em> to denote the first element of <em>d</em>, but plain text source code cannot handle subscripts like this (and both Ox and C were developed to take plain text as the source code).  Instead, the syntax definition of both languages (and many others) says that <code>d[0]</code> refers to the first element of the vector <code>d</code>, <code>d[1]</code> to the second, etc.</p>

It is worth thinking about what <code>d[0]</code> means. Recall that <code>\&d</code> is the address of the (statically allocated) variable <code>d</code>.  And if <code>p</code> is a pointer, then <code>*p</code> is the inverse operation: go to the contents of the location of <code>p</code>, interpret those contents as an address.  Because that is an address, <code>*p</code> is a left-object as long as <code>p</code> was declared as a pointer. We can think of <code>d[</code> as similar to <code>*p</code>.  It means go to the location pointed to by the contents of <code>d</code>. But that is just step one.</p>

The next step is to evaluate the expression that appears before <code>]</code> and move down in memory that many elements of the vector.  So <code>d[0]</code> is the first element, <code>d[2*3+4]</code> is the eleventh element because the expression evaluates to <code>10</code>, so ten steps are taken starting from the first.</p>

<LI>There's Power in the Union: dynamic typing in a static language</LI>

<DT>Here are three true statements:</DT>
<OL class="steps">
<li>C is a statically typed language.</li>
<li>The Ox language interpreter is a compiled C program.</li>
<li>Ox is dynamically typed language.</li>
</OL>

In light of the discussion so far this should be confusing, because it was confusing to me.  After using Ox for a while I began to wonder how this trick was played.  I had an idea how to do it because languages like C and Pascal have a backdoor feature of their syntax that might allow this.   But I was also curious to find how it was done in Ox exactly.  It was not hard to discover this, because it is not a hidden aspect of the language, even though Ox is not an open source product. </p>

How it is done is of no interest to most users of a language like Ox.  But when learning to program it is worth discussing because it sheds light on how things work.  More importantly, understanding the trick of dynamic typing in a static language prepares us to the integrate outside resources in an Ox program.</p>

Why is C statically typed? As in the case of most static/dynamic tradeoffs, the main reasons are code efficiency and code safety.  A C compiler can ensure that during run time memory contents will contain values that have the interpretation the programmer intended, because at compile time it can does enforce the defined type of each variable.  It generates compile errors if the user tries to do something illegal with the declared type. <em>But</em>, memory contents at run time are <b>not</b> typed.  They are simply patterns of 0s and 1s and could be interpreted in half-a-dozen different ways by the CPU regardless of what the programmer thinks the contents should be. Thus, static typing of variables is a language feature not a hardware feature.

<DT>C has several basic variable types, including:</DT>
 <DD>integer, float (real), and character.  It also has pointers and multi-dimensional arrays of these basic types.  </DD>
 <DD>Further, it has a very subtle item called a <code>union</code>, which is the back door alluded to above.  </DD>

To illustrate its use, consider a model in which you have a random variable $X$ that takes on positive values and has an upper bound on its support, denoted $B$.  That is, the density of $X$ is 0 for $x $<$ 0$ and $x $>$ B$.  However, your model has two special cases:  $X$ is a continuous random variable that takes on all values in the interval [0,B]. And $X$ is a count variable that takes on only integer values [0,1,...,B-1,B]. In the continuous case $B$ could be an integer value, as in $B=6.0$, but this is different than the count case of $B=6$.</p>

<DT>The complication is that you want your code to be used for both cases. </DT>
<DD>One way to think about doing this is:
<pre>
    Version 1
----------------------
int Bdisc, IsDiscrete;
float Bcont;

...

if (IsDiscrete) {    // process X as a count variable, using Bdisc
    ...
    }
else   {  // process X as a continuous variable, using Bcont
    ...
    }
</pre></dd>

The statement <code>if (A) { } else { }</code> means to check the condition <code>A</code> during execution, and if <code>A</code> is true, then execute the statements between the first two brackets.  Otherwise (else), execute the statements in the brackets following <code>else</code>.   The integer variable <code>IsDiscrete</code> can store a True/False logical condition, because C will interpret a value of 0 as False and any other value of <code>IsDiscrete</code> as True.</p>

There is a very minor inefficiency here. In any one model either <code>Bdisc</code> or <code>Bcont</code> is not used.  That is one memory cell in RAM, which is not an issue.  But the inefficiency could be an issue if the information to be stored might be large arrays of either integer or real (<code>float</code>) values.  More importantly, this code is hard to maintain.  It has to have two different names for a concept that means only one will apply at a time.</p>

<DT><code>union</code> allows the programmer to eliminate this inefficiency:</DT>
<dd><pre>
   Version 2
-------------------------
union Bound {
     int disc;
     float cont;
     int IsDiscrete;
    }

Bound B;
if (IsDiscrete) {
    ...   B.disc   ....
    }
else   {
    ...   B.cont  ...
    }
</pre></dd>

The variable <code>B</code> is a variable of type <code>Bound</code>.  This is an example of a C <em>user-defined type</em>, and is a combination of built-in types.  The union type <code>Bound</code> contains two variables, one <code>int</code> and one <code>float</code>.  The idea is that the bound is a concept in the model (the upper bound of support of the random variable $X$).  And that concept has a property, the numerical value of the bound.  In addition, that property is either integer or real, and the difference is important for the rest of the model.  So rather than two separate variables, <code>Bdisc</code> and <code>Bcont</code>, there is one variable <code>B</code> with one of two possible values, <code>disc</code> or <code>cont</code>.</p>

The source code accesses the elements of the union using the <code>.</code> operator. <code>B.disc</code> tells the compiler to go to the memory cell referenced by <code>B</code> and then access its component named <code>disc</code>.  The key is that the C compiler will use the <em>same</em> memory location for both <code>disc</code> and <code>cont</code>.   There are <em>not</em> two separate addresses, one containing the integer value and one the float or real value.  And it will interpret the memory cell as the corresponding type depending on which variable name is used in the code. </p>

Note that, there may be multiple variables of type <code>Bound</code>.  If <code>Bound B;</code> is changed to <code>Bound B1, B2</code> then <code>B1.disc</code> would refer to one location and <code>B2.disc</code> another.  Now at a given point in the running program we could be using a continuous random variable as <code>B1</code> and a discrete one in <code>B2</code>, or two continuous random variables with different bounds, etc.</p>

Just because a program compiles and executes does not mean the results are correct or meaningful.  
<DD>For example, this C program segment<pre>
union {
    float x;
    char a;
     B;
     }
B.a = 'Q;
B.x = B.x / 2.2;
</pre>
would compile and execute but the results would not be reasonable</DD>

The programmer is saying that <code>B</code> should store the real (floating value) interpretation of the character "Q".  (Coding of characters is discussed in ???.)  Because <code>a</code> is declared a <code>char</code> variable the C compiler is happy to store "Q" in it.  Whatever binary code that means "Q", the next line says to divide it by 2.2.   The C compiler will allows this happen because <code>x</code> is declared <code>float</code>.</p>

This is a mistake, but not a compile-time error.  It is a conceptual error with the program that the C compiler cannot keep the programmer from making.  It is up to the programmer to ensure that their program is written to ensure that the contents of a <code>union</code> are properly interpreted.  Again, the memory contents are not intrinsically typed.  So the CPU is quite happy to treat the contents of <code>B.x</code> as a real number even though they correspond to a coding for the character Q.</p>

In basic C programming there is rarely a need for a <code>union</code> variable, and many programmers would never need to use it.  We have introduced <code>union</code> not as an advanced and esoteric feature but as something fundamental because it is the backdoor C provides through which Ox can be a dynamically typed language.  But the code above shows that a <code>union</code> on its own is prone to create errors that are hard to catch.  In the first example we kept track of whether the random variable was discrete or not with another variable named <code>IsDiscrete</code>.  But in a program with several such variables it would be a nuisance to have to keep track of pairs of separate variables. </p>

Instead, it is better (more convenient, less likely to create errors) to package the two aspects of the random variable together into one C variable.  This could be an array of length 2, one element for <code>IsDiscrete</code> and the other for <code>disc/cont</code>.  but the array would either have to be of base type <code>int</code> or <code>float</code>, and the second element could not be a <code>union</code>.  </p>

What we need is a <em>heterogeneous array</em>, which in C is called a <code>struct</code>, short for structure:
<dd><pre>
struct RV {
   int IsDiscrete;
   union {
     int disc;
     float cont;
      B ;
     };
   }
RV X, Y;

if (X.IsDiscrete) {
   ... X.B.disc ...
   }
else {
   ... X.B.cont ...
   }
</pre></dd>

A memory map for this is given in the below. The variables <code>X</code> and <code>Y</code> are two variables declared as type <code>RV</code>, a user-defined type that contains two memory cells. One cell is for <code>IsDiscrete</code>, which the programmer can use to keep track of which kind of random variable is being processed.  The second is <code>B</code>, the union.  Elements of a structure are also accessed with the <code>.</code> operator, as in <code>X.IsDiscrete</code>.  But note that each element of a structure refers to a unique location in memory, but in a union the same location.  So <code>X.B</code> refers to the location for the bound.   To use the bound the programmer refers either to <code>X.B.disc</code> to give the location an integer interpretation, or <code>X.B.cont</code> a real-valued interpretation.</p>

<DD class="callout"><h4>Two struct variables with a union element.</h4>
<img src="img/ustruc.png"/></DD>

Note that there are two locations labeled <code>IsDiscrete</code>, but this does not confuse the compiler because the programmer cannot directly refer to either one. The code must specify which variables <code>IsDiscrete</code> fields is being referenced.</p>

What we now have is a C program for which a random variable's type, either continuous or discrete, is determined <em>dynamically</em>.  And in one case something about the random variable is interpreted as integer, in the other case continuous.  That something is the upper bound, and it is stored in the same location regardless of the type.  </p>

Code as above allows the programmer to keep track of which interpretation to give <code>B</code> as the program executes.  This is done by tracking for every variable declared as type <code>RV</code> and indicator for whether it is discrete or not.  And, as long as the programmer is careful there is nothing that prevents <code>X</code> above from being discrete for part of the run time and continuous another time. </p>

The source code has to be written to keep track of <code>X.IsDiscrete</code> and have code such as <code> If (X.IsDiscrete) { ... } else { ... }</code>.  In the figure, after some execution time we see that <code>X</code> is currently holding a continuous random variable with upper bound 7.2 and <code>Y</code> is discrete with upper bound 6.  </p>

Again, the memory cell <code>X.B.cont</code> is not inherently in a real state.  Its contents could be interpreted as an integer but the result would be junk.  The same is true for <code>Y</code>.  The corresponding value of <code>IsDiscrete</code> allows the program to ensure there is no confusion.  And note that <code>X.IsDiscrete</code> will only be interpreted as an integer because that is its static type.</p>

<LI>Return to the original puzzle</LI>
    <blockquote><em>How does an language like Ox, which is interpreted by a C program, have dynamic types but the underlying C programm has static types?</em></blockquote>

First, in the example above the variable <code>X</code> has a static type. It is always of type <code>RV</code>.  And <code>X.B</code> is always of type  <code>union { int disc; float cont; }</code>.   What is dynamic is the interpretation of the union not the type.</p>

    <h4>Answer 1:</h4>
    <DT>Everything in Ox is stored in the underlying C code as the same (static) <code>struct</code>, which includes a <code>int</code> code for the current type and a <code>union</code> for the current type of the variable.</DT>
    <DD>The little man behind the curtain is indeed an ordinary C program, but one that exploits <code>union</code> to emulate dynamic typing, a form of Ox wizardry that it is a bit like Oz wizardry.</DD>
    <DT>This Ox code that displays the wizardry of dynamic typing:</DT>
<DD><pre>#include "oxstd.h"
main() {
  decl x;
  x = 5;  println(x);
  x = 5.0; println(x);
  x = "five"; println(x);
  x = x * x;
  }</pre></DD>
At each assignment to <code>x</code> the type of data stored in it is changed.  The Ox interpreter changes the variable type indicator for <code>x</code> and then stores the value using the appropriate element of the C <code>union</code> for storing the value. Now, consider the last line of the program.  Currently <code>x</code> is storing the word "five", and multiplication of character strings is not defined.  This will generate a runtime error, caught by the Ox interpreter.  </p>

Anytime an operation is performed the interpreter checks that the types of the operands are the correct or allowed types.  If not, it does not just let the operation happen as in <code>???.c</code> above, which would result in junk.  Instead, it ends execution and reports the error to the programmer. We do not have to guess about the way Ox, as a C program, handles data of different types  The answer is provided for us by looking at the file <code>Ox/dev/oxtypes.h</code>, which is part of the Ox development download.  In that file, you find the following:</p>

<DT>Everything in Ox is an C structure of type <code>oxvalue</code></DT>
<DD><pre>
    Full Declaration                           Trimmed Declaration
------------------------------------------------------------------
struct oxvalue                            struct oxvalue
{   int type;                             {   int type;
    union                                     union
    {                                         {
        double dval;                              double dval;
        int    ival;                              int    ival;
        struct oxstring    sval;             ...
        struct oxmatrix    mval;             } t;
        struct oxrange     rval;          }
        struct oxarray     aval;
        struct oxfunction  fval;
        struct oxclass     clval;
        struct oxfile      ioval;
	struct oxreturn	   retval;
	struct oximport	   impval;	
    } t;
}
</pre></DD>
The trimmed version simply gets rid of some lines and it should look familiar.  It is essentially the same as <code>RV</code> but with different names.  The union is called <code>t</code> not <code>B</code>, and the real variable is of type <code>double</code> not <code>float</code>. The rest of the full declaration of <code>oxvalue</code> shows that many other things in an Ox program are also stored using this <code>struct</code>.  The difference is that these other types, such as a matrix or an Ox function, require their <code>struct</code> type to keep track of their values. </p>

You can easily find the declaration of the <code>struct oxmatrix</code> to see what the C program that interprets Ox keeps track of to handle matrices.</p>

<DT>When we combine these features of C:</DT>
    <UL class="menu">
    <LI>dynamic memory allocation</LI>
    <LI>pointers such as <code>*p</code></LI>
    <LI><code>union</code></LI>
   <LI><code>struct</code></LI></UL>
  we are in a position to explain what <code>decl x;</code> means in Ox. First, the part of <code>oxl.exe</code> that parses and compiles your program finds instances of <code>decl</code>. It then knows for each variable declared a storage space has to be created.  Since this is happening during execution of <code>oxl.exe</code> the memory has to be allocated dynamically.  It cannot allocate, say a <code>*int</code> or <code>*float</code> for <code>x</code>, because this is happening before <code>RT0</code> of the Ox program.</p>
  
  Instead, it allocates a <code>*oxvalue</code>, which will enable it to store <em>anything</em> that <code>x</code> might represent during execution of the Ox program.  These allocations happen at <code>RT0</code> for declarations that are <em>global</em>.  For declarations within functions they will occur each time the function begins to execute.</p>

<h4>Answer 2</h4>

 <DT><b>Every</b> variable (every left-object) in an Ox program is a dynamically allocated structure of type <code>oxvalue</code>.</DT>
   <DD>During execution <code>oxl.exe</code> checks that the current interpretation of  the <code>union t</code> is consistent with the current reference to the variable.</DD>

This answer is one reason that "Real economists write in FORTRAN".  On each operation, such as <code>x*x+3</code>,  Ox the interpreter is executing extra machine instructions to check the current (dynamically determined) type of the operands.   In a statically typed compiled language like C these runtime checks are unnecessary.  The checking is done once at compile time.  </p>

How much this checking costs depends, and must be traded off with the advantages in terms of programming time.  Further, C code for such things as matrices operations, which may appear in a library used by the programmer, must carry out its own checking on input.  So some of the overhead in a language like Ox occurs in compiled languages as well.</p>

</OL>
<h3><a name="s024"><LI>Across The Great Divide<br/>&emsp;The Two Kinds of Programming Languages</a></LI></h3>
<OL class="section">

<LI>The Same But Different</LI>

<DT>Ox and C programs look alike and may appear to behave alike.</DT>
<DD>For example, the same output is produced if  <code>six.ox</code> is run in Ox and <code>six.c</code> is run as a C program</DD>
<DD>OxC Lady<pre>
.six.ox                              six.c
----------------------------         -----------------------------------
#include &lt;oxstd.h&gt;                   #include &lt;stdio.h&gt;;
main() {                             main() {
  	decl h;                           	int h;
  	h = 6;                              	h = 6;
	print("if ",h," was 9");            	printf("if %i was 9",h);
  	}                                 	}

-------------------------------- Output -------------------------------

if 6 was 9                            if 6 was 9
</pre></dd>

<DT>There are only three differences between the two files:</DT>
 <DD><code>decl/int</code> </DD>
 <DD><code>print/printf</code>.</DD>
 <DD><q>if </q>,h,<q> was 9" versus <q>if %i was 9 ",h</q></q>
 <DT>This is not coincidence.  Ox was designed to look like C.  </DT>
 <DT>Also, both of these programs cause certain key things to happen.  </DT>
 <DD>At some point during execution of either of them a memory cell will contain 6$_{10}$ = <code>0000  0110</code>$_{2}$.  </DD>
 <DD>And the contents will be retrieved and sent to a segment of machine instructions that communicates with the screen or disk file to produce the character "6" for you to see.</DD>

<DT>Yet, at the machine level <em>everything</em> will be completely different between executing the C and Ox versions of <code>six</code>.</DT>
 <DD>This is because they are on different sides of the <dfn>compiled</dfn> / <dfn>interpreted</dfn> divide. (Sometimes what I call <q>interpreted</q> is called <q>scripted</q>.)</DD>
 <DD>In a compiled language, source code is ultimately converted to machine instructions (compiled).  The executable instructions are stored in an <dfn>executable</dfn> file.  </DD>
 <DD>In an interpreted language your source code is never converted to machine instructions. The source code is an input (a script) to an <dfn>interpreter</dfn>, which is a program (itself interpreted or compiled) that runs the code. </DD>
 <DD>This distinction is less important than in the past, but can still be very important for writing good programs that are efficient. Understanding the implication of the difference will help you to avoid writing Ox programs that run slowly like molasses.</DD>

<LI>Compile, though your heart is breaking</LI>

<DT>C is a <dfn>compiled</dfn> language, which means &hellip;:</DT>
<DD>A C program is read as input by another program (the C compiler, such as <code>gcc</code>) &hellip;</DD>
<DD>The C compiler  (eventually) creates an <dfn>executable file</dfn> of binary machine code.  </DD>
<DD>Running the program means loading the executable file into memory and setting the computer's Machine Program Counter (MPC) to the first instruction in the code.</DD>

Compilation is to a program as digestion is to a meal. In digestion food is taken and broken down step-by-step until it can be used by the body for energy and nutrients. We will describe the process by which the C program <code>six.c</code> is converted to machine instructions that can produce output and do any other work a machine is capable of.</p>

Since C is a compiled language, there has to be a program available to do the compiling. One C compiler is known as <dfn title="The GNU C Compiler. ">gcc</dfn><details class="aside"><summary>What's GNU?</summary>GNU is a clever geeky concept, GNU is Not Unix. Look it up.</details>. 
If we are compiling on a Windows machine, then the compiler would be a program on disk with the <code>.exe</code> extension.  To do the work of compiling the program has to be RAM and be running as described earlier.  So in the diagram below the file <code>gcc.exe</code> has already been loaded into RAM and has been told to compile <code>six.c</code>.</p>

<DD class="callout"><div align="center"><h3>From Program to Executable in a Compiled Language</h3>
<img src="img/compile.png"/><blockquote>A compiler digests your source code and produces machine executions stored in an executable file.  This file can be added to running jobs list of CPU and needs no further interaction with the compiler to run.</blockquote></div></DD>

<LI>From Code to Execution</LI>
<OL class="chapter">

<LI>Lexical Analysis </LI>

Using the program=food analogy, the first step is like chewing your food.  The lexical analyzer part of the compiler takes the human readable text of the program and converts it to the essential parts called a <dfn>token list</dfn>.  The tokens include all the essential information from the program.  Once the token list is created the source code is no longer necessary (although it might kept around to point on where the program goes wrong) A key part of lexical analysis is <dfn>pre-processing</dfn>.  Pre-processing commands in C and Ox are indicated by <code>#</code>. The expression<DD>
<pre>#include &lt;stdio.h&gt;</pre>
tells the lexical analyzer to go find a file named <code>stdio.h</code> and insert its contents at the <code>include</code> as if they had been cut-and-pasted into <code>six.c</code> by the programmer. 
This makes it much easier for the programmer to avoid duplication across different programs. The C compiler will know where to find <code>stdio.h</code>. Its name <code>stdio</code> means "standard input and output" .  </DD>

If you <code>include</code> files  not directly related to the C language the lex analyzer may have trouble locating the file, causing a <code>CompileTime</code> error.  If you do find <code>stdio.h</code> and search it for "printf", you will notice a couple things.  First, it is a plain text file that you can read.  And, second, all it does is list <code>printf ()</code> followed by some text and ending in <code>}</code>.   In other words, the header file only <em>declares</em> that a function called <code>printf()</code> exists and could be used by the programmer if they want.  It does not <em>define</em> what the function does, either as C code or as binary machine instructions.  Apparently that happens somewhere else but the compiler does not need those details in order to compile your program.  It just needs to know that eventually the code for <code>printf()</code> will be available.</p>

The token list strips the code down to its essential parts.   For example, the token list would include the kind of token and its value: "main", "int", "h", and "printf" would each produce a token of type <em>identifier</em>.  Meanwhile, "(", ")", "=" and some other bits would be <em>symbol</em> tokens.  ' "if " ' converts to a <em>literal string</em>, and "6" would convert to a <em>literal integer</em>. Spaces and new lines between tokens and comments can play a role in separating tokens, so that "int h" is two tokens not one token, "inth". However, it does not matter if the are separated by one space or 50.   Once the lexical analyzer has come up with the list of tokens other aspects of the original text file are thrown out and play no further role in the meaning of the C program.</p>

Text  editors can highlight the text of the program to make it easier to read and correct. The editor is constantly scanning the text and changing the font according to the rules of the language. But an editor that knows the  syntax of a language is not a compiler.  Instead, it is a "light" version of a lexical analyzer for the language.  A compiler understands the rules of the language <em>and</em> can convert the intent of the program into machine instructions.</p>

<LI>Syntax Analysis</LI>

With the token list created the compiler can now start to figure what you want the computer to do.  First, the C language has a syntax.  A C program may not make sense because some kinds of tokens cannot follow other kinds. The sentence <q>Food dog eat</q> does not make sense in English, so English does not allow the writer to put two nouns (food and dog) in a row followed by a verb (eat). In the same way, <code>main h () {</code> could not be the second line of <code>six.c</code>.  You cannot just put two identifier tokens next to each other in proper C.</p>

Note that just as human languages, the syntax can be okay but the meaning is not.   Example, a native speaker of some languages might say in English, "Eat dog food" meaning that (a) dog eat(s) food.   But in English the subject (dog) comes before the verb (eat).  On other hand, this sentence is syntactically correct if it is a command to "Eat dog food!".  Now the token dog is not the subject but an adjective modifying food.  And in commands the verb comes first and the subject (you) is implied.  So the syntax was acceptable but the meaning was not what was intended by the speaker.</p>

In computer languages the syntax can be correct but the program fails to tell the computer to do what the programmer wishes. This kind of error can only be caught later on.  At this stage only syntax errors like <code>main h () </code> are caught.  The syntax analyzer produces a complicated object called a <dfn>parse tree</dfn>.  This tree must convert the tokens into something that means something.  For example, the parse tree will ensure that the tokens "h" that appear on lines 3, 4 and 5 all refer to the same thing.  Every identifier has to match up with something. One identifier that is mentioned but not defined is <code>printf()</code>.  If you looked at <code>stdio.h</code> you would find that it is mentioned there, but what <code>printf()</code> does is not.  In C (and in Ox) header files do not typically include code but just names of things for which the code is available somewhere.</p>

<LI>Compilation</LI>

The C compiler now arrives at the task that earns it the name.  The internally stored parse tree for the program is converted to a sequence of machine instructions to carry out the meaning of the program.  The output of this stage of the process is called <dfn>object code</dfn>, as in the "the object of a compiler is to produce machine code".  Unless we ask for another name, this sequence of instructions will be placed on disk in a file called <code>six.o</code>  The object code may only exist temporarily or it may stay on the disk to be used later.</p>

The diagram emphasizes that the object code is not understandable to humans. It is full of binary instructions specific to the computer doing the compilation.  However, the semantics of the original program mean we know a few things about the contents of the object code.  First, somewhere in the code is a memory location that will, during execution, hold the contents of the variable <code>h</code>.   And since the literal number $6$ is assigned to something in the code, this literal constants must be converted to a binary code for 6 and stored somewhere.  So somewhere in <code>six.o</code> is a memory cell with a binary representation of six.  Note that the contents of the location labeled <code>h</code> are left blank.  That is because the object code does not do the work of the program, so the contents may be set to something or may be whatever pattern of bits happen to be on the disk.</p>

Since our six program uses a built-in function called <code>printf()</code>, and since <code>stdio.h</code> does not define what the function does, the object file now has to do something about this.  So it must look for the binary instructions for <code>printf()</code> and insert them into <code>six.o</code>, <em>or</em> set up <code>six.o</code> to go and get the binary code for <code>printf()</code> when it is needed.  It turns out that it is the latter.  The binary instructions to print things out to the screen or a file in C is not included in the object file <code>six.o</code>.  In fact, <em>many</em> bits of instructions that are required for the program to run are not present in the object file.  In this sense an object file is not <em>executable</em>.  It contains machine instructions but not all necessary machine instructions. By analogy to term papers, the object file can be seen as the main body of the text but not the list of references, table of contents, title page, etc.</p>

<LI>Linking</LI>
The <dfn>linker</dfn> is the part of the job that converts the object code into an executable file.  That is, an executable file is one that can be loaded into RAM, put on the running program list and given control of the CPU.  Among other things, the linker must make the connection between the identifer <code>printf()</code> and the binary code for that function that is sitting in a file.  The name of the file is probably <em>not</em> <code>stdio.o</code>.  You may have some difficulty tracking down exactly where the object code for <code>printf()</code> is located, but that's because of issues that go beyond what we need. For our purposes let's just suppose that a file called <code>stdio.o</code> has the binary object code for each of the functions defined in <code>stdio.h</code>.  Then it is the linker that will grab that code and link it to your code, ensuring that <code>six.exe</code> will use it when it is running.</p>

</OL>

<LI>Running a Program in a Compiled Language</LI>

<UL class="ul">
<li type="disc"><code>CodeTime</code>:</li>
<DD>The programmer editing the source code. Debugging errors from other times. Coming up with test cases, input data, checking Facebook</DD>
<li><code>ParseTime</code>:</li>
<DD>Pre-processing of source code, compiler directives Parsing text and creating token list. Certain syntax errors reported</DD>
<li><code>CompileTime</code>:</li>
<DD>Creation of object code (machine readable if compiled, pseudo-code if interpreted) More subtle syntax errors found (compiler errors)</DD>
<li><code>LinkTime</code>:</li>
<DD>Creation of executable file (if language is compiled) Machine code for external functions referenced in source code located
Link errors produced if code cannot be found or is incompatible with object file</DD>
<li><code>LoadTime</code>:</li>
<DD>Executable file (if compiled) or interpreter loaded into RAM, entry point (first instruction) put on list of running programs
Runtime environment started to support execution <code>RT0</code> occurs right before first instruction is loaded into the machine/interpreter program counter (MPC)</DD>
<DD>Errors associated with memory, incompatibility</DD>
<li><code>RunTime</code>:</li>
<DD>Machine code executes <em>or</em> interpreter executes pseudo object code</DD>
<DD>Output produced</DD>
<DD>Runtime errors: bad operands, file errors, numerical exceptions, out-of-memory, dynamic type incompatibility, etc.</DD>
<DD>Output errors: results are not what is expected</DD>
</UL>

<LI>These rivers of suggestion: interpreted languages</LI>

Ox is <em>not</em> compiled.  It is an <em>interpreted</em> language, which is illustrated below.

<div align="center"><h3>From Program to Executable in an Interpreted Language</h3>
<img src="img/Interpret.png"/>
<blockquote>An interpreted language digests your source code but only to the point of pseuedo object code, which is input to the language's interpreter.  executable file.  When your program "runs" it is really the interpreter that is executing on the CPU.  If the interpreter is not only the machine your program cannot function.</blockquote></div>

Converting <code>six.ox</code> into output starts out just like <code>six.c</code>.  The program's text is parsed into tokens and then a parse tree by another running program,  <code>oxl.exe</code>.   This leads to an object file, with extension <code>.oxo</code> (Ox object file).  But the object file in an interpreted language does <em>not</em> consist of machine instructions.  It contains instructions for the <em>interpreter</em> not the machine.  The interpreter is another program that is written to carry out the instructions implied by the program.  The interpreter for Ox is also <code>oxl.exe</code>, and <code>six.oxo</code> is input that program.  In a compiled language the user's executable file takes control of the machine to do the work.  In an interpreted language the user is never in charge of the machine.</p>

Now consider what happens to <code>6</code> and <code>h</code> in <code>six.ox</code>.  First, the constant has to stored somewhere in the object file so that the interpreting part of <code>oxl.exe</code> has it ready to assign to <code>h</code>.  But there is no location in the object that will contain the contents of <code>h</code>.   The object file is loaded into memory when running, but not as machine instructions, simply input for the interpreter.  The instructions that retrieve the contents of <code>h</code> are in <code>oxl.exe</code> not linked and loaded along with a file called <code>six.exe</code>.  However, there must be some memory location for <code>h</code>, and there is.  But it cannot be inside <code>oxl.exe</code>, because at the time it was compiled and linked <code>six.ox</code> did not exist.  And the Ox interpreter inside  <code>oxl.exe</code> could not be prepared to store every conceivable variable. In fact, <code>oxl.exe</code> was created on a completely different machine than the one running it now.</p>

So <code>oxl</code> must use more memory than it started with in order to execute the commands intended by <code>six.ox</code>.  If it simply used the next location after the end of <code>oxl.exe</code> it will likely be corrupting the data or instructions of some other running program or the operating system itself.  Computer systems do not let programs do this.  They protect the locations under the control of other programs while a program is control of the CPU during its slice of the timeshare arrangement discussed earlier.  Part of this control is the <em>run time system</em> (RTS), which assists running programs.  Of course, the run time system does not operate simultaneously, since a single CPU can only perform one instruction at a time.  Instead, some tasks in a language will implicitly request the RTS the next time it is in charge of the CPU.  The running program, here <code>oxl.exe</code>, then waits until the task is done before going on with its work.  (It "waits" by turning the CPU over to the OS and every time its slice of time starts it checks whether the RTS has finished.  If not it continues to wait.</p>

Thus, to execute <code>six.ox</code> the Ox interpreter inside <code>oxl.exe</code> gets a little more memory to store <code>six.oxo</code>. And then as it is interpreting the instructions in it, a little more memory is allocated to store <code>h</code>.  This is illustrated in Figure 4 as showing the object file and the variable location in memory but beyond the bounds of <code>oxl.exe</code>.  Where they end up in memory is up to the RTS and the OS. Return to a segment of the second program presented, <code>10x.ox</code>:
<DD><pre>x = 0.25;
println( "Is 2.5=10*(0.25)? ", 2.5== x+x+x+x+x+x+x+x+x+x ? "Yes" : "No");
</pre></DD>

Note that the constants <code>0.25$_{10</code>$} and <code>2.5$_{10</code>$} must be converted to a binary representation and then stored in the <code>.oxo</code> 'file'. (The word file is quoted because the Ox object code may never become a file on disk; it may only exist in RAM while <code>oxl.exe</code> compiles and then interprets the program.) Then the pseudo-code to repeatedly add the contents of <code>x</code> appears in <code>six.oxo</code>, and at run time the Ox interpreter will execute that code.</p>

<LI>Living in the Virtual World: programming in a compiled language not required</LI>

Interpreted languages have existed for decades, but originally they were specialized and tied closely to the machine running the interpreter.  Many older economists and their hipster colleagues have a strong aversion to interpreted languages because they were restrictive and slowed by the interpreter <em>overhead</em>.  But in many domains the distinction is much less important than before, say, Java arrived.  Java  is an interpreted language, but it is designed as a general purpose language to run on all platforms, including devices that are not general purpose computers.  The interpreter of the language is known as the <em>Java Virtual Machine</em>.  Java programs can be compiled to pseudo-object code and then interpreted.  The object code can also be compiled to a machine executable file.  In many ways Java and later languages such as Python have blurred the distinction between compiled and interpreted languages.  However, within the context of intensive computation, such as a solving and estimating a large scale econometric model, the distinction still matters.  The overhead can destroy your performance, unless you are careful.  Thus, it is still a common belief that real programmers use FORTRAN or C, in part because only compiled languages intrinsically efficient.</p>

We have compared two kinds of languages, compiled and interpreted, and a nearly identical programs written in each type (C and Ox).  We have left unanswered two questions: 
<DD>what created <code>gcc.exe</code> and </DD>
<DD>what created <code>oxl.exe</code>?</DD>

Of course, the answer is a compiler created them both. The Ox parser/compiler/interpreter is itself a C program.  So Ox is both a language, which has a grammar, and a C program that implements the language.  So any work you do in Ox is really happening inside a C program.  Despite the name, the interpreter for a computer language is more like a translator of human languages rather than an interpreter.  A translator takes statements in one languages and converts them to another.  But it is free to revise the translation as it analyzes the source.  An interpreter must translate in real time. A language like an interpreter is called <em>interactive</em>.  Interactive execution is simply a case where each statement is parsed and executed before the next one in the source.  Interactive programs can 'wait' for input to come in whenever the user (human or otherwise). Ox can run in interactive mode.  The interpreter is a different executable called <em>oxli.exe</em> but is only available on Unix or with the professional version.</p>

What is the point of writing programs that are merely input to a C program? Why not simply program in C?  Do programs like Ox (or Matlab or R) exist only for people who aren't smart enough to write their own programs in C or FORTRAN? Do real economists only use FORTRAN? </p>

Some people hold this opinion, but this begs the question, why use FORTRAN?  Why not program directly in assembly language, which is just a step up from coding machine instructions directly?  The answer: using C/FORTRAN will save a programmer a great deal of coding time because of the many details they see to that are unimportant for your task.   But the same is true with compiled languages compared to languages written in them.  Languages like Ox free the programmer from dealing directly with many issues that are not important to the task at hand but must be addressed by someone at some point.</p>

<DT>An example:</DT>
<DD><pre>
decl I2 = unit(2);
println("I inverse= ",  invert(I2) );
</pre></DD>
That snippet of code in Ox would require dozens of lines of code in C to write from scratch.  C does not know what a matrix is, so the do-it-yourselfer would have to lines of code to return a  $n \times n$ identify matrix.  The C language itself has no matrix inversion code.  On the other hand, Ox knows what a matrix is , even though it is a C program, and it has routine to create a <em>I</em> so the programmer can use it for economics.  The code to invert a square matrix takes dozens of lines of C code, but in Ox it is a function ready to work for you.</p>

Users of C would typically not do what I just said.  They would not program from scratch the concept of a matrix along with the operators and functions such as matrix inverse.  They would typically rely on a library of C routines for doing math, trusting the writer of the library that they do a good job.  In one sense you can think of Ox as a math library.  (In fact, later on we show how a C programmer could use Ox functions as a math library.) But it is more than that because, as a language, an Ox programmer can translate the math 
$$V = B'AB$$ 
into the code
<pre><code>V = B' * A * B;</code></pre> 
A C math library, on the other hand, might translate the expression into something like 
<pre><code>V = matmult(matmult(transpose(B),A),B);</code></pre></p>

Use of a mathematical interpreted language like Ox (or Matlab or R) is convenient and reliable for math, but this comes with a price. If a C programmer relied on a math library their code might not look as nice but the library functions are machine code that execute directly.   In Ox the interpreter must be running while executing your more elegant Ox code.  This creates an <em>overhead</em> cost of using an interpreted language instead of compiled libraries.  Some would say that programs/languages like C or FORTRAN are inherently faster than ones like Ox or Matlab.  Later we explore this idea in detail. It is true that naive Ox code can be extremely slow compared to C code that looks very similar.  But often the naive Ox code is less elegant than better code that runs much faster, even as fast as the C version.  And the overhead cost can be as low as 0 compared to native C code, and <code>RunTime</code> overhead does not account for the <code>CodeTime</code> overhead created by using code that is farther from the mathematical statement of the problem.</p>
</OL>

<h4>Summary</h4>

<UL class="sum">
<li>Computer languages are either <em>compiled</em> (ultimately creates machine instructions) or <em>interpreted</em> (run by another program); some interpreted languages are <em>interactive</em>.}</li>

<li>Both kinds of languages go through the same stages of digestion, but the nature of the <em>object</em> files are quite different.</li>

<li>Executable files for a compiled language contain machine code for the program and code segments referred to by the program and stored in library files.</li>

<li>Programs can ask for and receive more memory as they are running.  This is <em>dynamic memory allocation</em>, and it can only work because the operating system provides real-time support for executing programs, called
 <em>the run time system.</em></li>

<li>Interpreted languages include <em>overhead</em> because the instructions are not executed directly by the CPU but by another running program, the interpreter.  <b>Some</b> tasks take much longer to do in an interpreted language than in an interpreted language.  But not <b>all</b> tasks take longer and in some cases an interpreted language can execute a task much <b>faster</b> than a compiled language. (The details of these speed comparisons are covered in Chapter ??)}</li>

</UL>
<h3><a name="s025"><LI>Run Lola Run<br/>&emsp;The Programming Cycle</a></LI></h3>
<blockquote class="quote"><em>There has never been an unexpectedly short debugging period in the history of computers.</em><br><b>--Steven Levy</b></br></blockquote>

<DT>A programmer is a human trying to do a machine's job.</DT>
  <DD>Unlike the instruction cycle, which occurs in the blink of an eye, the programming cycle occurs at our time scale.  </DD>
  <DD>In the cycle, the programmer (or programmers) repeatedly modifies human-readable code.  The hope is that the code can be converted to, or handled by, machine instructions that execute on a processing unit. </DD>
  <DD>And besides running, the hope is that the code will run correctly: it will do the job intended by the programmer.  </DD>
  <DD>The poor human gets feedback from the system when the code does not translate to machine actions (a "compiler error"), or the machine actions fail to execute (an "execution error"), or the output is not correct (a "mistake").</DD>
    <DD>All the while, the programmer cycles through psychological states displayed below: In professional programming this job is done by a team of people who follow practices and standards.  </DD>
    <DD>This textbook is aimed at a person who is programming on their own in order to implement their own economic modeling.</DD>

<h4>Manic Depression:The Four Stages of  <s>Grief</s> Programming</h4>
<img src="img/cycle.png"/>

<DT>Programming can be  satisfying and occasionally exciting when the machine finally does what you want (apparently).</DT>
  <DD>But it also tedious and frustrating because the machine and its programs cannot read the programmer's mind. Humans often forget how simple and dumb machines are.  </DD>
  <DD>However, rest assured. The humans are still firmly in control. The machines and their program masters do not appear to have their own objectives yet. Instead, they  are maids and chauffeurs waiting for us to want them to do something for us in a language they understand.</DD>

<DT>We will expand on some of these stages, but below is the arc that you should expect to follow when setting out to do economic computation.</DT>
  <DD>When you are actually writing the program we will call it <code>CodingTime</code>.</DD>
    <DD>When you think the program does what you want you try to run it, which requires the computer to understand the instructions and then carry them out, we break this up into two stages: <code>CompileTime</code> (translating the code into  machine instructions) and <code>RunTime</code> (carrying out the machine  instructions by loading them into RAM and adding the first instruction to the running program list).</DD>
      <DD>In some languages these stages are very distinct, but in many languages the user may not be aware of these separate stages.</DD>

<DD class="callout"><h4>The Waiting is the Hardest Part</h4>
<img src="img/grief.png"/>
<blockquote>All progress in programming leads to more code writing and debugging.</blockquote></DD>

<h4>Time</h4>

<OL class="section">
<LI>Stage 1: <code>CodeTime</code></LI>

<DT>Coding is when you are working on the text of your program in your chosen language.  </DT>
<DD>This is like writing a draft of a term paper.  When writing a term paper you might write a draft and then hand it over to someone to read it and make comments. </DD>
<DD>In the flowchart above, some stages are shaded, including <code>CodeTime</code>.  These filled-in stages are when you, the lowly human, are doing something.  </DD>
<DD>At the other times in the programming cycle the work is being done by the computer. What you should gather from the flowchart is that as the program develops you continually come back to Stage 1.</DD>

<LI>Stage 2: <code>CompileTime</code></LI>

<DT>Just as your parent might look at the draft of your paper and give you feedback, so you will be asking the computer to execute your program.  </DT>
<DD>But before this happens the intent of the program must be clear as written in the language you are using.  Often dumb mistakes of yours or misunderstanding of the language make your program invalid in the language.  </DD>
<DD>Mistakes found at this stage are often <em>syntax errors</em>, akin to grammatical and spelling errors in your paper.  When they exist it means your paper/program cannot be understood by the audience. Fixing these errors is referred to as <dfn>debugging</dfn> (why?).</DD>

<DT>You may be required to go back several times to fix the errors and submit the program again.  </DT>
<DD>Often fixing some errors leads the compiler to find other errors that were always there, or the fix itself may have errors.  With patience you eventually get your program past <code>CompileTime</code>.  </DD>
<DD>At this stage the compiler can translate your program into something the computer can execute.</DD>

<LI>Stage 3: <code>RunTime</code></LI>

<DT>After the instructions the compiler inferred from your program are executed we get to running or executing the program. </DT>
<DD>As discussed in details below, the difference between what we call <code>CompileTime</code> and <code>RunTime</code> is not always obvious to you the programmer, especially in languages like Ox.  But to understand what you are doing it is important to see the difference in timing.</DD>

<DT>Once your program is running it will usually produce runtime errors.  </DT>
<DD>That is, the program starts to run but then "crashes" and quits before doing everything you want it to do. The analogy is submitting a draft of your term paper to the teacher who finds mistakes in your reasoning.  </DD>
<DD>These are mistakes in meaning (semantics) rather than mechanical issues of syntax.  The teacher hands back the draft with required changes in red. This initiates another sequence of changes and edits, which usually require you to go back to Stage 1 and work on your code again.  </DD>
<DD>In some cases something else causes a runtime error, like the format of the data your program uses is incorrect.  But often you must change the program and resubmit it to the compiler, which may find new syntax errors, leaving stuck at Stage 2 again.  </DD>
<DD>These new <code>CompileTime</code> errors must be fixed before getting a shot at Stage 3 again.</DD>

<LI>Stage 4: <code>TestTime</code></LI>

<DT>Once the program executes without errors there are results or output to look at.  </DT>
<DD>This may be a table of numbers or a graph or a very large and complex output.  Just because output is produced does not mean that it is the correct or the intended output for the input you provided. </DD>
<DD>You cannot simply accept the output but rather must question it and subject it and the program that created it to scrutiny.  If we write computer programs to give us answers to problems we cannot solve by other means, then how can we check the output of our program.  </DD>

<DT>The best way is to start by running it on cases (or using data for which) you know the correct output from other means.</DT>
 <DD>Suppose your test case is when some parameter in your economic model, call it $\alpha$ is equal to 0.  </DD>
 <DD>For this case you can solve your model on paper and you get an answer (or result or prediction) of 2.5.   </DD>
 <DD>You have written your code to handle the general case when $\alpha$ can be non-zero.  You run your code for $\alpha$=0 and get output of 2.5.</DD>

<DT>Probably every programmer, and especially self-taught amateurs, spends too little time in <code>TestTime</code>. </DT>
 <DD>The more you program the more you learn that your code will fail under many conditions (different input).  Once code runs it is human nature to start executing it on data for which they cannot directly verify the output.  Any time you spend testing your code and making it more robust to input values will usually pay off in less time later on trying to figure why your results seem wrong or the program crashes.</DD>

<LI>Stage 5: <code>Production Run</code></LI>

<DT>Finally, your program compiles, executes and gives correct answers for cases that can be verified by other means.  </DT>
<DD>You can now run your program for data that you cannot know the correct output for ahead of time.  Of course, this change in the data can expose compile or runtime errors that were not detected before, so moving from test cases to production runs is not often immediate. </DD>
<DD>Once we get output, how do you know it is correct?  In general you will not know this, and you should always act as if there are errors in your code that you have not discovered yet.  </DD>
<DD>One way to detect these is to check wether your code produces output consistent with your intuition or with something similar to comparative static results in economic theory.</DD>

<DT>Continuing the example from Stage 4: </DT>
<DD>If you run your program for the case $\alpha$=0.5, you don't know exactly what value is correct.  But perhaps you do know that it must be greater than 2.5, the prediction for $\alpha$=0.  </DD>
<DD>Then obviously you confirm that is the case. Often you think the output should move in one direction but you are not certain.  If you get output that does not accord with your intuition you could stay confident of your coding and belief that your model has counter intuitive predictions, making this the point of your whole research agenda.  </DD>
<DD>However, again it is almost always best to start by doubting your code and trusting intuition. Like in trial in a television show, treat your program as a hostile witness.</DD>

<h4>A programming cycle for a modified "hello world" program.</h4>
<DD><pre>
PROGRAM                         COMPILER SAYS        RTE SAYS        OUTPUT
------------------------------------------------------------------------------------

include "oxstandard.h"           include
main() {                          not understood
  decl x,v="hello worl";
  println(x);

------

#include "oxstandard.h"          file not found
main() {
  decl x,v="hello worl";
  println(x);
}

------

#include "oxstd.h"               OK!                  x has no value
main() {
  decl x,v="hello worl";
  println(x);
}

------

#include "oxstd.h"               OK!                  OK!              hello worl
main() {
  decl x,v="hello worl";
  println(v);

------

#include "oxstd.h"              OK!                  OK!              hello world
main() {
  decl x,v="hello world";
  println(v);
  }
</pre></DD>

</OL>
<h2><a name="s026"><LI>Advanced Programming in Ox</a></LI></h2>
<blockquote class="toc"><h4>Contents</h4>
<OL type="1" class="toc3"">
<LI><a href="s027.html" target="content">Snakes and Arrows<br/>&emsp;Vectors, Matrices and Arrays</a></LI>
<LI><a href="s028.html" target="content">Higher Ground<br/>&emsp;More Things in Ox</a></LI>
<LI><a href="s029.html" target="content">More Expressions</a></LI>
<LI><a href="s030.html" target="content">Objects and Classes</a></LI>
<LI><a href="s031.html" target="content">The Style Council</a></LI>
</OL>
</blockquote>
<OL  type="1" ">
<h3><a name="s027"><LI>Snakes and Arrows<br/>&emsp;Vectors, Matrices and Arrays</a></LI></h3>

<OL class="sections">

<LI>Building blocks of Ox data structures</LI>

<DT>In computer lingo, a <em>data structure</em> is an organized group of 1 or more memory cells.</DT>
<DT>In other chapters, we have discussed <em>scalar data types in Ox</em></DT>
<DD><code>int</code>: stores a single signed binary integer</DD>
<DD><code>double</code>: stores a single floating-point real (in double precision)</DD>
<DD><code>pointer</code>: stores a pointer to an Ox variable (or other data types) using the <q>location of</q> operator, <code>&amp;</code></DD>
<DT>There are other scalar types in Ox, which are either discussed elsewhere or is not important for our purposes</DT>
<DD><code>file</code>: holds a pointer-like value that let's the user read and write information from a file on disk.  For the most part we won't need to use open files, but they are important in other ways.  Note that some input and output can be carried out without creating a <code>file</code> variable, including <code>savemat()</code> and <code>loadmat()</code></DD>
<DD><code>function</code>: in compiled languages functions are not equivalent to data types, but in a interpreted language like Ox that can be stored in a variable and can be passed as arguments.</DD>

<DT>This chapter describes three basic array types in Ox</DT>
<DD>In computer lingo, an array is a generic term for a data structure that is made up of multiple scalar data types or even multiple other array types.</DD>

<DT>Ox Vectors and Matrices are <em>homogeneous</em> arrays</DT>
<DD>That is, each element of the structure is the same type.  Each element of a vector or a matrix is a <code>double</code>, a FPR.</DD>
<DD>Another kind of homogeneous array is a <code>string</code>, which is one or more <code>characters</code></DD>

<DT>Ox Arrays are a <em>heterogeneous</em> array</DT>
<DD>That is, each element of an Ox array can be a different type, at least from the point of view of the programmer.</DD>

<DT>Other array structure: <em>class</em></DT>
<DD>Ox is an <em>object-oriented</em> language, and a <code>class</code> is the type that an object is</DD>
<DD>Classes and objects are discussed separately.  You can use Ox for many purposes without ever dealing with objects, but they can be very helpful for more sophisticated solutions to problems.</DD>

<LI>Matrices</LI>

<DT>Ox is a <em>matrix</em> language, in the sense that a matrix is one of the basic data types.</DT>

<h3>Matrix Creation</h3>

<DT>Create a matrix or vector using the <code>new</code> operator</DT><DD>
<pre>
      MATRIX                     VECTOR
    a = new matrix[5][5];      a = new matrix[5];
</pre></DD>
<dt>Create a matrix using syntax for handling "hard" constants
</DT><DD><pre>
          MATRIX                 VECTOR
    b = <1,2,3; 4,5,6>;        b = <1;2;3>;

    c = ;;
    </pre>

<dt>Create a matrix using one of Ox's functions designed to produce matrices
</DT><DD><pre>
         MATRIX                     VECTOR
    a = zeros(5,5);             a = zeros(5,1);
    b = unit(3);                b = unit(1);
    c = ones(4,4);              c = ones(4,1);
    d = constant(6.5,2,3);      d = constant(6.5,2,1);
                                e = range(0,5);
</pre></dd>

<DT>Create an <em>empty</em> matrix</DT>
<DD><pre>
a = <>;
</pre>
Why would you do this?  One good reason is because later commands in your program will expand the empty matrix.  </DD>

<li>Manipulating Matrices</li>

<h3>Concatenation</h3>
<DT>You can create a vector from hard constants using the syntax show above: </DT>
<DD><code>&lt; , ,&hellip; ; , , &hellip; ; &hellip; &gt;</code>.  So <code>&gt; 2.5 , 0&lt;</code> would create a row vector, <code>(2.5 0.0)</code>.  </DD>
<DD>But, suppose you have two variables, suppose you have two variables, a and b.  Both contain numbers that you want to put in a vector.  Let's say a=2.5 and b=0.0 (although you might not know that why writing the code because the values depend on other input).</DD>
<Dd>You might think <code>&lt;a,b&gt;</code> would work, but since "a" is not a hard integer like "2" you can't use that syntax.  You will get a compile-time error.  The reason is that the <code>&lt; &hellip; &gt;</code> actually happens when Ox is compiling your program.  It does not happen when your code is executing.</Dd>
<Dd>Instead, use the "concatenation operators", ~ and |.
<pre>
Symbols   Description                   Meaning                    Example            Constant Equivalent
-------------------------------------------------------------------------------------------------------------
~         horizontal concatenation      add columns to a matrix    d = 2.5 ~ 0.0;     d = <2.5,0.0>;

|         vertical concatenation        add rows to a matrix       d = 2.5 | 0.0;     d = <2.5; 0.0;

~=        horizontal self-concatenation add rows to myself         d = ones(2,2);
                                                                   d ~= 2.5;          d = <1,1,2.5;1,1,2.5>;

|=        vertical self-concatenation   add columns to myself      d = zeros(2,1);
                                                                   d |= 2.5;          d = <0;0;2.5>;
</pre></Dd>

<h3>Reshaping Matrices</h3>

<DD><pre>
Function            Description
-----------------------------------------------------------------------------------------------------
shape()

reshape()

vec()

unvec()

</pre></DD>

<li>Matrix Operations</li>

<DT>Standard Operations</DT>
Addition, Subtraction

Multiplication

Scalar Multiplication

Division (inversion)

<DT>Dot-Operators</DT>

<DT>Various</DT>
<DD>Many many operators and functions in Ox are designed to do things on matrices</DD>

<LI>Arrays</LI>

<DD><pre>

a = new array[5];

a = {};

a = {0,"hi",<2.5;0.0>};

</pre></DD>

</DD></OL>
<h3><a name="s028"><LI>Higher Ground<br/>&emsp;More Things in Ox</a></LI></h3>

<DL>
<DT><code>function</code>:</DT><DD>A segment of Ox code.  How and why a variable might contain a function is discussed later.</DD>
<DT><code>file</code>:</DT><DD>Refers to a file on disk that can read and written to.</DD>
<DT><code>class</code>:</DT><DD>A heterogeneous collection of variables and functions that operate on them. Discussed in Chapter ??</DD>
<DT><code>an object of a class</code>:</DT><DD>Also discussed in Chapter ??</DD>
</DL>


<h3><a name="ox_syntax_scope"></a>Scope</h3><p>
Variables declared at the start of a statement block have scope and life restricted to the block. These variables are called <i>automatic</i>: they are created and initialized whenever the block is entered, and removed as soon as the block is exited.

Variables declared outside any statement block have global scope and life; these are called <i>static</i>.

Note that Ox assignment of arithmetic types and string type implies copying over the contents from the right-hand side to the left-hand side. Automatic variables of any type can be assigned to variables with broader scope.

<h3><a name="ox_syntax_qualifier"></a>Type qualifiers</h3><p>
A <tt>const</tt> object can only be initialized once, and not changed thereafter. The use of <tt>serial</tt> is explained in <a href="#ox_syntax_RefParallel">this section</a>. The <tt>const</tt> and <tt>serial</tt> qualifiers are  mutually exclusive.

<p>A <tt>const</tt> object must be initialized (unless declared <tt>extern</tt>) but its value may not be changed thereafter. Unless declared <tt>extern</tt>, a <tt>const</tt> object cannot be accessed from other files. If of scalar <a href="#ox_syntax_RefTypes">type</a>, a <tt>const</tt> can appear in a constant-expression.

<p>At the external level of declarations, as treated here, it is possible to specify a matrix size, and initialize that matrix to zero. If an external variable is created without explicit value and without dimensions, it will default to an int with value 0. Here are some examples:

<h3><a name="s029"><LI>More Expressions</a></LI></h3>


<h4>Address operator &amp;</h4>

Recall from the chapter on addresses that <code>&amp;</code> is the address operator in Ox.  That is, <code>&x</code> is the location of the variable <code>x</code>.   The operand <code>x</code> must be an lvalue.  That is, it has to be a <q>thing</q>.  It is possible to take the address of a class object, a function, or an array element, but not of a matrix
element. So you cannot say <code>y = &A[2][3]</code> so that <code>y</code> points at the 2,3 element of a matrix say.  But you can write <code> y = &A</code> which means <code>y</code> points to the variable <code>A</code> which might currently contain a matrix.</p>   

So if you can't point directly to <code>A[2][3]</code> how could you use <code>y</code> to get at it?  This is a somewhat tricky aspect of Ox.  Essentially we need to undo the address operator <code>&amp;</code>.  We want to access the thing <code>y</code> is pointing to.  What makes it trick is that this looks like accessing an element of a matrix.  That is, <code>y[0]</code> means <q>Look at the contents of <code>y</code>.  They are pointing to another thing.  Go to that thing.  
<dd><pre>
y = &A;
println(y[0][2][3]," = ",A[2][3]);
</pre></dd>
So in effect <code>y[0]</code> is the same as <code>A</code> if <code>y</code> contains a pointer to (or the address of) <code>A</code>.

<h4><a name="ox_syntax_new"></a>New and delete</h4><p>

The <tt>new</tt> operator can be used to create an object of a class, or to create a matrix, string or array. The <tt>delete</tt> operator removes an object created by <tt>new</tt>. Note that matrices, strings and arrays are automatically removed when they go out of scope; this is not the case for objects. A class object, on the other hand, must be removed explicitly using the <tt>delete</tt> operator. If not, it will exist until the program terminates (which may be acceptable).

Only one or two array levels at a time can be created by <tt>new</tt>; however, <tt>delete</tt> removes all sublevels. A string created by <tt>new</tt> consists of null characters, a matrix will have all elements zero. Matrix, string and array objects with dimension zero are allowed (this can be useful to start concatenation
in an iterative loop; remember that an empty matrix constant is <tt>&lt;&gt;</tt>, and an empty array <tt>{}</tt>). Matrices and arrays can be created with either one or two dimensions.

<p>Examples involving objects of <a href="#ox_syntax_RefClasses">classes</a> are given.

<h4>Fancy Matrix and Array Indexing</h4>

<DD>Three ways of indexing are distinguished:
<pre>
indexing type   example
scalar          m[0][0]
matrix          m[0][<0,1,2>]
range           m[][1:]
</pre></DD>
In the first indexing case (allowed for all non-scalar types), the expression inside square brackets must have scalar type, whereby double is converted to integer. Vector types may also be indexed by a matrix or have a range expression inside the brackets. It is possible to use only one index to a matrix. If a matrix <code>x</code> is a column or row vector, <tt>x[i]</tt> it will pick the <i>i</i>th element from the vector. If <tt>x</tt> is a matrix, it will treat the matrix as a vector (row by row, which corresponds to the <tt>vecr</tt>).</p>

If a matrix is used as an index to a matrix, then each element (row by row, i.e. the <tt>vecr</tt> of the argument) is used as an index. As a consequence, indexing by a column vector or its transpose (a row vector) has the same effect. A matrix in the first index selects rows, a matrix in the second index selects columns. The resulting matrix is the intersection of those rows and columns.</p>

A range index has the form <i>start-index</i> <tt>:</tt> <i>end-index</i>. Either the start-index or the end-index may be missing, which results in the lower-bound or upper-bound being used respectively. An empty index selects all elements. The resulting type from a range or empty index is always a vector type.</p>

Indexing beyond the end will result in a fatal run-time error. An exception is indexing a string for reference: this can be done one position beyond the end, which returns 0. For example, <tt>i=s[sizeof(s)]</tt> sets <tt>i</tt> to 0.</p>


<h4>Function calls, Actual and Formal Arguments</h4>

In an expression <code>f()</code> calls the function <code>f</code>.  That is, whatever that function does will happen.  In that case it appears <code>f</code> has no arguments or inputs.  If it does want information from the program then the values are listed inside the parentheses.

All argument passing is by value, but when an array is passed, its contents may be changed by the function (unless they are <tt>const</tt>). The order of evaluation of the arguments is unspecified; all arguments are
evaluated before the function is entered. Recursive function calls are allowed. 

<h4>Concatenation (also called appending)</h4>

<h3><a name="ox_syntax_concat"></a>Concatenation expressions</h3><p>

<pre>
left        operator   right           result
int/double     ~       int/double      matrix 1 x 2
int/double     ~       matrix  m x n   matrix m x (1+n)
matrix m x n   ~       int/double      matrix m x (n+1)
matrix m x n   ~       matrix  p x q   matrix max(m,p) x (n+q)
int/double     |       int/double      matrix 2 x 1
int/double     |       matrix  m x n   matrix (1+m) x n
matrix m x n   |       int/double      matrix (m+1) x n
matrix m x n   |       matrix  p x q   matrix (m+p) x max(n,q)
int            ~  |    string          string
string         ~  |    int             string
string         ~  |    string          string
array          ~  |    array           array
array          ~  |    any basic type  array
</pre><p>

<h4>Dot Operators</h4>


<h4>Self-Assignment and Self-Concatenation</h4>

<pre>
                    =               assign
                    *= .*=          self multiply then assign
                    /= ./=          self-divide then assign
                    += -=           self-add/subtract then assign
                    ~= |=           self-concatenate then assign
</pre><p>

The assignment operators are the  simple assignment <tt>=</tt> as well as the compound  <tt>*=  /=  +=  -=  ~=  |=  .*=  ./=</tt> operators. An lvalue is required as the left operand. The type of an assignment is that of its right operand. The compoundd assignment <i>l</i> <i>op</i><tt>=</tt> <i>r</i> is equivalent to <i>l</i> <tt>=</tt> <i>l op (r)</i>.


<h3><a name="TabSyntaxOXDOTOP"></a>Table syn.3: Results from dot operators</h3><p>

<blockquote>This table explains what happens when you use a dot operator on different kinds of variables.  The symbol &#8226; is a stand-in for the different operators that have a dot version. That is, what you see is <code>r = a .&#8226; b</code>.  The table shows you the type and dimension (if relevant) of the left-side argument (a), the type and dimension of the right-side (b) and the resulting type and dimension (r). For example, the first example says that if boh a and b are integers then <code>a.*b</code> returns an integer.</blockquote>

<pre>
       left (a)        op          right (b)      =       r
type        dim      &#8226;   type       dim        type    dim      scalar value
----------------------------------------------------------------------------------
int                 .&#8226;   int                   int             a &#8226; b
int/double          .&#8226;   double                double          a &#8226; b
double              .&#8226;   int/double            double          a &#8226; b

scalar              .&#8226;   matrix      m x n     matrix  m x n   a &#8226; b_{ij}
matrix     m x n    &#8226;   scalar                 matrix  m x n   a_{ij} &#8226; b

matrix     m x n    .&#8226;   matrix      m x n     matrix  m x n   a_{ij} &#8226; b_{ij}    same dimensions

matrix     m x n    .&#8226;   vector      m x 1     matrix  m x n   a_{ij} &#8226; b_{i0}    equal rows
matrix     m x n    .&#8226;   vector      1 x n     matrix  m x n   a_{ij} &#8226; b_{0j}    equal columns

vector     m x 1    .&#8226;   matrix      m x n     matrix  m x n   a_{i0} &#8226; b_{ij}    equal rows
vector     1 x n    .&#8226;   matrix      m x n     matrix  m x n   a_{0j} &#8226; b_{ij}    equal columns

vector     m x 1    .&#8226;   vector      1 x n     matrix  m x n   a_{i0} &#8226; b_{0j}    equal rows
matrix     1 x n    .&#8226;   vector      m x 1     matrix  m x n   a_{0j} &#8226; b_{i0}    inner dims

string     n        .&#8226;   string      n         vector  1 x n   a_{j}  &#8226; b_{j}
string     n        .&#8226;   int                   vector  1 x n   a_{j}  &#8226; i
int                 .&#8226;   string      n         vector  1 x n   i      &#8226; b_{j}
</pre>

<p>The most common operators are <em>dot-operators</em> (operating element-by-element) and relational operators (operating element by element, but returning a single boolean value). The resulting value is given Tables <a href="#TabSyntaxOXDOTOP">syn.3</a> and <a href="#TabSyntaxOXDOTREL">syn.4</a> respectively. In addition, there are special matrix operations, such as matrix multiplication and division; the result from these operators is explained below. A scalar consists of: int, double or 1 <tt>x</tt> 1 matrix.

<h3><a name="TabSyntaxOXDOTOP"></a>Table syn.3: Result from dot operators</h3><p>
<pre>
left  a        op   right b         result         computes

int            op   int             int            a op b
int/double     op   double          double         a op b
double         op   int/double      double         a op b
scalar         op   matrix  m x n   matrix m x n   a op b_{ij}
matrix m x n   op   scalar          matrix m x n   a_{ij} op b
matrix m x n   op   matrix  m x n   matrix m x n   a_{ij} op b_{ij}
matrix m x n   op   matrix  m x 1   matrix m x n   a_{ij} op b_{i0}
matrix m x n   op   matrix  1 x n   matrix m x n   a_{ij} op b_{0j}
matrix m x 1   op   matrix  m x n   matrix m x n   a_{i0} op b_{ij}
matrix 1 x n   op   matrix  m x n   matrix m x n   a_{0j} op b_{ij}
matrix m x 1   op   matrix  1 x n   matrix m x n   a_{i0} op b_{0j}
matrix 1 x n   op   matrix  m x 1   matrix m x n   a_{0j} op b_{i0}
string n       op   string  n       matrix 1 x n   a_{j}  op b_{j}
string n       op   int             matrix 1 x n   a_{j}  op i
int            op   string  n       matrix 1 x n   i      op b_{j}
</pre><p>

<h3><a name="s030"><LI>Objects and Classes</a></LI></h3>
<h3><a name="s031"><LI>The Style Council</a></LI></h3>
<h4>Background</h4>

The previous chapters presented some simple Ox programs to illustrate how a computer works.  And in later chapters we will show how to do math and economics in Ox.  This chapter is about programming, using Ox for examples.  It teaches the syntax and other aspects of the language, but it is not intended as a quick way to learn Ox if you have previously taken a formal programming class. This chapter asks the reader to first think of a program as whole, like the canvas for a painting.  Eventually we fill in the small details to complete the picture, but first we think of about the general outline.</p>

One reason to take this leisurely path towards programs that do real work is that the Ox documentation follows the more direct approach. If you have programmed before then you know what you need to get started: examples and a complete description of syntax, predefined constants, functions and classes. You will start modifying the examples and programming right away.  As you encounter compiler errors you will go back to the documentation for clarification.  The HTML documentation does all that for you.</p>

For readers who are less sure of their preparation I encourage you to first look at the big picture.  The concern here is developing a sense of programming without much concern to write programs that are sensible.</p>

<OL class="section">
<LI>I'm Bad, I'm Nationwide</LI>
<blockquote class="quote"><em>The Principle: use global identifiers sparingly</em></blockquote>

A program creates an environment of things that will exist at some point in the memory of the computer while the program is running. Outside this world is the <defn>Run Time Environment</defn>, which sets things up for the program and lets it get information in and out.  The <abbr title="Run Time Environment">RTE</abbr> needs to know the entry point into the world:  the first command to be executed when the program gains control of the CPU (compiled) or interpreter.  </p>

In C and Ox, the program's entry point is a single function called <code>main()</code>. <code>main</code> might be the last thing in the <code>.ox</code> file, but it is always where execution starts.  You may have a lot code that compiles, but without a <code>main()</code> it will not do anything.  Once started the program may terminate at any point (for example an fatal error occurs), but it definitely terminates if/when the program counter (the PC) gets to the end of <code>main()</code>.</p>

It might make sense that the entry point is the first thing in the source code.   However, the job of parsing the source code is made simpler if identifiers are <em>declared</em> before they are used.  So in most Ox programs many items will be declared and/or defined above <code>main()</code>.  As discussed earlier, <code>#include "oxstd.h"</code> declares all the built-in items in the Ox program and placing it above <code>main()</code> ensures they can be used.</p>

We call the world of the program <code>the globe</code>, which is not typical, because identifiers in it are said to be <em>global</em>. A global identifier, and the location it refers to, can be accessed by any line of code in the file after it is declared. (When your program is spread over other files there is a bit more to what it means to be global.) The two main types of global identifiers in Ox are variables and functions. Every variable must be listed in a <code>decl</code> statement.  As discussed in the previous chapter, <code>decl</code> tells the Ox interpreter to create a new dynamically allocated variable of C type <code>oxvalue</code>.  We can think of this allocation as happening before <code>RT0</code> for global variables.</p>

A function can be declared by simply stating its name: 
<DD><code>f();</code> declares <code>f</code> to be a function.  That does not say what it does, merely that it exists on the globe.  The function is <em>defined</em> by placing the statements that it will execute inside curly brackets:
<pre>
f();                        // f declared

g() {                       // g defined and declard
   println("I am g");
   }

f() {                       // f defined
  println("I am f");
  }
</pre></DD>

<UL class="ul">
<LI>Lines in the source code do not really mean anything. </LI>
    <DD>A statement may span many lines, and a single line can contain several statements.  What matters is the semi-colon <code>;</code> that ends a statement and the right curly bracket  <code>}</code> that ends a group of statements started with <code>{</code>.</DD>

<LI>New lines do matter for one thing: comments that start with <code>//</code>. </LI>
    <DD>Anything after <code>//</code> on the line will be ignored by the compiler.  You can put explanatory notes there to help a human reader understand the code.  The comment ends when the next line in the source code begins.  Comments within a line and across lines are delimited by <code> /* */</code>. </DD>

<li>Functions do not have to be declared separately.</li>
    <DD>If the definition appears then that will declare the identifier.  One reasons for separating the definition and declaration has already be seen.  The <code>.h</code> file can contains only declarations.  The definitions can then be linked in from a separate file.  This can get a little tricky when your program has more than one source file, so a whole section below is devoted to this.</DD>
</UL>

A function creates a sub-world between the left and right bracket of its definition.  Variables declared inside the function are  <em>local</em> to it.  As in C a function cannot be defined within another function, only at top level as a part of the the globe.  However, we will see that some functions are actually <em>declared</em> below the global level.  No statements outside  <code>{ }</code> can access a local variable.  A statement inside a function can reference any global declared before the function is defined.</p>

<DT>This code will create a compiler error:</DT><DD>
<pre>
 1          decl v;
 2          f() {
 3              v = 5;
 4              y = 6;
 5              }
 6          decl y;
 7          g() {
 8              y = 7;
 9              }
10          main() { }
</pre></DD>

Line 3 is okay because <code>v</code> is used ("referenced") after it is declared on line 1. But the global <code>y</code> is declared <em>after</em> it is first used inside <code>f()</code>. Making the programmer declare before using identifiers means the parser does not have scan the file once to find all the declared identifiers and then scan again.  </p>

<DD>The error looks something like:
<pre>
new06.ox (4): 'y' undeclared identifier
new06.ox (4): 'y' left-value expected (need storage object)
Ox reports errors: exit code= 1!!
</pre></DD>

Line 7 inside <code> g()</code> is fine because <code>y</code> was declared before <code>g()</code> was defined.


<DT>Consider this program:</DT>
<DD><pre>pp.ox

 1        #include "oxstd.h"
 2        ping();
 3        pong()  {
 4            println("pong");
 5            ping();
 6            }
 7        ping()  {
 8            print("ping-");
 9            pong();
10            }
11        main() {
12            ping();
13            }
</pre></DD>

If the function declaration for <code>ping()</code> were not separate from its definition then line 2 would be deleted and the code would not compile, because <code>ping()</code> is defined after it is used in <code>pong()</code>.  If we were to swap their order then <code>pong()</code> would used before it is defined. But since <code>ping()</code> can be declared before <code>pong()</code> and then defined afterwards the code is fine. 

The programmer decides what functions to declare and what they will do in order to best represent the problem to solve.  Consider two prototypes.
<UL class="ul">
<LI>Mr. E.</LI>
Mr. E is a typical self-taught programmer, which means in Ox he is liable to simply let <code>main()</code> do all the work.  The program becomes a a long sequence of statements. The overall task is not broken into smaller tasks.  Perhaps after the program has expanded and Mr. E. has copied-and-pasted a segment of code to three places he decides to move that code to a function and simply call it three times.  The functions he defines will have names like <code>func1()</code> and <code>Ablsx()</code>.  He's forgotten what the second one stands for, since he created 6 months ago. Some functions need to access the same data so he makes those identifiers global.  This also obviates the need to figure out how Ox passes information to functions, because his functions simply use global variables to do that.</p>

<LI>Ms. P.</LI>
At the other extreme Ms. P is a well-trained software engineer solving the same problem as Mr. E.  Her <code>main()</code> easily fits on the screen, and may have just two or three statements in it.  It refers to functions she's written with names like <code>Initialize()</code> and <code>SolveModel()</code>.  These functions in turn call other functions, each with a specific task to perform that can be summed by the function's name, such as <code>FindEquilibrium()</code> or <code>CheckObservation()</code>.
    <details class="aside"><summary>What'sInAName.</summary>This style of naming identifiers has a name: <a href="https://en.wikipedia.org/wiki/CamelCase">CamelCase</a>, and using it betrays my Pascal background.  Ox prefers a different convention called Hungarian notation, which packs more information into the name.  Several other conventions exist.  As you program you will probably change how you name things, and as a function gets re-coded to fix errors or to generalize the code you should always ask if the name is still accurate.  Most people who program a lot for themselves settle on one style or the other without being perfectly consistent.</details>
</UL>

You might think that the part of the parable is to explain how Mr. E spends weeks getting his code to work, while Ms. P. steadily develops the code and gets it working properly in much less time.  But actually, most people who do a lot of programming cycle back and forth between these two styles.  When the issue seems straightforward it is natural to just tackle it directly.  But at some point the head on approach becomes unwieldy.  At that point it helps to understand the way Ms. P. programs.  This makes complex code readable and easier to correct and extend.  It also allows Ms. P. to test components separately, to isolate problems and re-use code within changing contexts.  However, the ability to switch to Ms. P. style does not happen automatically.</p>

<LI>I Call Your Name</LI>
<blockquote class="quote"><em>The Principle: Name constants in your code and protect them from accidental changes</em></blockquote>

Programs rely on special constant values , such as the value of $\pi$, or the 2$\times$2 identity matrix, or the number of players in the game your program analyzes. Code is much easier to read and more reliable to use if each constant is given a name, such as <code>Pi</code> or <code>I2</code> or  <code>N</code>.  The code is more reliable because the correct value only has to  be set once when it is assigned to the identifier.  </p>

T>If instead you leave the number of players as a number, say <code>3</code>, then <code>3</code> may appear scattered in your code. To change the number of players to <code>4</code> each instance must be changed otherwise perhaps difficult-to-find bug has been introduced. And <code>3</code> might show up for some other reason, so you need to change only those 3s that refer to the number of players.</p>

In Ox, variables can be <em>initialized</em> when they are declared, as in <code>decl Pi = 3.1417;</code>.
At <code>RT0</code> the memory cell for <code>Pi</code> will indeed contain the rough approximation to $\pi$.  But the danger of assigning a constant to a variable is that variables ... vary.   You may accidentally change the value of <code>Pi</code> in some line of code, perhaps because you typed <code>Pi = 5</code> but meant to type <code>Hi = 5</code>.  The compiler does not catch typos like this, as long as <code>Pi</code> was declared above the line.  But from then in <code>RunTime</code> the value has changed, and again this is a difficult error to locate.</p>

There are two way to name constants in Ox and be guaranteed they stay constant from <code>RT0</code> until the program terminates.  One way is to add the attribute <code>const</code> to the declaration: <code>const decl Pi = 3.1417;</code>. Now the Ox compiler knows that <code>Pi</code> should never change, and if it encounters the statement <code>Pi = 5</code> it will complain and not finish creating object code, let alone execute your program.  You can then fix the typo and compile again.</p>

The other way to create a constant only works for integer values, but it can be very helpful in writing good code.  It is the <code>enum{}</code> statement, which is similar to <code>enum</code> in C, but not exactly the same. All <code>enum</code> does is let the program <em>enumerate</em> a sequence of integer values and assign an alias for each:
<DD><pre>
    enum{Zero,One,Two}
    enum{Asia,Africa,Europe,NorthAmerica,SouthAmerica,Australia,Antarctica,Ncontinents}
    enum{Three=3,NegThree=-3,NegTwo,Six=Three+Three}
</pre><dd>

Without any <code>=</code> an enumeration is just the numbers <code>0,1,2,...</code>. The identifer is the new alias for that integer.  So the first enumeration means in that this program <code>Zero &equiv; 0</code>, <code>One &equiv; 1</code>, and <code>Two &equiv; 2</code>.  And the Ox compiler will not let your code attempt to change the value. (In fact no memory cell is used to store <code>Zero</code> so it cannot be changed during execution.  It appears as its integer value in the object code.  In Ox, an enumerated value is <b>not</b> a <em>left-object</em> because it is impossible to put it on the left side of the assignment operator <code>=</code>.</DD>

The second enumeration lists the seven continents and assigns each an integer code, starting with 0 for <code>Asia</code>.  So in this program the number 0 has two names: <code>Zero</code> and <code>Asia</code>.  <code>Antarctica</code> gets a value of 6.  A convenient way to define the number of items enumerated is to add a final enumeration, so <code>Ncontinents &equiv; 7</code>.  Now, if later the code is modified to define India as a continent of its own, the tag <code>India</code> can be put in the list and the number of continents will become 8 automatically (once the code is recompiled).  This can be a very handy way to label the elements of a vector.</p>
<DD>For example, the specification of the X variables in a regression can be an enumeration:
 <pre>enum{Cons,Gender,Age,AgeSquare,Ncoeff}</pre>
Now if <code>beta</code> is a vector of coefficients, it will be of length <code>Ncoeff</code> and <code>beta[Age]</code> will, for example, return the coefficient on age.</DD>

The final enumeration shows that an enumeration can be used to create any integer constant.  The list converts to <code>3,-3,-2,6</code>.  <code>NegTwo</code> is assigned as a name for -2 because <code>enum</code> increments after each comma unless <code>=</code> appears.</DD>

<li>Call Me: functions and their arguments</li>
<blockquote class="quote"><em>The Principle: Use functions to avoid duplicate code and to protect data.</em></blockquote>

<DT>Scope and Lifetime of Variables</DT>

<DT>Formal and Actual Parameters</DT>

In following a top-down approach to programming, we are now concerned with getting information in and out of functions.  A bottom-up approach would focus on statements and operators and later consider grouping them into functions.</p>

Information passing can be confusing even if you have programmed before, because languages differ on how to pass information.  So to explain this the functions in our examples will continue to do little more than assign values to variables and print them out.
<DD>arguments.ox<pre>
#include "oxstd.h"
decl one=1.0;
five(a,b,c) {
   c[0] = one-a;
   b = b+5;
   println("b ",b);
   return 5;
   }
main() {
   decl two=2.0, d;
   println("Give me five: ",five(6.0,two,&d));
   println("What is d? ",d);
   }

--------------- Ox at 15:30:31 on 18-Sep-2012 ---------------

Ox Console version 6.21 (Windows/U) (C) J.A. Doornik, 1994-2011
This version may be used for academic research and teaching only
b 7
Give me five: 5
What is d? -5
</pre></DD>

First, the word "arguments" refers to items listed in parentheses after a function name.  There there are both <em>formal</em> arguments and <em>actual</em> arguments.  Formal arguments appear in the functions declaration and definition.  So in line 3 above <code>b</code> is the second formal argument to <code>five()</code>.  Actual arguments are the items listed in a call to the function within the code.  <code>five()</code> is called on the second to last line of the program.  The second value there is <code>two</code>, a local variable.  So at this call <code>two</code> is the second actual argument. </p>

The formal arguments are placeholders.  The actual arguments are what goes in the placeholder at a particular point in run time.  So <code>two</code> is associated with the formal argument <code>b</code> at that call to the function.</p>

<li>Fast, Flexible, Portable</li>
<blockquote class="quote"><em>Rule of Thumb #13. Learn a fast language, such as C or Fortran.</em><br>Use Google to find author</blockquote>

<DT>What is meant by <em>Fast</em>? </DT>

This chapter suggests that rule-of-thumb #13 is not very helpful.  This chapter is a guide for using languages like Ox (or Matlab or Python) so that your code's speed compares to the code you could write in C or FORTRAN.  A few hours thinking about the topics discussed here and using them to write your own code can save you weeks of waiting for results or weeks of re-coding your problem in another language because your code takes longer than you think.</p>

We have already discussed the first step required to understand this issue: C/FORTRAN are compiled languages.  Ox/Matlab/R/Python are interpreted languages. Their interpreters are programs written in a compiled language, so they derive their efficiency in computing from a program written in another language by another person (or group of people).  This can make interpreted language appear slower than compiled ones, but it depends on several factors.</p>

The previous chapter also discussed another aspect of speed.  A proper accounting for the time taken by the programming cycle includes not just how long <code>RunTime</code> takes, but all the time from an idea to a finished result.  In some cases this may be primarily <code>RunTime</code>.  If the problem is very similar to things you have already programmed (or someone else has programmed it, so you can use a <em>canned</em> package), but it involves a lot of computation, then you only care about how long production runs take. An example in econometrics might be a Monte Carlo or bootstrap computation on a simple data generating process.</p>

Otherwise, a full accounting for speed includes time spent coding (and debugging) as well as <code>RunTIme</code>.   Rule of Thumb #13 suggests it is better to pay the upfront cost of learning a compiled language.  Having paid that upfront cost you will not later on be stuck with high marginal cost of a seemingly slow derived language during your production run.  But everyone would agree that there is a limit to that argument.  Why stop with a language like C? Why not learn to program in assembly language to wring out even more inefficiency from your code?  No one advocates that solution because the fixed costs swamp the reduction in marginal cost, but in many cases decreasing returns kick in to rule out using compiled languages.  </p>

Another way to pay an overhead cost to avoid high marginal costs later on is to <em>study this chapter and learn the lessons in it.</em>  For most problems these lessons allow you to have the best of both worlds:  use of a convenient interpreted language that avoids pitfalls into glacial execution times.</p>

<h4>Flexible Flyer: Write Code that can be reused and relied upon</h4>

As a young economist how will you use the computer to do your research?  This is difficult to answer, but here are some extreme cases.  First, you may end up using the same framework over and over again.   In this case it makes sense to write code specific to that task and to optimize its execution speed.  That is, you plan to stay in <code>CodingTime</code> for a short time.  If you spend two weeks optimizing the code and use it over and over again you might save yourself months of time waiting for the code to finish.</p>

On the other hand, you might end up working on many different kinds of model which require very kinds of computation.  In this case you will end up spending a long time in <code>CodingTime</code>.  You will not find it worthwhile to squeeze out all the computational inefficiency in each project because it which enter <code>ProductionTime</code> once.  Two weeks optimizing the code may save you two hours of computing time.</p>

Most people fall in between these extremes.  As a researcher you will probably adopt one or two approaches (paradigms, frameworks, etc) to answer economic questions.  But within your chosen approaches you will be continually changing the details of your model, and therefore your code. In this case you would like to balance the concern for computational efficiency with programming flexibility.  Ideally you program the shared aspects of your models once and efficiently, but it should be done in such a way that making changes do not require going back to the beginning.  One important reason to avoid this is that every time you change your code there is a risk that new bugs are introduced.  But if you can reuse the same basic code and modify only details you can limit the chances that changes cause errors.</p>

Perhaps the best way to follow this strategy is to use <em>object oriented programming</em>.  Later in this chapter OOP will be introduced and emphasized. One very important by-product of good OOP code is that your code can be shared with other people with some chance that they can modify and expand it easily, at least easier than if they have to tweak all your code to do something different.</p>

Let $f(x)$ be a function of a single real number $x$.  We can write this more formally as $f:\Re\to\Re$.  To begin, we want to use the cube-root of $x$:
$$f(x) \equiv x^{1\over 3}.$$</DD>
A symbolic function can be represented on a computer as a sequence of instructions to be applied to an input value.  The steps are machine instructions in a computed language, and pseudo-instructions in an interpreted one.  The program that works with $f(x)$ has to be able to run these instructions from different places in the code and to send different values of $x$.  Finally, the value of $f(x)$ computed by the instructions has be retrievable.</p>

In Ox and all other languages, you can compute $x^(1/3)$ <em>inline</em>:  <code>x^(1/3)</code>.  If we are translating a symbolic model into a computer program then using inline operators has a potential drawback. If we wish to change $f(x)$ from the cube root of $x$ to something else, but otherwise leave the rest of the model the same, we have to find every use of it in the code and replace it.</p>

<DT>Inline coding of a named function is a bad idea</DT>
<DD><pre>
-----------------------------------------------------------------
    x = 5.0;
    ...
    y = x^(1/3) - z;
    ...
    z = 25 -3*y^(1/2);   // is this the square root of y, or a typo??
    ...
</pre></DD>
All computer languages have a syntax for calling functions, sending input values and receiving output values.  In Ox we can then simply code $f(x)$ as a an Ox function.</p>

<DT>Use <code>functions</code> to code functions.</DT>
<DD><pre>
   Version 1                  Version 2               Version 3
----------------------------------------------------------------------
f(x) {                     cubert(x) {              f(x,av) {
   return x^(1/3);            return x^(1/3);        av[0] = x^(1/3);
    }                         }                      return TRUE;
                                                     }
...                        ...                      ...
y = f(8.0);                y = cubert(8.0);         ok = f(8.0,&y);
</pre></DD>
Each of these code segments are valid ways to represent $x^3$ in Ox.
    <details class="aside"><summary>Floating Point</summary>Recall from the puzzle that opened this book that it is possible that these values are not exact.  In particular, <code>0.001<sup>1/3</sup></code> will not be exactly <code>0.1</code> because in the program <code>0.001</code> and $x^3$ are both floating point reals.</details>
The first two versions are almost identical, and both allow the program that uses the function to assign the value of the function to a variable.  So in both cases <code>y</code> would hold the value <code>2.0</code> in after the line is executed.  The routine is <em>passed</em> $x$ stored as a FPR and returns another FPR as an numerical approximation to $f(x)$.  The only difference between Version 1 and Version 2 is the name we give function: the generic <code>f()</code> or the specific <code>cubert</code>.  Which kind of name to use depends on the role $f(x)$ plays in your model. If $x^{1/3}$ is really basic to your model, in the sense that it makes no sense to use another function, then it makes sense to use a name like <code>cubert()</code>. </p>

In essence, you are "binding" the specific name to the function because they go together.  However, if $x^{1/3}$ is just a convenient form and you might want to solve your model for other forms of $f(x)$, then the generic name is better. That way, if down the road you switch to, say, $f(x)=\ln x$, the reference in the rest of the code to <code>f()</code> is still clear, whereas the specific name <code>cubert</code> would now be misleading.</p>

One difference between the first two is the name.<code>cubert()</code> is a more descriptive name for this function because it says what function is (the cube root of its argument).  But that is not necessarily better.  What if we later decided to study $x^{1/4}$ with the same program? In the first case the name $f(x)$ is not misleading and we simply change it to return $x^{1/4}$.  But <code>cubert()</code> becomes a misleading name, which may end up with errors if the change in the exponent is forgotten. </p>

So which name is better depends on the context.  If the main program is meant to deal with an arbitrary function then <code>f(x)</code> is better because it is generic.  But if the function is going into a library to be used across many programs, and it was always be $x^3$, then the name <code>cube()</code> is better.  </p> 
The other difference is that the first uses floating point multiplication (<code>x*x*x</code>) and the second uses the Ox exponent function, $x^3$.  They do return the same value but internally they are different calculations.</p>

Version 3 is different.  Now the value of the function is returned to the main program through a second argument, <code>av</code>.  As discussed earlier, output arguments in Ox must be <em>addresses</em>.  So the function's code assigns $x^3$ to the variable pointed to by <em>av</em>.  The return value is still set, in this case to <code>TRUE</code> or <code>1</code>. This is closer to the way that built-in Ox procedures want functions to be defined.  The reason is that the function can tell the program whether the function evaluation can be trusted. <code>TRUE</code> is returned because built-in Ox procedures typically expect the user's function to return 1 (<code>TRUE</code>) if everything is fine and 0 if the evaluation of the function failed. </p>

For example, consider writing and using a function $(x)^{1\over 3}$.  Now this function is not defined (as a real function) if $x=-3$. We could write our code to simply kill the program based on a numerical exception.  But it may be preferred to let the program continue to run but deal with the fact that the function value was undefined.
<DD><pre>
cubert(x,av) {
   if (x &t;= 0) {
      av[0] = x^(1/3);
      return TRUE;
      }
   av[0] = .NaN;
   return FALSE;
   }
&vellip;
if (f(x,&y))
   //proceed, y holds x^(1/3)
else
   // deal with negative x, y holds .NaN
</pre></DD>
In the case of a negative value of <code>x</code>, <code>cubert()</code> assigns .NaN to <code>av[0]</code> but also sets the flag to <code>FALSE</code> so that the program that set a negative value might be able to address.  This can be very important. For example, suppose the main program is searching for values of $x$ that satisfy some condition.  Then it needs to know that $x=-3.0$ is not valid when dealing with cube roots, but if $f(x)$ were plain old $x^3$ it would not be a problem.  Returning both a <code>valid argument flag</code> and the value of the function if the argument is valid allows the program to continue searching even after trying an invalid $x$.</p>

Now consider the generalization:
<DD>$$g_n(x) = x^{1/n}.$$</DD>
Here there are now two quantities that may take on different values, $x$ and $n$.  The notation is used to suggest that the value of $n$ is, in some sense, fixed first and then values of $x$ are used.  This is different than writing $g(x,n)$, which suggests that both $x$ and $n$ are varying simultaneously.  In the first notation we often would call $n$ a parameter of the function and $x$ the argument.</p>

Your Ox code can reflect this difference between $n$ and $x$.
<DD><pre>
   Version 4             Version 5           Version 6
--------------------------------------------------------
const decl n=3.0;        decl n;             g(x,n=3.0) {
g(x) {                   g(x) {                 return x^(1/n);
  return x^(1/n);          return x^(1/n);      }
  }                        }
...                      ...
y = g(x);                n = 3.0;             y = g(x);
                         y = g(x);            z = g(x,4.0);
                         n = 4.0;
                         z = g(x);
</pre></DD>
As with Versions 1-3, none of these ways to code $g(x)$ is wrong, but depending on the way the function is to be used, one method will be better (more reliable) than the others.  In the first case, the parameter $n$ is declared a global constant.  This binds the value 3.0 to <code>n</code> at <code>CompileTime</code>.  The only way to set <code>n</code> to a different value is to change the code.  </p>

Version 5 uses a global too, but it is not <code>const</code>.  So its value is bound at <code>RunTime</code> and can be changed while the program executes.  This can be good or bad.  It is bad if it should not change, because then a typo in the code (<code>n = 33;</code> not <code>m = 33;</code>) will cause confusion and incorrect output.</p>

Version 6 does not use a global value for <code>n</code>, so it looks more like $g(x,n)$, except that it uses Ox's <b>default-value</b> feature. The user can call <code>g(x)</code> or <code>g(x,n)</code>.  If $n$ is not provided then the default value of 3.0 will be used.  Unlike Version 5, in which the global parameter is changed and is then in effect for every subsequent call to <code>g(x)</code>, the value of <code>n</code> passed in Version 6 just applies for that function evaluation.</p>

A final version of a way to code a parametric function that uses <em>objects</em> is discussed later.</p>


</OL>
</OL>
<h2><a name="s032"><LI>Life in the Fast Lane<br/>&emsp;High Performance Computing</a></LI></h2>
<blockquote class="toc"><h4>Contents</h4>
<OL type="1" class="toc3"">
<LI><a href="s033.html" target="content">Avoid Overhead</a></LI>
<LI><a href="s034.html" target="content">One Way or Another<br/>&emsp;Parallel Execution</a></LI>
<DT><a href="ex009.html" target="content">Exercises</a></DT>
</OL>
</blockquote>
<OL  type="1" ">
<h3><a name="s033"><LI>Avoid Overhead</a></LI></h3>


<DT>Interpreted languages have overhead costs in terms of computational time relative to compiled languages.  </DT>
 <DD>The reason is simple but the implications are not as simple as: compiled languages = fast, interpreted languages = slow.  This section builds up a way to see the costs of overhead.</DD>

<DT>To simplify the discussion, the term "i-code" refers to a program in an interpreted language and "c-code" to one in a compiled language that does the same thing.</DT>

<DT>First, the reason interpreted languages have overheads is because code written in them does not get translated to machine code.  </DT>
<DD>It gets interpreted by other machine code.  So on top of the instructions to do the job there must be instructions to do the interpreting.  </DD>
<DD>Thus, in principle, i-code must run no faster equivalent c-code.  But how much slower matters a great deal on what the code is doing and who wrote both programs (in the sense of how skilled they were and their concern for execution speed).  </DD>
<DD>The "in principle" qualification is that the two codes are both equally well-crafted and optimized for speed.  </DD>
<DT>If, instead, suppose two conditions hold.  </DT>
<DD>First, the interpreter was written and compiled with great care and the i-code it is running is written carefully.  </DD>
<DD>Second, the c-code was written by a neophyte economics graduate student.  </DD>
<DD>Then it is quite possible that the i-code will get the job done as fast or even faster than the c-code.  </DD>
 <DT>It is also quite likely that the i-code would be much easier for the neophyte to write and debug if, for example a mathematical i-language is used.</DT>
    <DD>And for a neophyte to write good c-code for a complex problem to exploit the inherent speed advantage of a compiled language may required much more <code>CodingTime</code> than using a good interpreted language.</DD>

<DT>Let's see this in action.  </DT>
<DD>You can do this demonstrate yourself if you have a complete tool box described earlier, including <code>Ox</code> and <code>gcc</code> running on the same Unix machine.  As before, we start with two very short and not-quite identical Ox and C programs:</DD>

Loops c-loop.c ox-loop.ox

<DD><em>I could loop for 10,000,000 years</em>
<pre>
gcc c-loop.c ./a.out
    Experiment 1.  1 loop, 10 million trips
        time = 0.260000 ; x=100000000

    Experiment 2.  1 loop, 10 million trips, entering a loop each time
        time = 0.430000 ; x=100000000

oxl ox-loop.ox
    Experiment 1. 1 loop, 10 million trips
            time= 11.81 ; x=100000000
    Experiment 2. 1 loop, 10 million trips, entering a loop each time
            time= 26.04 ; x=100000000
</pre></DD>

<h3><a name="s034"><LI>One Way or Another<br/>&emsp;Parallel Execution</a></LI></h3>

<DT>The CPU in Tim, our basic computer introduced earlier, executes commands stored in RAM one at a time.  This is <defn>serial execution</defn>.
    <DD>The apparent ability to do more than one thing at once is due to a timesharing operating system and the speed of the instruction cycle compared to the slowness of human perception. </DD>
    <DD>Of course, most  computers today have more than one processor and can perform true <defn>parallel execution</defn>.
    <DD>There are well-established ways to get separate CPUs to coordinate.  When a computer has, say, a quad-core CPU it means four different (usually identical) processors are executing instructions at once.  </DD>
     <DD>The operating system can manage which programs run on which core.  For example, your web browser might be running on core 1 while you watch a movie shown to you by core 3.  This type of parallel execution is unimportant for our purposes, because a program would execute in serial on a single core.  </DD>
<DT>Parallel execution matters if it can be harnessed by your program to finish more quickly. </DT>
<DD>Taking advantage of parallel hardware to reduce <code>WallClock</code> time can be a challenge because some algorithms and some operations do not lend themselves to parallel execution.  </DD>
<DD>That is, parallel execution does not reduce the total number of instructions required for an algorithm to finish.  </DD>
<DD>Instead, parallel execution usually results in more instructions to get the job done both to coordinate the multiple nodes and because some instructions may be redundant.</DD>

<DT>In the worst case, a program runs on two processors at once and simply carries out the algorithm  twice.  </DT>
 <DD>In this case the total number of instructions is doubled and the <code>WallClock</code> time is identical.
 <DD>In the best case each processor carries out half of the original instructions so the total number is the same but the <code>WallClock</code> time is cut in half.</DD>
  <DD>In practice, most algorithms used in economics will fall somewhere between those two extremes in terms of gains from parallel execution.  Some parts of an algorithm are easy to run in parallel and some are not.  This makes parallel execution somewhat difficult to understand and to implement on ones own.</DD>

<DT>One way to distinguish types of parallel execution is between <defn>shared memory</defn> and <defn>distributed memory</defn> processing. </DT>
 <DD>With shared memory your program is running on two or more processors that access the same memory cells.  So if one processor stores $x$ is a memory cell the other processor can access that memory cell directly while it executes. </DD>
 <DD>On the other hand, with distributed memory each processor has its own cell for $x$ and cannot access the other memory cells directly.</DD>
<OL class="section">
<LI>Low-Level: Multi-Threading</LI>

<DT><defn>Multi-threading</defn> is an important way in which shared memory parallel execution is implemented.  </DT>
 <DD>The idea is not difficult to understand, but the hardware and software support required to make it work is complex, for the same reason that too many cooks spoil the broth.  </DD>
 <DD>Multi-threading means that your program will run in serial mode on a single processor until it reaches a point where the algorithm can exploit parallel execution.  The program then splits into two or more threads, each executing the same segment of code from your program but for different parts of the shared memory.  </DD>
 <DD>Once that segment has been completed by all the threads they terminate and return back to a single thread working in serial.</DD>

 <DT>Multi-threading is low-level and must be handled by the compiler.</DT>
Note: Ox version 7.0 <em>Professional</em> is compiled with a multi-thread aware C compiler.  So you can tell it to use all your processors.

<h3>Multi-Threading.</h3>
 <DT>With multiple CPUs sharing the same core (RAM) some segments of code can be done simultaneously.</DT>
 <DD>Multi-threading a vector operation
<pre>
    float x[200], sum;         ===>     CPU1                        CPU2
    ...                                 -working-                   -idle-
                                                         -split-
    sum = 0.0;                          sum1=0.0                    sum2 = 0.0
    for (i=0; i<200; ++i)               for (i=0; i<99; ++i)        for (i=100; i<200; ++i)
        sum = sum + x[i];                   sum1 = sum1 + x[i];           sum2 = sum2 + x[i];
                                                         -rejoin-
                                        sum = sum1+sum2;             -idle-
</pre></DD>

<DT>Limitation: dependency. </DT>
<DD>Expressions depend on previous results, or calls to user-defined functions.</DD>
<DD><pre>
    float x[200], z[200];
    for (i=1; i<200; ++i)           for (i=2; i<200; ++i)
        {                               {
        x[i]= 0.5*x[i-1]+z[i];          x[i]=myfunc(x,i);
        }                               }
</pre></DD>


<LI>High Level: Message Passing Interfaces</LI>

<DT>Distributed memory parallel execution is typically less complex to implement because it does not involve a single set of instructions splitting into separate threads and then rejoining again.  </DT>
<DD>In fact, it is possible to implement distributed memory parallelism without any special tools as long as the processors can communicate somehow.  </DD>
<DD>But typically distributed memory parallelism requires more intervention from the programmer.  The compiler cannot coordinate the actions by itself.</DD>

<DT>High Level Parallelism coordinates the activities of independent processors without shared memory.  </DT>
<DD>To achieve this efficiently an environment must be created to allow a user's program running on one CPU to communicate to another copy running on another CPU.  This is the MPI <em>environment</em>.</DD>

<h3>Client/Server Using MPI.</h3>

<DT>This paradigm involves point-to-point communication.  </DT>
<DD>It can be highly flexible (dynamic), thus efficient if the sub-tasks or hardware is heterogeneous.  But it require extensive programming and the use of tags to specify tasks.</DD>
<OL class="steps">
<LI>A single program is started on multiple "nodes" (separate memory).</LI>
<LI>Each copy gets details: its id and how many nodes there are.  </LI>
    <DD>One node (id=0) becomes the client; others are servers.  </DD>
    <DD>The program then splits.  The client executes client tasks and servers execute server tasks.  Since the copies of the programs are communicating from different points within the same program the messages must include information about the context.  </DD>
    <DD>This is handled by "tagging" each message with an integer code.  The user's program must send and receive the tags. </DD>
<LI>Servers wait for a task and input from the client; it sends results back with the same tag and waits for the next instruction.</LI>
<LI>The Client sends tasks and input to servers, waits for output, uses it. It then repeats this process as the algorithm progresses.</LI>
<LI>Client decides the job is complete; it sends a STOP message (or a STOP tag) to all servers.</LI>
<LI>All copies of the program end.</LI>
</OL>

<h3>MPI: Peers and Group Communication.</h3>
<DT>This paradigm involves group communication.  </DT>
<DD>Coding is simpler that client/server but less flexible.</DD>
<OL class="steps">
<LI>A single program is started on multiple "nodes" (with separate memory).</LI>
<LI>Each copy gets details: its id and how many nodes there are.</LI>
<LI>Node 0 is first among peers (less differentiated than client/server)</LI>
<LI>Peers do work on their part of the job; share results (broadcast, gather, reduce).  No tags are needed because all peers are at the same line of code in the original program when communications occur. </LI>
<LI>Stopping point is reached and all end.</LI>

<h3><a name="ex009"><LI>Exercises</a></LI></h3>
<h3>Exercises</h3><OL class="steps">
<LI>Remove the <code>#include</code> directive in <code>hello-world.ox</code> and see what happens.</LI>
<LI>Run the program below.  It should produce an error.  Explain why.<DD><pre>
#include "oxstd.h"
main() {
  decl case;
  case = 5;
  }</pre></DD>
</LI>
<li>Explain why the program below is not a complete Ox program.
<dd><pre>program() {  decl x;  x = 5;  }</pre></dd>
</li>
<LI>Copy this code to OxEdit. Fix the errors with comments so that it produces hello world.</LI>
<DD><pre><code>
#include "oxstd.h"
*/  A comment  /*
/*
main() {
// println(
"hello, world"
);
}
</code></pre>
<LI>Mark each of the following as valid or invalid Ox identifiers</LI>
<dd><pre>
               Valid            Invalid
a
a1
1a
a_1
_a_1
doit!
b c
ABC
</pre></dd>
<li>Explain the output of this program including warnings.
<DD><pre>
#include "oxstd.h"
main() {
    decl v = <0; 1; 2>;
    v[1] = 4;
    println("v=",v);
    decl A = <0, 1; 2, 3>;
    A[1] = 4;
    println("A=",A);
    }</pre></DD> </li>
<li>Explain the difference between postfix and prefix incrementing by explaining the output of this program
<DD><pre>
#include "oxstd.h"
main() {
    decl i;
    i = 5;
    println(i);
    println(i++);
    println(++i);
    println(i);
    }</pre></DD> </li>
<LI>Use <code>scan("%g",&x)</code> in a program to read in a number.  If it is bigger than 0 print out the log of x.  If it is less than or equal to 0 return a message that says the log of x is undefined.</LI>
<LI>Use scan to enter a number <code>x</code> and the conditional expression <code>? :</code> to store in another variable <code>0</code> if <code>x &lt; 10</code>, <code>1</code> if <code>10 &le; x &lt; 100</code> and <code>2</code> if <code>x &ge; 100</code>.</LI>
<li>Use a <code>while()</code> loop to compute the average value of a vector then print it out.</li>
<li>Use a <code>while()</code> loop to compute the largest value in a vector then print it out.</li>
<LI> In the <a href="http://www.doornik.com/ox/oxsyntax.html" target="_blank">Ox Syntax Reference</a> find the <code>GOTO</code> statement. Below is code to print the first 50 non-negative integers using <code>if()</code>  and <code>goto</code>.  Move the
  label <code>TOP</code> so that this becomes an infinite loop.  And then replace the loop with a correct <code>for()</code> loop.
  <DD><pre><span class="fname"><em><a href="./code/goto-no-no.ox" download>goto-no-no.ox</a></em></span>
<object height="200" width="95%" type="text/plain" data="./code/goto-no-no.ox" border="1"></object></pre></dd>
</LI>
<LI>Exercise: What output will be produced by <code>seven.c</code>? By <code>sevenb.c</code>?</LI>
 <LI>Start with this code. Go through the edit/compile/debug/execute/debug cycle, until the program runs and produces correct output.</LI>
  <DD><pre><span class="fname"><em>bang-head-wall.ox</em></span>
  <object height="100" width="95%" type="text/plain" data="./code/bang-head-wall.ox" border="1"></object></pre></dd>
<LI>Run this code and verify an error occurs.
<dd><pre>
   decl v;
   f() {
       v = 5;
       y = 6;
       }
   decl y;
   g() {
       y = 7;
       }
   main() { }  </pre></dd>
Then Move the declaration of the global <code>y</code> above the first reference to it and see if the error goes away.</LI>
<LI>Run the program below. It creates a popular game played by two or four players.  Then add a global variable called <code>rally</code>.  Change the code so that <code> rally</code> counts how many rallies have occurred.  Have the rally end after 10 volleys.
<DD><pre>
 #include "oxstd.h"
 ping();
 pong()  {
     println("pong");
     ping();
     }
 ping()  {
     print("ping-");
     pong();
     }
 main() {
     ping();
     }               
 </pre></DD> </LI>
</OL>
</OL>
</OL>
<h1><a name="s035"><LI>Digital Mathematics and Statistics</a></LI></h1>
<blockquote class="toc"><h4>Contents</h4>
<OL type="A" class="toc2"">
<LI><a href="s037.html" target="content">Fundamentals</a></LI>
<LI><a href="s041.html" target="content">Non-Linear Systems</a></LI>
<LI><a href="s042.html" target="content">Optimization</a></LI>
<LI><a href="s045.html" target="content">Sliding Doors<br/>&emsp;Simulation &amp; Randomness</a></LI>
</OL>
</blockquote>
<OL  type="A" ">
<h2><a name="s037"><LI>Fundamentals</a></LI></h2>
<blockquote class="toc"><h4>Contents</h4>
<OL type="1" class="toc3"">
<LI><a href="s038.html" target="content">Blurred Lines<br/>&emsp;Linear Algebra and Linear Systems</a></LI>
<LI><a href="s039.html" target="content">Roll With the Changes<br/>&emsp;Differential Calculus</a></LI>
<LI><a href="s040.html" target="content">Add It Up<br/>&emsp;Integral Calculus</a></LI>
</OL>
</blockquote>
<OL  type="1" ">
<h3><a name="s038"><LI>Blurred Lines<br/>&emsp;Linear Algebra and Linear Systems</a></LI></h3>
<!-- -->
<OL class="section">

<LI>A Quick Review</LI>

<OL>
Matrices play very important roles in many economic theories, and one key application of them is to solve linear systems of equations.  This might sound like high school algebra or that it applies only to very simple economic models.  But linear systems are almost always embedded in dynamic, non-linear models.  So they underly many if not all sophisticated economic theories. A clear notion of how to handle linear systems numerically is essential for doing numerical economics, even if knowing the details of the algorithms is not important.  First, let's ensure we all agree on names for kinds of matrices.</p>

<h4>Matrix Taxonomy.</h4>
<DT>A real matrix $A$ has element $a_{ij}$ in row and column $j$. </DT>
<DD>We can define a matrix using a formula for the elements.  So $A_{n\times m} = [ a_{ij} ]$ means "$A$ is the $n\times m$ matrix with elements $a_{ij}$."  </DD>
<DD>This is a compact way of writing
$$A = \pmatrix{ a_{11} & a_{12} & \cdots &a_{1m} \cr a_{21} & a_{22} & \cdots & a_{2m}\cr
\vdots & \ddots & \cdots & \cr a_{n1}& a_{n2} &\cdots& a_{nm}}.$$</DD>
<OL class="steps">
<LI>"A is square" means $n=m$.</LI>
<li>When $n=1$ we say "A is a row vector."</li>
<LI>When $m=1$ we say "A is a column vector."</LI>
<LI>When $i < j \rightarrow a_{ij}=0$ we say "A is lower triangular."</LI>
<LI>"A is diagonal" means $i\ne j \rightarrow a_{ij}=0$.</LI>
<li>When $n=m$ and $a_{ij}=a_{ji}$ we say "A is symmetric."</li>
<LI>"A = I" means $n=m\ \&\ a_{ij}=\cases{ 1 & i=j \cr 0 & i<>j\cr}$</LI>
</ol>

Next, let's agree on things to do with matrices.

<h4>Matrix Operators and Functions.</h4>
Given $A_{n\times m} = [a_{ij}]$ and $B_{r\times s} = [b_{ij}]$.
<ol class="section">
<LI>$A' = A^T = [a_{ji}]$.</LI>
<LI>$A+B = \left[a_{ij}+b_{ij}\right]$, which requires $n=r, m=s$.</LI>
<LI>$AB = \left[\sum_{k=1}^m a_{ik}b_{kj}\right]$ which requires $m=r$. </LI>
<LI>$A \circ B = A^T B = \sum_{j=1}^n a_{j1}*b_{j1}$, which requires $n=r, m=s=1$.</LI>
<LI>$A\ .\circ B = \left[ a_{ij}b_{ij}\right]$, which requires $n=r, m=s$.</LI>
<LI>With $n=m$, $A^{-1}$ is the matrix: $A^{-1}A = AA^{1} = I_n$.</LI>
<LI>$\det\{A\}$ or $|A|$ is a function $\Re^{n\times n}\to \Re$ defined recursively as:</LI>
<ol class="steps">
<li>$n=1 \rightarrow |A| = a_{11} \qquad n=2 \rightarrow |A| =  a_{11}a_{22}-a_{21}a_{12}$</li>
<LI>$n=3 \rightarrow  |A| = +/-$ 6 products of 3 matrix elements.</LI>
<li>&vellip;</li>
<LI>$|A| = $ sum of products of $n$ elements of $A$.  That is, the determinant is a nth order polynomial in the elements of $A$. So there are $n$ roots to an equation that sets $\det(A)=0$, allowing for repeated and complex roots.</LI></ol>
</ol>
</OL>

<li>Matrices in C then Gauss/Ox/Matlab/R</li>

Back in the 1990s when Ox was developed one of its major attractions was the fact that a matrix was a <em>native type</em> in Ox.  That is, it really understands a matrix.  </p>

Here is a quick example. In least squares regression, the OLS estimates of the coefficients is the well known formula $\hat\beta = \{X'X\}^{-1}X'y.$ The predicted vector is $\hat y = X\hat\beta$, the estimated error vector $e = y-\hat y$.  And the OLS estimate of the variance of the error term is $\hat\sigma^2 = (e'e)/(N-K)$, where $N$ is the number of rows in $X$ and $K$ is the number of columns. A user of Ox could duplicate these formulas for their own data with code that looks very similar to the symbolic results:
<dd><PRE>
decl N,K,X, y, bhat, yhat, e, sig2hat;
X = loadmat("X.mat");
y = loadmat("y.mat");
N= rows(X);
K = columns(X);
bhat = (X'*X)^(-1) * X' * y;
yhat = X*bhat;
e = y-hat;
sig2hat = (e'*e)/(N-k);
</PRE></dd>

The few textural differences include: Vvariables must be declared before they are used, which is not required in symbols, but usually the text wrapped around the symbols would explain/declare each variable.  Since <code>'</code> is not allowed in variable names in Ox, it is okay to denote transpose as <code>X'</code>: that cannot possibly be a variable with the name <code>X'</code>. In symbolic math variable names consist of one letter so that can just mean post-multiply $X$ by $Y$.   So $XY$ is symbolically the operation of pre-multiplying $Y$ by $X$.  But in Ox the lexical analyzer will think that <code>XY</code> is a variable, so <code>*</code> is used.  Ox programs are plain text files, so powers must be denoted <code>^{-1}</code> instead of either human written or typeset superscripts.</p>

Compare this to general purpose languages of the 1990s, C and FORTRAN.  In them, there is no notion of a matrix.  There are two-dimensional arrays of floating point reals which work to store a matrix.  But matrix operators are not built in.  And the matrix type, as we understand it symbolically is not <em>native</em> to C.  So a C programmer would have to write functions such as <code>matmult(X,Y)</code>, <code>matinvese(X)</code>, and so forth.  If this were done already, the C code to compute $\hat\beta$ might look like
<DD><pre>
bhat = matmult( matmult( matinverse( matmult(trans(X),X)), trans(X) ) , y);
</pre></DD>
There were (and are)  "math packages" or libraries of functions that free a programmer from having to program the basic operations, but the symbolic expression would not translate as closely to a programming expression.</p>

<h4>Element-by-element Operators and Other Matrix Functions</h4>

<DT>In basic matrix algebra:</DT>
 <DD>$AB$ is matrix multiplication as defined above which involves multiplying and adding rows and columns.
 In Ox, <code>A*B</code> is equivalent to matrix $AB$. </DD>
 <DD>Meanwhile $A+B$ is defined as the simple element-by-element addition of the two matrices, and in Ox
 <code>A + B</code> does the same thing.</DD>
 <DD>There is typically no need to define element-by-element multiplication of two matrices in symbolic algebra.</DD>

<DT>However, in computing it is often very convenient to apply scalar operators to matrices.</DT>
 <DD>Ox, like some other Matrix languages, puts a period in front of operators to indicate element-by-element.</DD>
 <DD> When an operator is applied to two matrices with the same dimensions, the Ox syntax references shows you what to expect.  That is,
 <pre>
    A              B            C
 matrix   .op    matrix   =   matrix    = a<sub>ij</sub> op b<sub>ij</sub>
 m x n           m x n        m x n
</pre></DD>
<DD> In other words, <code>A .* B</code> is defined as the matrix $C$, where $c_{ij} = a_{ij}\times b_{ij}.$
<pre>
  0   1    .*   1  -1    =     0   -1
  2   3        -1   1         -2    3
</pre></DD>
<DD><code>+</code> and <code>-</code> are already dot-operators, so you don't need to write .+.</DD>
<DT>Dot Operators Can Produce Runtime Errors</DT>
<DD><code>A .* B</code> is not defined if A is 2x3 and B is 2x4.  Just as in other cases, there has to be a matching of elements for the operation to work.</DD>
<DD>However, if one of the matrices is a vector the dot-operators will not produce an error.</DD>

<DT>Putting a column vector on the right side of a dot-operator is the same as if you had used a matrix with $n$ copies of the column.</DT>
<DD><pre>
    A                y            C
 matrix     .op    matrix   =   matrix    = a_<sub>ij</sub> op y<sub>i</sub>
 m x n              m x 1        m x n

  0   1  2   .*     1       =   0  -1  2
  2   3  2         -1          -2  -3  2
</pre></DD>
<DD>You will get an error if the number of rows of $y$ are not the same as $A$.</DD>

<DT>You can post-multiply by a row vector too, but then its columns has to equal the left argument.</DT>
<DD><pre>
    A                y            C
 matrix     .op    matrix   =   matrix      = a_<sub>ij</sub> op y<sub>j</sub>
 m x n              n x 1        m x n

  0   1  2   .*    1 -1 0     =   0  -1  0
  2   3  2                        2  -3  0
</pre></DD>
<DD>THIS CAN BE CONFUSING:  it matters whether you multiply by a row or column vector.</DD>

<DT>The Table in the Ox Syntax Reference shows that pre-multiplying by a vector produces similar results.</DT>

<DT>Dot Operators on Two Vectors Can Produce a Matrix or a Vector</DT>
<DD>If the two vectors have the same shape then they must have the same length and the result is the same shape.</DD>
<DD>If one vector is a row and the other a column a matrix is created:
<pre>
     y        .op      z       =       C         =  y<sub>i</sub> op z<sub>j</sub>
   m x 1             1 x n           m x n

     y        .op      z       =       C         =  y<sub>j</sub> op z<sub>i</sub>
   1 x n             m x 1           m x n
</pre>
So the result gets its row size from the row vector (whether it is the left or right argument) and its
column size from the column vector.</DD>

<DT>Other mathematical functions will work on matrices</DT>
<DD><code>exp(A)</code> is the matrix of exponents.  That is, its <code>ij</code> element equals $\exp(a_{ij})$.</DD>
<DD></DD>

<LI>Linear Systems</LI>
<OL>
<LI>Linear = Easy</LI>

One of the conveniences of linear systems is that the dimension of the system does not alter the basic notions.  Most of what can be said for square $n\times n$ linear systems is a direct analogue to what can be said of a scalar $1\times 1$ system.

A scalar system can be written</p>
$$ax = b,$$
where $a$ and $b$ are given real numbers and $x$ is an unknown quantity. This system has a unique solution for $x$ as long as $a\ne 0$.  Then the solution is obviously $x = b/a = a^{-1}b.$  If $a=0$ then it is not <em>invertibile</em> and there are two possibilities depending on $b$.  If $b = 0$ as well then <em>any</em> value of $x$ is a solution to the system ($0x=0$), so instead of one solution we get an infinite number.  If $a=0$ but $b\ne 0$ then there is no solution to the system.</p>

So in a scalar system there are either 0, 1 or infinite values of $x$ that solve the system.  Which case applies depends on a single number, $a$ and if $a=0$ then the value of $b$ also matters.When we generalize to $n$ dimensional linea rystems the only difference is what number plays the role that $a$ does in the scalar system. </p>

You know this number as the <em>the determinant</em> of the matrix.</p>

<li>Linear Solutions</li>

<DT>Given $A$ (square) and $b$, is there an $x$ such that</DT>
<DD>$$\mathop{A}\limits_{_{n\times n}} \mathop{x}\limits_{_{n\times 1}} = \mathop{b}\limits_{_{n\times 1}}?$$</DD>
<OL class="section">
<LI>These are equivalent statements</LI>

<DT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &laquo;No row of $A$ is a linear combination of the other rows&raquo; </DT>

<DT>$\Leftrightarrow\quad$ &laquo;No column of $A$ is a linear combination of the other columns&raquo;</DT>

<DT>$\Leftrightarrow\quad$ &laquo;$|A| \ne 0$&raquo;</DT>

<DT>$\Leftrightarrow\quad$ &laquo; $!\exists A^{-1}: A^{-1}A = I$&raquo;</DT>

<DT>$\Leftrightarrow\quad$ &laquo;$!\exists\ x= A^{-1}b$&raquo;</DT>

<LI>These are equivalent statements:</LI>

<DT>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&laquo;At least one row of $A$ is a linear combination of the other rows&raquo;</DT>

<DT>$\Leftrightarrow\quad$ &laquo;At least one column of $A$ is a linear combination of the other columns&raquo;</DT>

<DT>$\Leftrightarrow\quad$ &laquo;$|A|= 0$&raquo;</DT>
<DT>$\Leftrightarrow\quad$ &laquo;$\not\exists A^{-1}$&raquo;</DT>

<DT>$\Leftrightarrow\quad$ &laquo;$b\ne 0\ \Rightarrow\ \not\exists\ x: Ax = b.$&raquo;</DT>

<DT>$\Leftrightarrow\quad$ &laquo;many $x$ satisfy $Ax=0$ (called the <em>null space</em> of $A$).&raquo;</DT>
</OL>

<DT>In standard mathematics for economics textbooks &hellip;</DT>
<DD>the solution to linear systems is connected directly to finding the inverse of $A$:
$$x =  A^{-1}b.$$</DD>
<DD>Alas, the computationally efficient method to solve the system does not rely on matrix inversion.  In fact, the reverse is true: matrix inversion relies on solving linear systems.</DD>
</OL>
<LI>Solving Linear Systems in the real world.</LI>
<OL>
<LI>Suppose $A$ is <em>lower triangular</em>.  Then solving for $x$ only requires a sequence of <em>forward substitutions</em>:</LI>
<DD>$\qquad\pmatrix{a_1&0&0&\ldots\cr a_2&a_3&0&\ldots\cr \vdots&\vdots&\ddots&0\cr}x = b \quad\Rightarrow\quad
\matrix{& x_1 &= b_1/a_1 \cr \downarrow&x_2 &= {b_2-a_2x_1}/a_3 \cr \downarrow & \vdots &\vdots \cr \downarrow& x_n &= {b_n-\sum_{i=1}^{n-1} a_{?}x_{i}/a_? }\cr}$
</DD>

<LI>Suppose $A$ is <em>upper triangular</em>.  Then solving for $x$ only requires a sequence of <em>back substitutions</em>:</LI>
<DD>$\qquad\pmatrix{a_1&a_2&\ldots&a_n\cr 0&a_{n+1}&a_{n+2}&\ldots\cr 0&0&\ddots&\ldots\cr 0&\ldots&0&a_?\cr}x = b \quad\Rightarrow\quad \matrix{& x_1 &=& {b_1-\sum_{i=2}^{n} a_ix_{i}/a_1 }\cr \uparrow &\vdots \cr  \uparrow& x_{n-1} &=&(b_{n-1}-a_?x_n)/a_? \cr \uparrow& x_n &=& b_n/a_? \cr }$
</DD>
<LI>Suppose $A = LU$, where $L$ is lower $\triangle$ and $U$ is upper $\triangle$.  Then</LI>
<DD>$Ly = b \quad\Rightarrow\quad y = L^{-1}b \qquad Ux = y \quad\Rightarrow\quad x = U^{-1}y = U^{-1}L^{-1}b$</DD>
</OL>

<DT>That is, to solve a triangular system requires N divides, N(N-1) multiplies.</DT>
  <DD>(It also requires N(N-1) subtractions but we will not count this operation.  </DD>
  <DD>The reason is that addition requires a much shorter instruction than multiplicative operations, so most of the cost is in those operations.). </DD>
  <DD>That is, a total of N$^{2}$ <em>FLOPS</em> (Floating Point Operations). </DD>
  <DD>Further, we know the system is invertible as long as the diagonal elements are non-zero.  </DD>
  <DD>If one is zero the corresponding division results in NUM$\infty$;. </DD>

<DT>Suppose $A$ is <em>upper triangular</em>.</DT>
    <DD>Then solving for $x$ only requires a sequence of <em>back substitutions</em> and N$^{2}$ operations: </DD>
    <DD>If $A$ factors into the product of two triangular matrices, and the two matrices are already known, then solving the system requires $2N^{2}$ operations.</DD>

<DT>Consider first the trivial case when $N=1$.  </DT>
<DD>Then we have scalars $Ax = b$ and therefore $x = b/A$.  </DD>
<DD>It is clear that any non-zero scalar A can be written as the product of two non-zero numbers, call them $L$ and $U$.  </DD>
<DD>Indeed, in the scalar case we can simply normalize $L=1$ and define $U=A$.  </DD>
<DD>In other words, when $N=1$ there is a decomposition of $A$ into two triangular "matrices". </DD>
<DD>If, on the other hand, $A=0$, then $U=0$ and it is not possible to factor the matrix and then solve, since this would involve dividing by 0.</DD>

<DT>Once we let $N$ be greater than 1 it is not so obvious that A can be factored into triangular matrices or how to go about doing it. </DT>
    <DD>However, the idea that elements of $L$ can be normalized might be intuitively clear.  </DD>
    <DD>There are $N(N+1)/2$ non-zero elements in a triangular matrix.  </DD>
    <DD>Two such matrices have a total of $N(N+1) = N^2+N$ elements, but the original $A$ matrix has only $NN$ elements.  </DD>
    <DD>So we have $N$ more degrees of freedom (free values) than we need for the factorization.  </DD>
    <DD>One way to reduce this freedom is to normalize $N$ elements of the two triangles.  </DD>
    <DD>Following our scalar example, we can normalize the diagonal of $L$ to consist of 1s.  Then together there are exactly $N^2$ free elements in L and U to just match the elements in A.</DD>

<DT>Fortunately, for the case of $N>1$ it has been known for decades that if $A$ is non-singular then we can indeed find matrices $L$ and $U$ for it.</DT>

<li>L-U Decomposition</li>
<DT>If $|A|\ne 0$ then:</DT>
<OL class="steps">
<LI>$\exists L, U: A=LU$ and $L$ is lower $\triangle$, $U$ is upper $\triangle$, and $L$ has 1s on its diagonal.</LI>
<LI>Since the diagonal of $L$ is normalized $|A| = |LU| = |L| |U| = 1\times |U| = \prod_{i=1,\dots N} u_{ii}.$</LI>
<LI>The matrices $L$ and $U$ for $A$ can be found numerically using an algorithm that fails only if $|A|=0$.  This will happen in the process at some row $i$ when $u_{ii}$ is too close to 0.  At that point the L-U decomposition will stop because it has discovered that the determinant of $A$ is 0.  Thus, instead of computing the determinant in order to solve a system of equations (as taught in math econ courses), computer algorithms compute the determinant as a by-product of solving the system.</LI>
<LI>The solution is numerically more accurate if <em>permutations</em> of the rows of $A$ are allowed.  That is, a permutation  matrix $P$ is the identity matrix $I$ with some of it is rows swapped.  The L-U algorithm will then produce 3 matrices such that $A = PLU$.</LI>
<LI>Since Ox allows a matrix to be indexed by a vector its LU code, <code>declu</code> does not have to return a $P$.  It simply returns a vector of indices indicating the new order of rows of LU to get back to the original rows of A.</LI>
</OL>

<LI>Solving $Ax=b$.</LI>
<OL class="steps">
<LI>Compute $P$, $L$ and $U$ for $A$ in the previous theorem.  If this fails then $A$ is not invertible.</LI>
<LI>Forward solve $Ly=b$ for $y$. </LI>
<LI>Backward solve $Uz = y$ for $z$.  </LI>
<LI>Rearrange rows: $x = Pz$.</LI>
</OL>

<h3>Why should you not compute $A^{-1}$ to (simply) solve $Ax=b$?</h3>
<OL class="steps">
<LI>Since $L-U$ depends only on $A$, the decomposition can be used to solve for different $b$'s.  </LI>
<LI> In fact, suppose you 5 different $b$ vectors to solve $Ax=b$.  Then you can put the column vectors into a matrix $B$.  The back/forward substitution process can be used to solve a matrix equation $AX=B$. Each column of $X$ will correspond to the vector solution for the corresponding column of $B$.</LI>

<LI>Suppose $A$ is $N\times N$.  Now think of applying the idea in the previous point where $B = I$, the identity matrix of order $N$.  We can get $A^{-1}$ by solving $AX = I$.  So solving a single linear system by first computing $A^{-1}$ involves $n-1$ unnecessary solutions.  So, in symbolic linear algebra we imagine finding a matrix inverse to solve a system of equations.  But a computer would typically find the inverse by solving $N$ linear systems.</LI>

<LI>There are many cases when $A^{-1}$ is needed for its own sake.  Or you have to solve for many vectors $b$ (more than $N$ different ones).  Then it makes sense to compute $A^{-1}$ and then use it solve the linear systems. Computing $A^{-1}b$ is quicker than back/forward solving once.  So use L-U to compute $A^{-1}$ then store for other calculations or use it for many $b$ vectors.  </LI>
</OL>

<li>Symmetric Matrices</li>
<DT>Let $A$ be a $n\times n$ symmetric matrix.</DT>
<OL class="steps">
<LI>A <em>quadratic form in $A$</em> is a scalar $v = z'Az$ where  $z \in \Re^n$.</LI>
<LI>$A$ is <em>positive semi-definite</em> if
$\qquad\forall\ z \in \Re^n,\quad v \ge 0.$</LI>
<LI>$A$ is <em>positive definite</em> if
$\qquad\forall\ z \in \Re^n,z\ne 0,\quad v > 0.$</LI>
</OL>

<h3>Cholesky Decomposition</h3>
<DT>Theorem: Let $A$ be a symmetric positive definite $n\times n$ matrix.  </DT>
<DD>Then there exists a {lower-triangular } matrix $C$ such that:\quad  $A = CC'.$</DD>
<DD>$C$ is the Cholesky decomposition of $A$. </DD>
<DT>The matrix $C$ is a matrix concept of <em>a real square root</em>, which is why it relies on positive definiteness.</DT>
 <DD>For such matrices computing $A^{-1}$ using $C$ is faster and more precis0e numerically than using LU.</DD>

<DT>The theorem extends to positive semi-definite matrices using a limit argument.</DT>

<DT>Any lower triangular $C$ with non-zero diagonal entries will generate a positive definite matrix from $CC'$.</DT>
<DD>  And any symmetric pos. def can be generated from some such $C$.</DD>
</OL>
<h3><a name="s039"><LI>Roll With the Changes<br/>&emsp;Differential Calculus</a></LI></h3>
<OL class="section">

<li>Background</li>
<DT>Calculus explains instantaneous smooth change.  </DT>
<DD>It relies on the notion of a <em>limit</em>: evaluating an expression as a quantity gets closer and closer to some value but never takes on the value exactly.  </DD>
<DT>In the case of derivatives:</DT>
 <DD>the expression is a ratio (the secant of a function) as the denominator (the change in $x$) goes to zero.   </DD>
<DD>At exactly $0$ change the ratio is undefined, but the limit is still well-defined because the ratio is never evaluate at $0$ exactly.  </DD>
<DT>In the case of integrals:</DT>
 <DD>the limit expression is the sum of areas of rectangles (or trapezoids) as the base of the shapes goes to 0 length.  </DD>
 <DD>At exactly zero each area equals zero, but in the limit the sum of the areas is the area under the curve.</DD>

<DT>Numerical calculus translates these concepts to computation using floating point reals (FPRs).</DT>
<details class="aside"><summary>Symbolic Math</summary>Programs like Maple and Mathematica can do symbolic math in infinite precision, but they are limited in the complexity of expressions they can handle.  They are not very useful for the kinds of problems we are concerned with.</details>
 <DD>It should seem a bit difficult to translate into digital computation.  As we have seen in the chapter on digital arithmetic, a floating point real cannot represent values arbitrarily close to 0 or any other given real number.  </DD>
 <DD>There is a smallest positive FPR that is not zero, which is not true in the (standard) symbolic real number system, $\Re$.  </DD>
 <DD>Further, computer arithmetic, such as taking a ratio, cannot produce reliable results anywhere close to the value of smallest positive FPR.  </DD>
 <DD>Instead, machine $\epsilon$ defined earlier, is how accurate floating point arithmetic is near 1.0.  With 64 bit FPRS $\epsilon$ is about $10^{-16}$.</DD>

<DT>This means that numerical calculus has two layers of approximation related to symbolic calculus. </DT>
<DD>First, floating point numbers are only an approximation to real numbers; and, </DD>
<DD>Second, limits can only be approximated by finite differences.  In the case of digital algebra covered in the last chapter, the concept of instantaneous change and approaching a limit are not necessary.</DD>

<DT>Eventually we will consider functions of several variables (or equivalently functions of a vector of real numbers).</DT>
  <DD>And we will consider functions that produce more than one number (a vector-valued functions).  </DD>
  <DD>For now we consider generalizations of the example above that still are conceptually simple functions of single values.  </DD>
  <DD>Software functions can both receive and send more than one argument.  And since an argument to an Ox function might be a <em>oxarray</em>, even one argument might actually specify many values to be used as input to the function.  </DD>
  <DD>Further, as discussed earlier, an Ox function that codes $f(x)$ could rely on<em>global</em> variables for input data.</DD>

<li>Love Minus Zero, No Limit</li>

<DT>Given a symbolic function $f(x)$ we can approximate it digitally with a software function, <code>f(x)</code> or in the form sometimes requested by Ox, <code>f(x,av)</code>. </DT>
 <DD>In this case, the value of the function is returned to address <code>av</code> and the function itself returns <code>TRUE</code> if $f(x)$ is defined and <code>FALSE</code> otherwise.  </DD>
 <DD>To understand a digital approach to the derivative of $f(x)$, first recall the definition. The derivative of real-valued function at a point $x$ is the slope of the function's tangent line. </DD>
 <DD>In turn, the tangent is the limit of the secant as the step size $h$ goes to 0.
    $$f^\prime(x) \equiv {df(x)\over dx} \equiv \lim_{h\to 0} {f(x+h)-f(x)\over h}.$$</DD>

<DT>In many cases an analytic form of the limit is known.</DT>
  <DD>If $f(x) = x^n$, then $f^\prime(x) = n x^{n-1}$, for $n \ne 0$.  </DD>
  <DD>This is an example of an <em>analytic derivative</em>.   </DD>
  <DD>Note that the derivative is itself a function of $x$. Since $f^\prime(x)$ is also a function it can be a <em>different</em> sequence of instructions. </DD>
  <DD>If $f(x) = x^2$ then $f^\prime(x) = 2x$ and we call $f^\prime = 2x$ an <em>analytic derivative</em>.

<DT>Symbolic math often deals with functions with no analytic expression.</DT>
  <DD>That is, $f(x)$ is defined <em>implicitly</em>.  </DD>
  <DD>Since a computer captures a function as a sequence of instructions, a function that is not analytic can still be <em>computable</em>.   </DD>
  <DD>We can compute derivatives of a {computable} function, using {numeric derivatives}. </DD>

<DT>To carry out the $\lim$ operation we might store $h$ as FPR in, say, 64 bits.  </DT>
 <DD>Any $h$ less than "machine precision"  cannot be distinguished from 0.  From then on, $h \doteq 0$ and the ratio is <code>NaN</code>. </DD>
 <DD>This might suggest: approximate $f^\prime(x)$  with ${f(x+\epsilon_m)-f(x)\over \epsilon_m}$.  The numerator is approximately 0 and very inaccurate.  Then we divide 0 or something close to 0 by something almost 0.</DD>
 <DD> The technical term for the result is <em>junk</em>.</DD>

 <DT>What is needed here is a finite difference (or <em>secant</em>) approximation to the tangent in which:</DT>
  <DD>$h$ is big enough to have plenty of bits available to reduce round-off errors </DD>
  <DD>but not so big that the curvature of $f(x)$ dominates.</DD>

<li>Central versus One-Sided Steps</li>

<DT>A straightforward translation of $f^\prime$ leads to
 <DD class="callout">$$f^\prime_{FD}(x) = {f(x+h)-f(x) \over h} \approx f^\prime(x).\qquad(FD)$$</DD>
 <DD>This is a forward-step derivative: add a small (but not too small) number to $x$. </DD>

<DT>On the other hand, the derivative <em>could</em> be defined as</DT>
 <DD>$${f^\prime(x)  = \lim_{h\to 0} {f(x+h/2)-f(x-h/2) \over h}}$$
 In the limit the difference from the usual definition goes away.</DD>

<DT>When $h$ is small (but not too small) there is a difference between a forward step and a central step.  </DT>
 <DD>By keeping $f(x)$ inside rather than on one edge the finite approximation is almost always better.
$${f^\prime_{CD}(x) = {f(x+h/2)-f(x-h/2) \over h} \approx f^\prime(x) }\qquad(CD)$$</DD>

<div align="center"><h3>Numerical Derivatives</h3>
<DD class="callout"><img src="img/fgrad.png"></img><blockquote>Numerical derivatives can be computed different ways. Forward and central differences are the most common.</blockquote></DD></div>

<DT>Now consider taking the derivative at $x=1.0$ and $y=10000.0$.  </DT>
 <DD>One issue is if the same $h$ should be used for both.  If so, round-off errors may become an issue.  </DD>
 <DD>Adding $10^{-4}$ to $10^{4}$ has different implications in FPRs than adding it to $10^{0}$. </DD>

 <DT>One way to adjust the step size is to make it proportional to $x$.</DT>
   <DD>That is, $h = \delta x$, where $\delta \approx 10^{-4}$.  But this fails if $x=0$, since then $h=0$.  </DD>
   <DD>Numerically we want to ensure that a minimum step size is maintained that does not flirt with machine precision.</DD>

<h3>Central-Difference Numerical Derivative with Safe Proportional Step Size</h3>
<OL class="steps">
<LI>Set $h \approx 10^{-5}$,  a standard step size for $x=1.0$.</LI>
<LI>Set $d \equiv (\epsilon_{m})^{1/2}$, a minimum step size well above machine precision.</LI>
<LI>Let $h_{x} = max( (|x|+d)*h , d )$, either a proportional or minimum step.</LI>
<LI>Compute $f^{'}_{CD}(x) = { f(x+h_{x}/2) - f(x-h_{x}/2)  \over  h_{x}}$.</LI>
</OL>

<LI>Second Derivatives</LI>

The algorithm above handles a single derivative, $f^\prime(x)$.   The idea extends to multi-dimensional functions.

<DT>The second derivative is the derivative of the first derivative:</DT>
<DD>$$f^{\prime\prime}(x) \equiv {d^2f(x)\over d x^2} = {d\left[{d f(x)\over dx}\right]\over dx} = \lim_{h\to 0}\  {f^\prime(x+h)-f^\prime(x)\over h}.\qquad(2D)$$</DD>
<DT>Of course, if have analytic first derivative we could compute the second derivative numerically on it.</DT>
<DT>But what about taking a numerical derivative of a numerical derivative?</DT>
<DD>First, inside (2d) substitute the definition of a numerical central-step derivative in for $f^\prime(x)$ using $h$ as the step size.</DD>
 <DD>Then approximate the second derivative with a central-step derivative on that, using the same $h$.</DD>
 <DD>The result simplifies into an expression that requires three evaluations of $f(x)$ not four, because two of the steps cancel out.</DD>
 <DD class="callout">&nbsp;$$
f^{\prime\prime}(x)\quad \approx \quad {  { f\left(x+h/2+h/2\right)-f\left(x-h/2+h/2\right)\over h} - { f\left(x-h/2+h/2\right)-f\left(x-h/2-h/2\right)\over h} \over h }
\quad=\quad  {f(x+2h) - 2f(x) + f(x-2h) \over h^2} $$&nbsp;</DD>

<LI>Partial Derivatives: Gradients, Jacobians and Hessians</LI>
<OL>
<LI>Multivariate functions</LI>

<DT>Now, let's let $x$ be a vector of $n$ numbers:</DT>
<DD>$$x = \pmatrix{x_1\cr x_2\cr \vdots\cr x_n}.$$</DD>
<DD>We would then write $x \in \Re^n$ to indicate this without having to write out the elements of the vector each time.</DD>
<DT>$f(x)$ is still a real-valued function, so  $f:\Re^n\to\Re$.</DT>


<LI>Partial Derivatives</LI>
<DT>The notion of a derivative is applied to each component of $x$ to define its partial derivative.</DT>
<DD>To define the partial derivative of $f()$ with respect to $x_i$ we have to add/subtract a small amount to $x_i$.  </DD>
<DD>It is a bit cumbersome to write out $\pmatrix{ x_0 & x_1 & \cdots & x_i + h & \cdots & x_n}$ in defining partial derivatives.  </DD>
<DD>We can use vector additions to make it simpler.</DD>
<DD>Let $\iota_i$ be a $n\times 1$ vector with zeros everywhere except a 1 in the i$^{th}$ position: $\iota = \pmatrix{0&0&\cdots&1&0\cdots}$.</DD>
<DD class="callout">Then
$${\partial f(x) \over \partial x_i} \equiv \lim_{h\to 0}\ {f\left(x+h\iota_i\right)-f\left(x\right)\over h}.$$</DD>

<DT>The gradient is the vector of partial derivatives.</DT>
<DD class="callout">&nbsp;
$$\mathop{\nabla f(x)}\limits_{_{1 \times n}}  \equiv \left[ \matrix{\partial f(x) \over \partial x_{j} }\right]$$&nbsp;
</DD>
<DD>Other notation is kept consistent if we think of the gradient as a <em>row</em> vector not a column vector like $x$.</DD>

<DT>How many f's</DT>
<DD>For computing the gradient $\nabla f$ with a forward step requires {$n+1$} function evaluations.  </DD>
<DD>A CD gradient requires $2n$ evaluations.  So if computing $f$ is costly this can be a big difference, but typically the improvement in precision is worth it.</DD>

<LI>The Hessian Matrix</LI>
<DT>Each partial derivative of $f(x)$ has second derivatives with respect to each component of $x$.</DT>
<DD class="callout">The resulting matrix of second partial derivatives is called the <em>Hessian</em> of $f(x)$
$$Hf(x) = \left[ {\partial^2 f(x) \over \partial x_i \partial x_j } \right] = \left[\matrix{
{\partial^2 f(x) \over \partial x_1^2}&{\partial^2 f(x) \over \partial x_1 \partial x_2}
&\cdots&{\partial^2 f(x) \over \partial x_1 \partial x_n}\cr%
{\partial^2 f(x) \over \partial x_2 \partial x_1} & {\partial^2 f(x) \over
\partial x_2^2}&\cdots&{\partial^2 f(x) \over \partial x_2 \partial x_n}\cr%
{\partial^2 f(x) \over \partial x_n\partial x_1}&{\partial^2 f(x) \over \partial x_n
\partial x_2} &\cdots&{\partial^2 f(x) \over \partial x_n^2 }\cr
}\right]$$
&nbsp;</DD>


<LI>The Jacobian Matrix</LI>
<DT>The definitions above all concern real-valued (scalar-valued) functions.  The Jacobian expands the notion of gradient to vector-valued functions.</DT>
<DT>Now let $f:\Re^n \to \Re^m$.</DT>
  <DD>As a vector-valued function $f$ can be written as a vector of component functions: $$\mathop{f(x)}\limits_{_{m\times 1}} = \pmatrix{ f_1(x)\cr f_2(x)\cr\vdots\cr f_m(x)} = \Bigl[\ f_i(x)\ \Bigr].$$&nbsp;</DD>

<DT>Each component function of $f(x)$ can have partial derivatives with respect to each element of $x$.</DT>
<DD>That is $\partial f_i(x) / \partial x_j$ is the partial derivative of the $i^{th}$ component of the output vector with respect to the $j^{th}$ element of the input vector. In total there would be $nm$ such partial derivatives.</DD>
<DD>If we put all the partial derivatives in a matrix, then we call it the <em>Jacobian of $f$</em>:
$$Jf(x) = \left[ {\partial f_i(x) \over \partial x_j } \right]
=\left[\matrix{
{\partial f_1(x)\over\partial x_1}&{\partial f_1(x)\over\partial x_2}&\cdots&{\partial f_1(x)\over\partial x_n}\cr
{\partial f_2(x)\over\partial x_1}&{\partial f_2(x)\over\partial x_2}&\cdots&{\partial f_2(x)\over\partial x_n}\cr
\vdots&\vdots&\cdots&\vdots\cr
{\partial f_m(x)\over\partial x_1}&{\partial f_2(x)\over\partial x_2}&\cdots&{\partial f_m(x)\over\partial x_n}\cr
}\right].$$&nbsp;</DD>

<DT>For $m=1$ the Jacobian is the gradient, $\nabla f(x)$.</DT>
<DD>This is why defining the gradient as a row vector keeps the dimensions straight.</DD>

<LI>Hessians and Jacobians</LI>

<DT>For a given real-valued $f$ and $x$, the Hessian is a square matrix.</DT>

<DT>The Hessian matrix for $f(x)$ is a (very) special case of the Jacobian of a system of functions.</DT>
<DD>The Hessian of a real function is the Jacobian of its (transposed) gradient:
$$Hf(x) = \left[ J\left[\nabla f\right]^T\right](x).$$</DD>

</OL>

<LI>Calculus in Ox</LI>
<DD><pre>
#import "maximize"

Num1Derivative(func, vP, avScore);

Num2Derivative(func, vP, amHessian);

    func
        in: a function computing the function value, optionally with derivatives
    vP
        in: p x 1 matrix with parameter values

    avScore/amHessian
        in: an address
        out:
            p x 1 matrix with 1st derivatives at vP
            p x p matrix with 2nd derivatives at vP
</pre></DD>

<DD>The supplied func argument should have the format
<pre>
    func(vP, adFunc, ...);
        vP
            in: p x 1 matrix with coefficients
        adFunc
            in: address
            out: double, function value at vP
        returns
            1: successful,
            0: function evaluation failed

</pre></DD>
<DD>
<pre>
NumJacobian(func, vX, amJacobian);
        func
            in: function returning m x 1 vector value of the system

        vX
            in: n x 1 matrix of parameters

        amJacobian
            in: address
            out:  m x n Jacobian matrix
</pre></DD>

<DD>The supplied func argument should have the following format:
<pre>
func(avF, vX);
        avF
            in: address
            out: m x 1 matrix, value of the system
        vX
            in: n x 1 matrix input

        returns
            1: successful,
            0: function evaluation faile

</pre></DD>
</OL>
<h3><a name="s040"><LI>Add It Up<br/>&emsp;Integral Calculus</a></LI></h3>
<!-- -->

<h4>Definition of an Integral</h4>

<DT>A finite Riemann sum based on trapezoids:</DT>
 <DD>$${\hat R = \sum_{i=0}^{n-1} {b-a\over n}\left( f\left(a+i(b-a)/n\right) + {1\over 2}\left(f\left(a+(i+1)(b-a)/n\right)-f\left(a+i/n\right) \right) \right).}$$</DD>
<DD>$n$ function evaluations, $n-1$ rectangles below $n-1$ triangles.</DD>
<div align="center"><h3>Riemann Sums</h3>
<img src="img/int-1d.jpg"></img><blockquote></blockquote></div>

<h4>Trapezoid Approximations to $S$</h4>
<OL class="alg">
<LI>For $n=1$: $\hat R_1 = (b-a)\biggl[ {1\over 2} f(a) + {1\over 2} f(b) \biggr] $<br>
    For $n=2$: $\hat R =  (b-a)\biggl[ {1\over 4} f(a) + {1\over 2} f\bigl(\left(a+b\right)/2\bigr) + {1\over 4} f(b) \biggr] = {1\over 2}R_1 + {1\over 2}f\bigl(\left(a+b\right)/2\bigr)$</LI>
<LI>In general</LI>
    $${\hat R_n = (b-a) \sum_{i=0}^{n-1} \omega^i_n f(x_i)\ \hbox{and} \sum \omega_i = 1.}$$
    <DD>Different sets of weights are designed to reduce the error between $\hat R$ and $S$.</DD>
    <DD>Iterative integration: $R_n = {1\over 2}R_{n-1} + {1\over 2}\sum_{i=1}^{n/2} f\bigl(x_{2i-1}\bigr)$
    Start at $n=1$ and proceed until $|R_n-R_{n-1}| < \epsilon$.  A bad idea in a vector/interpreted language or under parallel execution.  </DD>
    <DD>Or: fix the depth $n$ and compute all at once.  Later check sensitivity of results by increasing $n$.</DD>
</OL>

<h4>Improper Integrals</h4>

<OL class="alg">
<LI>$S=\int_a^b f(x) dx$, where $f(a)$ or $f(b)$ undefined, including the possibility that  $a=-\infty$ or $b=\infty$. If the interval is unbounded (say, $b=\infty$) then for $S$ to exist  $\lim_{x\to \infty} f(x)=0$.</LI>

<LI> Change of variables: $z = g(x)$, $g$ monotonic and differentiable, $\left[g^{-1}\left(a\right),g^{-1}(b)\right]$ is compact.  Then
$$S = \int_a^b f(x)dx = \int_{g^{-1}(a)}^{g^{-1}(b)} f(g(z)) |g^\prime(z)| dz$$
So apply transformation and use a technique for proper integrals.</LI>
</OL>

<h4>Gaussian Quadratures</h4>

Error in approximating $S$ can be reduced for a given number of evaluations by choosing weights and nodes together for integrands of particular form.
<OL class="alg">
<li>Choose weights and points together for integrands of the form:
$${S = \int_a^b f(x) g(x) dx \approx \sum_{i=1}^n \omega_i f(x_i) = S^\star.}\qquad(GQ)$$
The weights $\omega_i$ and nodes $x-i$ are based on the weight $g(x)$ for any $f()$.  In particular, they are chosen so that $S=S^\star$ for any $f$ that is a polynomial in $x$ of order $2n-1$ or less.  </li>
<LI>Common Quadratures
$${g(x) = \cases{ 1          & Gauss-Legendre\cr
                e^{-x^2}    & Gauss-Hermite\cr
                e^{-x}      & Gauss-Laguerre\cr }}$${}
Note:  The baseline range of integration is different in each case.  Look up $\omega_i$ and $x_i$ in a table and apply.</LI>

<LI>If your integrand does not factor into a $g(x)$ of one of the common forms, you can rewrite as $f(x)g(x)/g(x)$ so that you use  (GQ) on $f(x)/g(x)$. </LI>

</OL>

<h4>Multi-dimensional Integration</h4>

$$S = \int_{a_2}^{b_2} \int_{a_1}^{b_1} f(x_1,x_2) dx_1 dx_2 = \int_{a_2}^{b_2}\left[ \int_{a_1}^{b_1}f\left(x_1,x_2\right)dx_1\right]dx_2.$$

Fixed $\delta$ methods:  Could integrate one dimension at a time. Or evaluate $f()$ on {a lattice} This is a matrix-oriented and parallel approach.

For given $x_2$,  $n=N$ evaluations provides sufficient precisions for $\int_{a_1}^{b_1} f(x_1,x_2) dx_1$.  How many needed for $S$?  $N\times N$.  For $D$ dimensions, evaluations is {$N^D$}: an example of {curse of dimensionality.}  The problem no more complicated but {work increases exponentially in $D$}.


<div align="center"><h3>Two Dimensional Integral</h3>
<img src="img/int-2d.jpg" ></img><blockquote></blockquote></div>

</OL>
<h2><a name="s041"><LI>Non-Linear Systems</a></LI></h2>
<!-- -->

<OL class="section">
<LI>Set Up</LI>
<DT>Consider these two problems:</DT>
<DD class="callout">1. Find an $x^\star$ that solves
$$ g(x^\star) = \overrightarrow{0}.$$&nbsp;</DD>
Here, $\overrightarrow{0}$ is a vector of zeros.
<DD class="callout">2. Find an $x^\star$ that maximizes $f(x)$, or
$$x^\star\ =\ \arg\max\ f(x).$$&nbsp;</DD>
<DT>These are closely related but not identical tasks.</DT>
<DD>For example, we know that if $x^\star$ maximizes $f(x)$ and $f(x)$ is smooth enough (i.e. it has continuous partial derivatives) then
$$g\left(x^\star\right)\ \equiv\ \nabla f\left(x^\star\right)'\ =\ \overrightarrow{0}.$$&nbsp;
So maximizing a function can be thought of as solving for the zeros of the gradient.</DD>
<DT>However, algorithms to solve 1 and 2 are not quite the same.</DT>
<DD>One way to think about this is that the system in 1 could be anything.  But partial derivatives are a very special kind of system. So algorithms to maximize a function can be more efficient than applying algorithms designed to solve systems.</DD>

<DT>Closed-Form Versus Solution Methods.</DT>
<DD>If $f()$ or $g()$ is a convenient form then we can algebraically solve the problem.  This would be a <em>closed-form</em> solution.  </DD>
<DD>However, problems the admit closed-form solutions are very special. Most interesting problems involve systems or objectives that do not have closed-form solutions.</DD>
<DD>What we discuss here are algorithms to solve 1 and 2 <em>sequentially</em>.  That means, start with an initial or starting value, $x_0$ and use the calculated value of the system/objective to move closer to the solution $x^\star$.</DD>
<DD>Typically these algorithms are sequential in the sense that the first step will produce a new guess $x_1$, which hopefully is better than the first guess but is unlikely to be equal to $x^\star$.  Then apply the procedure again to $x_1$ to get another guess $x_2$.  Keep doing this for until the latest guess, $x_t$, is close enough to $x^\star$ for our purposes.</DD>

<LI>Roots of a Non-Linear Systems</LI>

<ol class="chapter">
<LI>Definition</LI>
<DT>Given $g : \Re^n \to \Re^n$, a square non-linear system of equations. </DT>
<details class="aside"><summary>Smoothness</summary>The methods we cover assume that the second derivatives of the system are continuous.w </details>
<DD>We wish to find <b>a</b> $x^\star\in \Re^n$ that satisfies
$$g\left(x^\star\right)= \overrightarrow{0}.\qquad (*)$$</DD>
<DD>A vector that satisfies (*) is called a <em>root of the system</em>.</DD>
<DT>Close Enough for Academic Work!</DT>
<DD>Since the system $g$ will be computed numerically and the value of the inputs $x$ are stored as a vector of floating point reals, is very likely that we cannot satisfy the equation (*) exactly.</DD>
<DD>So, we will be satisfied if we are "close enough."  That means that

<LI>Linear Means Easy</LI>

<DT>Suppose $g$ is a linear system.</DT>
<DD>That means we can write $$g(x) = Ax+b$$
where $A$ is a square matrix and $b$ is a $n\times 1$ vector of constants.  </DD>
<DT>Of course, a linear does have a closed-form solution:
<DD>$x^\star = -A^{-1}b$. </DD>
<DD>That is, if we can compute $A^{-1}$ we can find the $x^\star$ that is the <em>unique</em> root of the system.</DD>
<DD>Given $A^{-1}$ an iterative or sequential solution is not needed, but we can think of it like an iteration anyway.</DD>
<DT>That is, suppose we started at a guess $x_0$. </DT>
 <DD>The value of the system at that point is $g(x_0) = Ax_0 + b$. If we wanted to get to $x^\star$ from there we could say:
$$x^\star = x_1 \equiv  x_0 - A^{-1}(b+Ax_0) = x_0 - A^{-1}g(x_0).$$
In other words, we find the root by subtracting a vector from the initial guess $x_0$.  </DD>
<DD>That is, we take a step from $x_0$ to get a new value $x_1$.  The size of the step is such that we wipe out the difference $g(x_0)$.  <details class="aside"><summary>Reminder: It is typically inefficient to actually compute $A^{-1}$</summary> <DD>Instead, solve linear system $$A s = -g$$
  to determine a <em>step</em>: $x_1 = x_0 + s.$</DD></details>

<DT><details><summary>Linear System as an Iteration</summary><img src="img/NRstep.png"/></details></DT>

<LI>Non-linear means locally linear</LI>
<DT>When $g$ is non-linear, we use the iterative formula treating $g$ as (locally) linear.  </DT>
<DD>The (local) analogy to $A$ is then $Jg(x)$.</DD>
</ol>

<li>Newton-Raphson (Compute Jacobian)</li>

Newton-Raphson is a centuries-old algorithm to find the root of a non-linear system which uses the Jacobian of the system.

<OL class="steps">
<DT>Given $g(x)$, and $x_0\in \Re^n$. Set $t=0$.</DT>
<LI><b>Compute</b> $g_t = g(x_t)$.</LI>
    <DT>Strong convergence:  $\|g_t\|< \epsilon_1$, then <img src="img/stop_sign.png"/>.</DT>

<LI><b>Compute</b>  the Jacobian at the new values, $J_t = Jg(x_t)$. </LI>
    <DD> <b>Solve</b> $J_ts_t = -g_t$ for $s_t$.</DD>
    <DD><b>Set</b> $x_{t+1} = x_t +    s_t$. </DD>
    <DD>Lack of convergence: if $J_t$ is (nearly) <em>singular</em> or $\|x_{t+1}-x_t\|<\epsilon_2$,
    then <img src="img/stop_sign.png"/>.</DD>

<LI><b>Increment</b> $t$ and go back to step 1.</LI>
</OL>

<DT><details><summary>Newton-Raphson Iteration</summary><img src="img/NRstep2.png"/></details></DT>


<LI>Properties of Newton-Raphson</LI>
<UL class="ul">
<LI>For well-behaved $g(x)$, convergence is <em>quadratic</em> in $t$.</LI>
    <DD>That is, how much of the distance between the current step and the ultimate value that is closed increases as a quadratic function of the number of iterations so far.</DD>

<LI>Not always feasible to program analytic $J$.  </LI>
    <DD>If numeric $J$ is used, then number of evaluations required for each step: $1+2n$.</DD>
      <DD>If the cost of calculating $g(x)$ is linear in $n$ then computational cost of each step is <em>quadratic</em> in size of the system.</DD>

<LI>No guarantee that the Newton-Raphson step will be an improvement or that it will converge.</LI>
      <DD>Behavior depends on $Jg$, which may be badly behaved far from a root.  May be near singular and steps may {diverge}.</DD>

<LI>Alternative:  use information from past evaluations to build up an approximation to $J_t$ without computing it.</LI>

<LI>Only "stable" roots will be found: no systematic way to use Newton-Raphson to find <em>all roots</em>.</LI>

</UL>

NRstep2.png

<LI>Broyden (Approximate Jacobian).</LI>

Broyden's method is a decades-old algorithm for solving a non-linear system that avoids computing the Jacobian of the system at each iteration.  Instead, it builds up an approximation to the Jacobian as the iterations proceed.

<DT>Given $g(x)$, and $x_0\in \Re^n$.</DT>
<OL class="steps">
<LI>Initialize. Set $t=0$; compute $g_0 = g(x_0)$; Set $J_0$ to a (well-conditioned) $n\times n$ matrix. Typically, $J_0 = I$. </LI>

<LI>Strong convergence:  $\|g_t\|< \epsilon_1$. Otherwise, solve $J_t s_t = g_t$ for $s_t$.  Set $x_{t+1} = x_t - s_t$.  Non-convergence: {$\|x_{t+1}-x_t\|<\epsilon_2$}. Possibly {reset $J_t$ to $J_0$.}.</LI>

<LI>Update Jacobian.  Compute $g_{t+1}=g(x_{t+1})$ Let $y=g_{t+1}-g_t$.  Then $${J_{t+1} = J_t +{(y-J_t s_t)s_t^T\over \|s_t\|}.}$$</LI>

<LI>Increment $t$ and repeat previous two steps.</LI>
</OL>

<LI>Properties of Broyden</LI>
<UL class="ul">
<LI>Theorem: $J_t \to Jg(x_t)$.  The gradient is built up without computing it directly.</LI>

<LI>More robust to initial value $x_0$ than Newton-Raphson.  But still no guarantee of convergence.</LI>

<LI>If convergence fails, restart at final values, which sometimes allows for further progress.</LI>

</UL>

<LI>SolveNLE</LI>

<DT>The standard Ox package <code>solvenle</code> codes both Newton-Raphson and Broyden.</DT>
<DD>To use it, your program must import the package:
<pre>#import "solvenle"</pre>
</DD>
<DT>Both algorithms are available in one function:</DT><DD>
<pre>SolveNLE(func, avX);</pre>
The two-argument version of a call to <code>SolvenLE</code> is the basic version.  Optional arguments can be sent to control the algorithm.</DD>
<DD><pre>
	func
		in: Ox function evaluating the nonlinear equations (see below)
	avX
		in: address of nx 1 matrix with starting values
		out: nx 1 matrix with final coefficients
</pre></DD>
<DD>In other words, you code the system of equations as a <em>function</em> which gets called by <code>SolveNLE</code>. The second argument
should be an address (so use <code>&</code>) of vector that contains the starting vector $x_0$.   When <code>SolveNLE</code> is finished it puts the final value back in the location sent.  So the starting values you send get written over with the final values by <code>SolveNLE</code>.</DD>

<DT>The supplied func argument should have the following format:</DT>
<DD><pre>
	func(const avF, const vX)

			avF
				in: address
				out: nx 1 matrix with nonlinear system f(x) evaluated at x
			vX
				in: nx 1 matrix with x values

		returns
			1: successful, 0: function evaluation failed
</pre></DD>
<DT>Example</DT>
<DD> Suppose $n=1$, a one-dimensional system and
$$g(x) = \ln x + x^2.$$
</DD>
<DD>We know at least one root must exist because: $g(0) = -\infty$ and $g(1) = 1$.</DD>
<DD>So somewhere between 0 and 1 the function crosses 0.  A reasonable starting value might be  $x_0=1$.  </DD>
<DD>Since $x\le 0$ is undefined, so we want to tell the algorithm to stay away from those values.</DD>
<DD><pre>
#include "oxstd.h"
#import "solvenle"

myg(fv,x) {
    if (x<=0) return FALSE;
    fv[0] = log(x) + x^2;
    return TRUE;
    }

main(){
    decl xx = <1.0>;
    SolveNLE(myg,&x);
    println("solution: ",x);
    }
</pre></DD>
<DD>Output:
<pre>
--------------- Ox at 15:33:17 on 22-Feb-2016 ---------------

Ox Professional version 7.10 (Windows_64/U/MT) (C) J.A. Doornik, 1994-2014
solution:
      0.65292
</pre></DD>


</OL>
<h2><a name="s042"><LI>Optimization</a></LI></h2>
<!-- -->

<OL class="section">
<li>Overview</li>
We begin with <em>unconstrained</em> optimization. The objective is a real-valued function of $n$ real values (arguments, choices, etc.).  We write $f : \Re^n \to \Re$ to say the same thing symbolically. Let $x \in \Re^n$ be a vector of choices.  Then maximization is written as
$$f^\star \qquad \equiv\qquad \max_{x}\ f(x).$$
These notes consider "maximum."  Rather than change formulas for minimum, it is better to use the identity
$$\min\ f(x)\quad =\quad \max\ -f(x),$$ i.e., negate your objective and maximize.</p>

The <defn>argmax</defn> is a fancy term for an argument that does the maximizing. So if $f(x^\star) = f^\star$ we would write $x^\star \in \arg\max f(x)$. Note we use $\in$ instead of $=$ because there can be more than one optimal values. In general $\arg\max$ is a <em>set</em>.</p>

Our focus is on <dfn>sequential optimization</dfn> techniques. Before that is explain, let's consider <em>non-</em>sequential optimization. For example, suppose $n=1$, a one-dimensional problem and let $f(x)$ be smooth (all derivatives exist).  Then, as emphasized in micro theory classes around the world, the optimal value of $x^\star$ would solve:
$$f^\prime(x^\star) = 0.\qquad(FOC)$$
If (FOC) can be solved explicitly using algebra we say it has a <em>closed-form</em> solution.  If so, then we do not need an algorithm to maximize $f(x)$. Except for some well-behaved examples (like quadratic) we can't find closed-form solutions to the maximization problem.</p>

Equation (FOC) might suggest that the we simply use a <a href="">non-linear system solver</a> to find the solution.  This can certainly work, but there are some reasons not to maximize this way.</p>

Sequential optimization is a kind of algorithm. Let's call one of these algorithms $V$. A sequential optimizer takes (at least) two inputs: the objective $f()$ and an initial guess or starting value, $x^0$,
$x^0\in \Re^n$. The optimizer can be thought of as a function that produces a guess or approximation to $\arg\max$:
<DD>$$x^\star_V\left(x^0\right) = V\bigl( f(), x^0 \bigr) \approx \arg\max_x\ f(x).$$</DD>


<LI>Line Optimization</LI>

We start with the case of one-dimensional optimization.  This procedure is part of other algorithms that handle more than one dimensions.

<DT>Given $f:\Re\to\Re$, $x_0$ and tolerance $\epsilon$.</DT>
<OL class="steps">
<LI>Initialize.  Calculate  $f(x_0)$.  Pick point $x_1>x_0$ and evaluate $f(x_1)$.</LI>

<LI>Bracket.  Evaluate $x_2 < x_3 < \dots < x_B$ until a local max must lie in $[x_0,x_B]$: That is, $$\max_{1<b<B} f(x_b)\ge \max\{f(x_0),f(x_B)\}.$$
    Set $x^L = x_0$, $x^m = \arg\max_{1<b<B} f(x_b)$ and $x^U=x_B$.</LI>

<LI>Bisect.  Try $x^\prime = (x^L+x^U)/2$.  So: $x^L<\min\{x^\prime,x_m\}<\max\{x^\prime,x^m\}<x^U$.  Either set $x^L=\min\{x^\prime,x^m\}$ and $x^m=\max\{x^\prime,x^m\}$; or set $x^U=\max\{x^\prime,x^m\}$ and $x^m=\min\{x^\prime,x^m\}$, ensuring bracket contains the optimum.</LI>

<LI>Iterate. Repeat previous step until $x^U-x^L < \epsilon$. Return $x^\star = {(x^L+x^U) / 2}$.</LI>
</OL>

<dt class="callout"><h4>One Dimensional (Line) Optimization</h4>
<img src="img/optline.gif" width="75%" ></img></dt>

</OL>
<OL  type="1" ">
<h3><a name="s043"><LI>Climb Every Mountain<br/>&emsp;Gradient Based Optimization</a></LI></h3>
<!-- -->

Use the derivatives of the function to guide the search for improvement.

<OL>
<LI>Steepest Ascent</LI>
<DT>Give $f(x)$ and $x^0\in \Re^n$ and tolerance $\epsilon$. </DT>
<OL class="steps">
<LI><b>Initialize.</b> Set $t=0$.</LI>

<LI><b>&rarr;Compute Gradient.</b> $\nabla f_t = \nabla f(x^t)$. Strong convergence:  If $\|\nabla f_t\|< \epsilon_1$, then <img src="img/stop_sign.png"/>.</LI>

<LI><b>Line Optimization.</b></LI>
<DD>$$\lambda^\star = \arg\max_\lambda f\left(x^t + \lambda \nabla f_t' \right).$$</DD>
<DD>Set $x^{t+1} = x^t + \lambda^\star\nabla f_t'$.  </DD>

<LI><b>Increment $t$</b> and repeat previous two steps (go back to &rarr;).</LI>

</OL>

<dt class="callout">
<h4>Steepest Ascent in Two Dimensions</h4>
<img src="img/optsteep.gif" width="50%" ></img></dt>


<LI>Newton's Method: Gradient and Hessian</LI>

<DT>Take a second order approximation to $f$.  </DT>
<DD>Let $\nabla f_0$ denote the $1\times n$ gradient at $x_0$ and $Hf_0$ the $n\times n$ Hessian
at $x_0$.
$${f(x) \approx f(x_0) + (x-x_0)\nabla f_0^T + {1\over 2}(x-x_0)^T \biggl[ Hf_0\biggr] (x-x_0).}$$
($^T$ stands for the matrix transpose operator.)  </DD>
<DD>Then the max of the approximation would set this equal to zero, which with a quadratic objective has a closed form:
$$x^\star = x_0 - H^{-1}f_0 \nabla f_0^T.$$
This is turned into an iterative process.</DD>

<h4>Newton</h4>
<DT>Given $f(x)$, and $x_0\in \Re^n$ and tolerance $\epsilon_1$.</DT>
<OL class="steps">
<LI><b>Set</b> $t=0$.</LI>
<LI><b>&rarr;Compute</b> $\nabla f_t$ Strong convergence:  If $\|\nabla f_t\|< \epsilon_1$, then <img src="img/stop_sign.png"/>.</LI>

<LI><b>Compute</b>  $H_t = Hf(x_t)$.</LI>
<LI><b>Solve</b> $H_t s_t = -\nabla f_t^T$ for the direction $s_t$.</LI>
<LI><b>Perform</b> line optimization on $\lambda$:</LI>
    $$\lambda^\star_t = \arg\max_\lambda f\left(x_t + \lambda s_t\right)$$
    <b>Set</b> $x_{t+1} = x_t + \lambda^\star s_t$.

<LI><b>Increment</b> $t$ and repeat previous two steps(go back to &rarr;).</LI>
</OL>

<dt class="callout"><h4>Newton versus Steepest Descent</h4>
<img src="img/optnewton.jpg" width="50%"/></dt>

<h4>Reasons for not using Newton's Method</h4>

<DT>Computing $H$ at each step of the iteration can be <em>costly</em>.</DT>

<dt class="callout"><h4>The Hessian can be <em>misleading</em> far away from an optimum.</h4>
<img src="img/opthessian.jpg" width="50%"/></dt>


<LI>Quasi-Newton Methods</LI>

<DT>A <em>quasi-Newton</em> algorithm uses the same step formula as Newton but it uses an <em>approximation</em> to the Hessian instead of computing it directly.</DT>
<DT>Quasi-Newton algorithms build up the approximation to the Hessian as iteration proceeds.  </DT>
<DD>The formula uses the current Hessian approximation and the changes in the parameter vector and the gradient vector.</DD>

<h4><dfn><abbr title="Broyden-Fletcher-Goldfarb-Shanno">BFGS</abbr> </dfn> Updating</h4>
<DT>Given $f(x)$, and $x_0\in \Re^n$.</DT>
<OL class="steps">
<LI><b>Initialize</b>. <br>
    <b>Compute</b> $\nabla f_0$.  <b>Set</b> $t=0$ and $H_0=I$ (or some other symmetric invertible matrix).</LI>

<LI>&rarr; Strong convergence:  If $\|\nabla f_t\|< \epsilon_1$, then <img src="img/stop_sign.png"/>.</LI>

<li><b>Solve</b> $H_t s_t = -\nabla f_t^T$. </li>
<li><b>Perform</b> line optimization on $\lambda$:</li>
    $$\lambda^\star_t = \arg\max_\lambda f\left(x_t + \lambda s_t\right)$$
    <b>Set</b> $x_{t+1} = x_t - \lambda^\star_t$.

<LI><b>Update $H$</b> (according to BFGS or other formula).</LI> <br>
    <b>Compute</b> $\nabla f(x_{t+1})$.  Let $z=x_{t+1}-x_t$ and $y= \left(\nabla f_{t+1}-\nabla f_t\right)^T$.
    <br>BFGS Update:
    $${H_{t+1} = H_t - { (H_t z)(H_t z)^T\over z^TH_t z} + {yy^T \over y^T z}.}$$

<LI><b>Increment</b> $t$ and repeat previous 4 steps (go to &rarr;).</LI>
</OL>

<h4>Theorem: $H_t \to Hf(x_t)$ in $n$ iterations.</h4>

<h4>Warning</h4>
<DT>The final value $H_T$ is <em>not</em> a reliable as $Hf(x^\star)$ and should <b>never</b> be used as an estimate of $H$.  </DT>
<DT>Instead, compute $Hf(x^\star)$ directly or do one Newton step.} </DT>

</OL>
<h3><a name="s044"><LI>Finding Nemo<br/>&emsp;Non-Gradient Optimization</a></LI></h3>
<!-- -->
<OL>
<LI>Nelder-Mead Amoeba (Simplex)</LI>

<DT>The Nelder-Mead (1965) algorithm searches for an optimum of a function without relying on the function's gradient or Hessian.</DT>
<DD>It is a very simple but smart "search" algorithm, typically much better than searching over a grid of values.</DD>
<DD>Because it does not rely on gradients its performance only requires <em>continuity</em> of the objective.  This means an objective with kinks poses no problem for Nelder-Mead.</DD>

<DT>The basic algorithm creates a <em>simplex</em> which is a closed shape within the parameter space.</DT>
<DD>If choosing one variable ($n=1$) then a simplex is simply an interval on the line.  An interval is defined by its upper and lower limits, that is 2 (or $n+1$) points.</DD>
<DD>When choosing two variables ($n=2$) a simplex is a triangle, a shape that involves three (or $n+1$) vectors. For the triangle to have a non-zero area no
two points or vertices can be on the same line.  </DD>
<DD>In general a simplex is defined by $n+1$ points that are not co-linear.</DD>

<h4>The Amoeba Algorithm</h4>
<OL class="steps">
<LI>Initialization.  Begin with initial value $x_0$.</LI>
    <UL class="ul">
    <LI>Create a simplex in $\Re^n$ with $n$ other (not co-linear) points. </LI>
    <LI>Call these points $x^0, x^1, \dots, x^n$.</LI>
    <LI>Evaluate the objective at each vertex, $f^i = f(x^i)$</LI>
    <LI>Identify the best ($f^M$), worst ($f^m$) and second worst ($f^s$) points.  </LI>
    </UL>
<DT>Return HERE to start a new iteration.</DT>
<LI>Attempt A.  Extend the best point.</LI>
    <UL class="UL">
    <LI>That is, stretch the best vertex $x^M$ out further from all the other points (by a factor greater). Call it $x^A$.</LI>
    <LI> Evaluate the objective at that point, $f^A = f(x^A)$.</LI>
    <LI> Keep $x^A$ if is better than the current worst point.</LI>
    <LI> So if $f^A > f^m$, replace $x^m$ with $x^A$. (Reset the values of $M,m,s$ to account for the change.) Return to HERE with the new simplex.  </LI>
    <LI>If $f^A < f^m$ then go on to attempt B.</LI>
    </UL>
<LI>Attempt B.  Try moving away from worst point.</LI>
<UL class="ul">
<LI>That is,  try $x^B$ which is on the opposite side of the simplex from $x^m$.</LI>
<LI>If $f^B > f^m$ then keep it as in Attempt A an return to HERE.</LI>
<LI>If not, try C.</LI>
</UL>
<LI>Attempt C. Collapse the simplex.</LI>

<UL class="ul">
<LI>Compute new points $x^0, \dots, x^n$ that are all a factor closer to the average point of the current Simplex.  </LI>
<LI> Evaluate the objective at each point and identify M, m and s.  Return to HERE.</LI>
</UL>
<DT>Continue these steps until simplex collapses or has an area smaller desired precision.</DT>
</OL></dt>

<dt class="callout"><h4>Walk like an Amoeba</h4>
<img src="img/amoeba.gif" width="50%"/></dt>

<LI>Simulated Annealing</LI>

</OL>
</OL>
<h2><a name="s045"><LI>Sliding Doors<br/>&emsp;Simulation &amp; Randomness</a></LI></h2>
<!-- -->
<OL class="section">
<LI>Simulating Randomness</LI>

<DT>Computer Randomness</DT>
<DD>There is nothing random about the operation of a computer, except to the extent that cosmic rays and products of truly random radioactive decay might <a href="https://en.wikipedia.org/wiki/Soft_error">scramble memory</a>.  </DD>
<DD>Yet computers appear to generate random events.  Doesn't your phone shuffle your playlist?  Yet, there is nothing random about the operation of the microprocessor on the phone.  </DD>
<DD>If your computer/phone/tablet starts to act in a truly random fashion it is time to get a new one.  </DD>

<DT>Simulation</DT>
<DD>In the modern world we are surrounded by <em>simulated randomness</em>.</DD>
<DD>One of the most important uses of computers in econometrics is to simulate randomness.  What is meant by this is something quite specific.  </DD>
<DD>What is really important to  simulate is <em>independent sampling</em> from a distribution.  That is, computer algorithms have been developed to <u>fake</u> IID sampling.</DD>

<LI>The Standard Uniform Distribution</LI>

<DT>We write $V\sim U(0,1)$ to mean</DT>
<OL class="steps">
<LI>$V$ is a continuous random variable that takes values strictly between 0 and 1</LI>
<LI>$V$ has a uniform (constant) pdf on (0,1). To make the total probability integrate to 1 the height of the density is 1:</LI>
<DD>$f(v) = 1$ for $0\le v\le 1$</DD>
<DD>$\qquad = 0$ elsewhere</DD>
<LI>The cdf of $V=\int_{0}^{v}f(u)du$ is simply $v$:</LI>
<DD>$F(v) = 0$ if $v\le0$</DD>
<DD>$\qquad v$ if $0\lt v \lt 1$</DD>
<DD>$\qquad 1$ if $v\gt 1$</DD>
</OL>

<DD>Equal density means that the probability $v$ lands in any interval $(a,b)$ inside $(0,1)$ is simply the size of the interval  $b-a$.
</DD>

<LI>Invert the CDF</LI>

<DT>The uniform distribution is the key to simulating randomness.  </DT>
<DD>It turns out that simulating $U(0,1)$ is all you need to be able to do in order to simulate any distribution $F(x)$.  </DD>
<DD>The key insight that allows us to do this is not obvious:</DD>

<DD><OL class="steps">
<LI>Draw a realized value from $U(0,1)$.  Call this value $u$.</LI>
<LI><em>Invert</em> the mathematical function for the CDF of $X$ at the value of $u$.</LI>
</OL></DD>

<DT>Illustration of the Procedure</DT>
<DD>Below is a CDF of a random variable $X$ that looks like the cumulative normal cdf, but does not need to be that function. Like all CDFs, it takes on values between 0 and 1 along the vertical axis.</DD>
<DD>The Uniform random number generator will produce a number between 0 and 1 with equal probability everywhere in that range.  The realized value is marked $u$ and appears to be around 0.75 in this case.</DD>
<DD>This value is inverted to find the value of $x$ for which $F(x) = u$.</DD>
<DD>The theorem says the value of $x$ produced by this procedure will follow the distribution of $X$.</DD>
<DD>More specifically, if we repeated this procedure over-and-over again and the Uniform random number generator was working properly the histogram of values of $x$ would pile up like the pdf $f(x)$.  As the number of replications went to infinity the histogram would converge to $f(x)$ exactly.</DD>

<DT><details><summary>Inverting the CDF to Simulate a Random Experiment</summary><img src="img/InvertCDF.png"/></details></DT>

<DT>What does this mean? The problem of simulating draws from any distribution has been reduced to a pair of much simpler problems:</DT>
<DD>Come up with a way to simulate draws from the Uniform distribution.</DD>
<DD>Have the ability to <em>invert</em> the CDF of the random variable you want to simulate.  </DD>

<DT>The Inversion task &hellip;</DT>
<DD>requires a formula (if one exists) <u>or</u> a numerical algorithms for computing functions and inverses of functions.</DD>
<DD>The procedures for all common random variable CDFs have been known for decades and are built into Ox and any other statistical package, mathematics library, etc.</DD>
<DD>We will rely on these routines and not discuss how they work.</DD>

<DT>The key to a Uniform RNG is </DT>
<DD>not to just to produce numbers between 0 and 1 that are equally likely,</DD>
<dd>but also to produce sequences of numbers that look like independent draws from the uniform distribution.</dd>
<DD>To assess this aspect of RNGs we need to understand the notion of autocorrelation.</DD>

<LI>Pseudo-Randomness</LI>

<DT>Definition: Pseudo-Random Number Generator (pRNG)</DT>
<DD>A pRNG is an algorithm that produces a list of numbers that have these features:</DD>
<DD><UL class="ul">
<LI>The list is <em>recursive</em>: the algorithm uses where it is in the list to produce the next item (and then moves to that spot in the list). A pRNG has one input, called its <defn>seed</defn>. Setting the seed picks where to start. </LI>
<LI>The list is <em>circular:</em> starting from any point eventually to a value that produces the starting point. A good pRNG is a very long list; it starts repeating itself only after a lot of draws.  The length of the list is called the pRNG period. </LI>
<LI>The numbers all lie between 0 and 1 and are evenly distributed.  They look like the uniform distribution, so we will write <b>$U \ {\buildrel  pseudo \over \sim}\  U(0,1)$</b> if  $U$ is a number produced using a pRNG.</LI>
<LI>The sample autocorrelation function of the list is <b>very</b> close to 0 for lags $k>1$ and less than the period.</LI>
</UL></DD>

<DT>Algorithm: Simulate an IID Sample (continuous)</DT>
<DD>Given $X\sim F(x)$.  Set $r=1$ (the first observation).</DD>
<DD><OL class="steps">
<LI>Draw $u^r \ {\buildrel  pseudo \over \sim}\  U(0,1)$.  This is one pseudo-random replication of a IID uniform random variable.</LI>
<LI>Find the value $x^r$ such that $F(x^r)=u^r$.</LI>
    <DD>That is, compute $x^r = F^{-1}(u^r)$. Based on the theorem above, $x^r$ is a simulated draw from the distribution $F(x)$:
    $$x^r \ {\buildrel  pseudo \over \sim}\  F(x).$$
    The inverse of the cdf can be computed either as a closed form for the inverse of the cdf or it can be computed $x^i$ numerically using computer algorithms.</DD>
<LI>Increment $r$ and repeat.  A pseudo IID sample is then $X_{r=1,\dots,R} \ {\buildrel  pseudo \over \sim}\  F(x)$.</LI>
</OL>

<DT>Simulating a Normal Random Variable using Pseudo $U$.</DT>
<details><summary>Illustration</summary><img src="img/pseudoN.png" alt="pseudo Z" width="75%"/></details>

<LI>Random Numbers in Ox</LI>

<DT>random numbers</DT>
<pre>
rann	standard normal distributed random numbers
ranseed	set and get seed, or choose random number generator
ranu	uniform [0,1] distributed random numbers
</pre>
<DT>Selected Routines from Probability package, requires <code>oxprob.oxh</code></DT>
<pre>
ranindex             draw a random index without replacement
ranmultinomial       multinomial distributed random numbers
ranpoisson           poisson distributed random numbers
ranpoissonprocess    realizations from a Poisson process
ranshuffle           samples from a vector without replacement
ransubsample         samples from a set of integers without replacement
</pre>
</OL>
<h3><a name="ex035"><LI>Exercises</a></LI></h3>
<h3>Exercises</h3><OL class="steps">
</OL>
</OL>
<h1><a name="s046"><LI>Digital Economics in niqlow</a></LI></h1>
<h3><a name="ex046"><LI>Exercises</a></LI></h3>
<h3>Exercises</h3><OL class="steps">
</OL>
</OL>
<footer><table width="100%"><tr><td width="20px"><a href="s.html">&larr;</a></td><td style="text-align:center">&copy; Christopher Ferrall 2016.  Queen's University.</td><td width="20px"><a href="s.html">&rarr;</a></td></tr></table></footer>
